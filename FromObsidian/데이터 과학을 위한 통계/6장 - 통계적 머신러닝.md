- k-NN, 앙상블, DT 등이 여기서 나온다.

## 1. K 최근접 이웃
- 아이디어
	1. 특징들이 가장 유사한 K개의 레코드를 찾는다
	2-1. 분류 :유사한 레코드 중 가장 다수에 속한 클래스를 찾은 뒤, 새로운 레코드를 할당한다
	2-2. 회귀 : 유사한 레코드의 평균을 찾아 새로운 레코드의 예측값으로 활용한다. 

- 특징
	- 피팅이 필요없으나, 가까운 정도를 측정하는 방법, K값 등에 따라 예측 결과가 달라진다.
	- X값은 수치형이어야 한다.

### 거리 지표
- 기본) 유클리드 거리(L2-norm)
	- $K\times n$만큼 `pairwise` 비교하기 때문에 데이터 수가 커질수록 계산량이 중요해짐
- 그 외) 맨하탄 거리(L1-norm)
	- 대각선으로 움직일 수 없고 한 축 방향으로만 움직일 수 있을 때 두 점 사이의 거리를 의미함
	- 이동 시간으로 근접성을 따질 때 좋은 지표
- 그 외2) 마할라노비스 거리(Mahalanobis distance)
	- 두 변수 간 높은 상관관계가 있을 때 유용하다.
	- 상관관계를 고려하므로 공분산행렬이 들어가며, 계산량 & 복잡성이 증가하는 단점은 있다.

### 원-핫 인코더
- 문자열 변수(혹은 범주형)를 다 Column으로 보낸 뒤, 0 혹은 1로 나타내는 것
	- 예를 들어 4개의 문자열 변수가 있다면 1개의 1과 3개의 0으로 구성된 벡터로 정리될 수 있다.
- 이렇게 만들 경우 **통계적 머신러닝 알고리즘에 사용하기 편해진다**는 장점이 있다.

### 표준화, 정규화, z-score
$$ z = \frac{x - \bar{x}}{s}$$
- 모든 변수에서 `평균을 빼고 표준편차로 나누는` 과정을 통해 변수들을 비슷한 스케일에 놓는다.
- 이를 `z-score`라고 한다. 변수의 스케일로 인한 영향을 줄일 수 있다.
- 참고) `데이터베이스에서의 표준화`는 DB 설계시 데이터의 중복을 줄이고 데이터 의존성을 확인하는 과정을 말한다.
- `z-score`는 점수를 변환하는 여러 방법 중 하나일 뿐이다
- 정규화(표준화)는 **데이터 분포에 영향을 주지 않는다.**

### K값 선택
- `k=1`이 가장 직관적이나 가장 좋은 결과를 주진 않는다.
	- `k`가 `너무 작다`면 데이터의 노이즈까지 고려가 되는 `오버피팅`이 발생할 수 있다
	- `k`가 너무 크다면 너무 과하게 평탄화되어 예측 기능을 잃어버린다.
- `최적의 k값을 찾기 위해` 
	- 일반적인 규칙은 없다.
	- **홀드아웃 혹은 타당성검사를 위해 따로 떼어놓은 데이터의 정확도로 K값을 결정**한다.
	- 데이터에 노이즈가 없고 잘 구조화되어 있다면, K값이 작을수록 잘 동작한다.
		- 손글씨 데이터, 음성 인식 데이터가 노이즈가 적은 편이고
		- 대출 데이터 등은 K가 클수록 좋다.
	- 통상적으로 K값은` 1 ~ 20 사이`에 놓으며 동률을 막기 위해 `홀수`를 이용한다.

### KNN을 통한 피쳐 엔지니어링
- KNN은 성능적인 측면에선 경쟁력이 있지 않지만, 실용적인 측면에서 **다른 방법의 특정 단계에 사용할 수 있는 지역적 정보를 제공**한다.
	- KNN은 데이터에 기반해 클래스에 속할 확률을 얻으며, 이 결과는 해당 레코드의 새로운 피쳐로 추가되어 다른 분류 방법에 사용한다. 이 자체로 원래의 예측변수를 2번씩 쓰는 셈이다.
	- `다중공선성 문제가 생길 수 있는가?` : 새로운 피쳐가 근처의 레코드에서 얻은 지엽적인 정보이기 때문에,  새로운 정보는 불필요하거나 중복성이 있는 정보는 아니다.

## 2. 트리 모델
- 쉽게 말하자면 `if - then - else` 모델이다. 이해도 쉽고 구현도 쉽다.
- 데이터에 존재하는 복잡한 상호 관계 속 패턴을 발견하는 능력이 있다.
- 예측변수들 사이의 관계로 단순 트리 모델을 표시할 수 있고, 쉽게 해석이 가능하다.

### 1. 재귀 분할 알고리즘
- 예측변수 값을 기준으로 데이터를 반복적으로 분할해나간다. 
- 대충 2차원 산점도가 있다고 치면 그 2차원 산점도의 데이터들을 가장 잘 나누는 기준을 찾는다는 뜻

- 책의 알고리즘 설명은 이렇다  
<분할 알고리즘>
1. 각 예측변수 $X_j$에 대해
	a. $X_j$에 해당하는 각 변수 $s_j$에 대해
		i. $A$에 해당하는 모든 레코드를 $X < s_j$와  $X >= s_j$로 나눈다.
		ii. $A$의 각 하위 분할 영역 안에 해당 클래스의 `동질성`을 측정한다.
	b. 하위 분할 영역 내의 클래스 동질성이 가장 큰 $s_j$값을 선택한다.
2. 클래스 동질성이 가장 큰 변수 $X_j$와 $s_j$ 값을 선택한다.

<재귀>
1. 전체 데이터를 갖고 $A$를 초기화한다.
2. $A$를 $A_1$와 $A_2$로 나누기 위해 `분할 알고리즘`을 적용한다.
3. $A_1$과 $A_2$ 각각에서 2.를 반복한다.
4. 더 이상 하위 분할 영역의 동질성이 개선되지 않을 정도로 충분히 분할을 진행했을 때 종료한다.

- 트리 모델은 0과 1의 이진 결과 외에도 하위 분할 영역에 존재하는 0, 1의 개수에 따라 확률값을 구할 수도 있다.

### 2. 동질성, 불순도 측정하기
- 정확도는 불순도를 측정하는 데 썩 좋지 않은 것으로 밝혀졌다.
- 대신 `지니 불순도`와 `엔트로피`가 불순도 측정 지표이다. 클래스가 2개 이상인 분류에도 적용이 가능하다.

1. `지니 불순도`
$$I(A) = p(1-p)$$
2. `엔트로피`
$$I(A) = -plog_2(p)-(1-p)log_2(1-p)$$
- $p$는 해당 파티션 내에서 오분류된 레코드의 비율이다.


- 참고)  `지니 계수Gini Coefficient`와 `지니 불순도Gini Impurity`는 다른 개념이다. 전자는 이진 분류 문제로 한정되며 `AUC 지표`와 관련 있는 용어다.

### 3. 트리 성장 멈추기
- 거대한 트리는 노이즈까지 반영하는 `작은 규칙`을 만드는 단계까지 만든다.  이러한 작은 규칙은 노이즈를 포함할 수 있기 때문에 새로운 데이터를 분류할 때 방해가 된다.
- `가지치기` : 가장 일반적으로는 **홀드아웃 데이터에서의 에러가 최소화되는 지점**까지이다. 
- 가지 성장을 멈추는 2가지 방법이 있다.
	1. **하위 영역**이나 리프 노드의 **크기가 너무 작다면 멈춘다.**
	2. 새로운 분할 영역이 `유의미`할 정도로 불순도를 줄이지 않는다면 분할하지 않는다.
		- 복잡도 파라미터`Complexity Parameter = CP` : 일종의 벌점으로 간주되어 트리 성장을 제한하는 데 사용된다. 
		- `최적의 CP 결정하기`
			1. 데이터를 훈련 - 검증용으로 나누고 훈련 데이터로 트리를 키움
			2. 트리를 단계적으로 가지치기함. 매 단계마다 `훈련 데이터`로 cp 기록
			3. 검증 데이터에 대해 최소 에러를 보이는 cp를 기록한다.
			4. 1~3을 여러번 반복한 후 각 트리에서 최소 에러를 보이는 cp값의 평균을 구함
			5. 원래 데이터를 이용해 위에서 구한 cp의 최적값을 이용해 트리를 만든다.

- 트리로 연속값 예측하기 : 불순도 측정 지표가 평균으로부터 편차값들로 바뀐다는 것과, RMSE로 예측 성능을 평가한다는 차이점만 있음.

### 4. 트리 활용하기
- 다른 모델은 `블랙박스`의 특성을 갖고 있음
- 단일 트리의 장점은..
1. **데이터 탐색을 위한 시각화가 가능**하다. 어떤 변수가 중요한지, 변수 간 관계가 어떤지 보여준다. 예측 변수 간 비선형 관계를 담을 수 있다.
2. 일종의 규칙들의 집합으로 볼 수 있기 때문에, **비전문가들과 대화하는데 매우 효율적**이다.
- 한편 `예측`의 영역에선 다중 트리를 이용하는 게 훨씬 강력하다. 
	- 대신 다중 트리에서는 단일 트리의 장점을 잃어버린다는 단점은 있다.

## 3. 배깅과 랜덤 포레스트
- 수소의 무게를 맞히는 대회에서, 다양한 예측이 나왔는데 이들의 평균과 중간값은 실제 무게에 1% 오차로 근접했다.
- 이 원리는 예측 모델에도 적용된다. `다중 모델의 평균 or 다수결 투표` 인 **앙상블 모델**은 단일 모델보다 더 나은 성능을 보인다.
- 앙상블의 가장 간단한 버전
	1. 주어진 데이터로 예측 모델을 만들고 예측 결과를 기록
	2. 같은 데이터에 대해 **여러 모델을 만들고 결과를 기록**
	3. 각 레코드에 대해 예측 결과들의 **평균(or 가중평균 or 다수결 투표)을 구함**

- 트리에 적용된 앙상블 : **랜덤 포레스트, 부스팅 트리**

### 1. 배깅
- `Bagging = Bootstrap Aggregating`
- **매번 부트스트랩 재표본에 대해 새로운 모델을 만든다.** 이거 빼곤 기본 앙상블과 동일함.
- 과정
	1. 만들 모델 수 $M$과 사용할 레코드의 수 $n$$(n<N)$을 초기화한다.
	2. 복원추출 방법으로 $n$개의 부분 데이터 $Y_m$과 $X_m$을 부트스트랩 추출한다.
	3. 의사결정규칙 $\hat{f_m}(X)$를 얻기 위해, $Y_m$과 $X_m$을 이용해 모델을 학습한다.
	4. $m = m + 1$로 반복 변수를 늘인 뒤, $m < M$이면 다시 1단계부터 ㄱ
	5. $\hat{f_m}$이 1인 경우의 확률을 예측한다면, 배깅 추정치는 $$\hat{f} = \frac{1}{M}({\hat{f_1}(X) + {\hat{f_2}(X) + ...}})$$이 된다.

### 2. 랜덤 포레스트
- 기존 DT를 만드는 과정은 모든 변수에 대해 분류 기준을 찾았다면, **랜덤 포레스트에서는 각 트리를 만들 때 변수 또한 샘플링한다.**
	- 따라서 **각 트리의 분류 기준은 랜덤하게 결정된 변수들(전체 변수의 부분집합)에서 찾게 된다.**
	- 포인트만 짚자면,
		- 각 `레코드`에 대해서는 `부트스트랩 샘플링`을 한다.
		- 각 트리의 변수는 `비복원추출`로 샘플링한다.
- 일반적으로 **전체 변수가 $P$ 개라면, 랜덤 포레스트는 $\sqrt{P}$개를 선택**한다.

#### OOB 에러
- 트리 모델을 만들 때 사용하지 않은 학습데이터를 사용해 구한 모델의 오차율

- 랜덤 포레스트는 블랙박스 모델로, 정확한 예측을 보이나 직관적인 해석은 불가능하다.
	- 예측 결과 또한 지저분한 편이다. 데이터에서 일반적이지 않은 예외 사항까지 학습해서 생기는 결과로, 오버피팅 가능성이 있다.(`편향-분산 트레이드오프`)

### 3. 변수 중요도
- 랜덤 포레스트는 피처, 레코드가 많을수록 장점을 발휘한다. 
- 어떤 예측변수가 중요한지, 이들의 **상관관계 항들에 대응되는 복잡한 관계를 자동으로 결정**하는 능력이 있다.
- 변수 중요도 측정법
	1. 변수 값이 랜덤하다면, 모델의 정확도가 감소하는 정도를 측정한다. 
		- 변수를 랜덤하게 섞는다는 것은, 해당 변수가 예측에 미치는 모든 영향력을 제거하는 것을 의미한다.
		- 정확도는 OOB 데이터에서 얻으며, CV와 같은 효과를 갖는다.
	1. 특정 변수를 기준으로 분할이 일어난 모든 노드에서 불순 점수의 평균 감소량을 측정한다. 
		- 해당 변수가 노드의 순도를 개선하는 데 얼마나 기여했는지를 나타낸다.
		- 학습 데이터로 측정되기 때문에 OOB에 비해 믿을 만하지 않다.

### 4. 하이퍼파라미터
- 학습 이전에 사용자가 직접 정해야 하는 파라미터.
- 회귀 모형에서 예측 변수들을 선택하는 게 비교적 선택 사항에 가까웠다면, **RF에서 HP는 훨씬 결정적인 영향을 미치는 중요한 요소이다.** 특히 오버피팅의 측면에서.
	1. 리프 노드의 크기 : 분류와 회귀에서 다르게 설정해야 함
	2. 전체 노드의 최대 개수 


## 4. 부스팅
- 모델들을 앙상블 형태로 만들기 위한 기법.
- 부스팅은 **이전 모델이 갖는 오차를 줄이는 방향으로 다음 모델을 연속적으로 생성**한다.
- `Adaboost, Gradient Boosting, Stochastic Gradient Boosting`이 가장 자주 사용되며, 그 중 `확률적 그래디언트 부스팅`이 가장 널리 사용된다. 실제로 파라미터만 올바르게 잘 선택한다면 랜덤 포레스트를 그대로 에뮬레이션 할 수 있다. 

### 1. 부스팅 알고리즘
- `Adaboost`
	1. 피팅할 모델 개수 $M$를 결정, 반복 횟수 $m=1$로 초기화. 관측 가중치 $w_i = 1/N$으로 초기화. 앙상블 모델 $\hat{F_0} = 0$으로 초기화.
	2. 관측 가중치값들을 이용해 모델 $\hat{f_m}$을 학습한다. 이 때 잘못 분류된 관측치에 대해 가중치를 적용한 합을 의미하는 가중 오차 $e_m$이 최소화되도록 학습한다.
	3. 앙상블 모델에 다음 모델을 추가한다. $\hat{F_m} = \hat{F_{m-1}} + \alpha_m\hat{F_m}$ //  $\alpha_m = \frac{log(1-e_m)}{e_m}$ 이다.
	4. 잘못 분류된 입력 데이터에 대한 가중치를 증가하는 방향으로 가중치를 업데이트한다. $\alpha_m$에 따라 증가 폭이 결정된다.(학습률 개념인 듯)
	5. 모델 반복 횟수가 M보다 커질 떄까지 반복한다.
	- 위 과정 결과 부스팅 추정치는 $\hat{F} = \alpha_1\hat{f_1} + \alpha_2\hat{f_2} + ... \alpha_m\hat{f_m}$이다. 
 - 잘못 분류된 데이터에 가중치를 증가시켜 현재 성능이 제일 떨어지는 데이터에 대해 더 집중해서 학습하는 효과를 가져온다. $\alpha_m$값을 이용해 모델의 오차가 낮을수록 더 큰 가중치를 부여한다.
 - `그래디언트 부스팅`에서는 가중치를 조정하는 대신 모델이 `유사잔차`를 학습시켜, 잔차가 더 큰 데이터를 더 집중적으로 학습하는 효과를 가져온다. 
 - `확률적 그래디언트 부스팅`은 매 단계마다 데이터와 예측변수를 샘플링하는 방식으로 랜덤한 요소가 추가된다.

### 2. XGBoost
- 대중적으로 가장 많이 사용되는 오픈소스 소프트웨어.
- `확률적 그래디언트 부스팅`을 구현했음.
- 직접 조절할 수 있는 다양한 파라미터가 있음. 
	- `subsample` : 각 반복 구간마다 샘플링할 입력 데이터의 비율 조정
	- `eta` : 부스팅 알고리즘에서 $\alpha_m$에 적용되는 축소 비율을 결정함
- 비복원추출로 샘플링한다는 점만 빼면 랜덤포레스트같이 동작한다.

### 3. 오버피팅 피하기
- `XGBoost`에서는 `subsample`, `eta`등으로 오버피팅을 피할 수 있다.
- 또다른 방법으로는 `정규화Regularization` 방법이 있다.
	- 모델의 **복잡도에 따라 벌점을 추가**하는 형태로 **비용함수를 변경**한다.
		- `alpha` : 맨하탄 거리
		- `lambda` : 유클리드 거리
		- 이 두 값을 크게 하면 복잡도에 따른 벌점이 커지며 결과적으로 트리의 크기가 작아진다.

- 참고 ) `Ridge`와 `Lasso`
- `Ridge` : 잔차제곱합에 회귀 계수의 개수, 크기에 따라 벌점 추가한 값을 최소화
$$\Sigma^n_{i=1}(Y_i - \hat{b_0} - \hat{b_1}X_i - ... \hat{b}X_p)^2 + \lambda (\hat{b^2_1} + ... \hat{b^2_p})$$
	- $\lambda$ 값은 계수에 대해 어느 정도 벌점을 부여할 것인가를 결정한다. **값이 클수록 모델이 데이터에 오버피팅 할 가능성이 작아진다.**
- `Lasso` : 벌점 항에 L1 Norm을 대신 이용한다.
$$\Sigma^n_{i=1}(Y_i - \hat{b_0} - \hat{b_1}X_i - ... \hat{b}X_p)^2 + \alpha(\left\vert\hat{b_1}\right\vert + ... + \left\vert\hat{b_p}\right\vert)$$
- XGBoost의 `lambda`는 `Ridge` 규제를, `alpha`는 `Lasso` 규제를 컨트롤한다.

### 4. 하이퍼파라미터와 교차검증
- 하이퍼파라미터 탐색은 교차검증으로 진행하여 각 폴드마다 각 모델에 대한 오차를 계산하여 이루어진다. 
- `XGBoost`의 하이퍼파라미터에는 아래 값들이 있다.
	- `eta` : `alpha`에 적용되는 0과 1 사이의 축소 인자. 기본값은 0.3이며 노이즈가 있다면 0.1 정도의 더 작은 값을 추천함.
	- `nrounds` : 부스팅 라운드 횟수 : `eta`가 작다면 알고리즘의 학습 속도가 늦춰지므로 라운드 횟수를 늘려야 한다. 다른 파라미터에서 오버피팅을 방지했다면 늘려도 ㄱㅊ
	- `max_depth` : 트리의 최대 깊이(기본 6). 부스팅 트리는 일반적으로 깊이가 얕다.
	- `subsample`, `colsample_bytree` : 전체 데이터에서 일부 데이터를 비복원 샘플링하는 비율 및 예측 변수 중 일부 변수를 샘플링하는 비율.
	- `lambda, alpha` : 위 참조


