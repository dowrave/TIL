- 빅데이터 시대가 되었지만 데이터의 질과 적합성을 일정 수준으로 이상 담보할 수 없는 채로 데이터의 크기가 늘어나기만 함
- **데이터 편향을 최소화하기 위한 방법**으로 표본 추출의 필요성이 더 커졌다.
- 빅데이터 프로젝트도 결국 표본 데이터로 예측 모델을 개발하고 테스트한다.

- 전통적인 통계학에서는 표본 집단으로 모집단을 추론하지만, 데이터 과학에서는 **표본 추출 과정과 주어진 데이터에 집중한다.**
	- `Random Sampling` : 무작위로 표본을 추출하는 것(`랜덤표본추출`)
		- `Simple Random Sample` : 모집단 층화 없이 랜덤표본추출로 얻은 표본
	- `Stratified Sampling` : 모집단을 층으로 나눈 뒤 각 층에서 무작위로 표본 추출`층화표본추출`
	- `Sample Bias` : 모집단을 잘못 대표하는 표본

### 표본 편향과 대표성
- 데이터 품질 = 완결성, 형식의 일관성, 깨끗함, 값의 정확성
- **대표성** : 
	- 리터러리 다이제스트 : 1000만명 vs  갤럽 : 2000명
	- 갤럽의 예측이 더 정확했음 
		- 전자는 사회경제적 지위가 높은 사람들이 대상이었고, `표본편향`이 발생했음.
			- 즉 모집단에서 유의미한 **비임의** 방식으로 표본이 뽑혔다는 것
			- `비임의` : 어떤 랜덤 표본도 모집단을 정확하게 대표할 수는 없다

- `자기선택 표본편향` 
	- 리뷰는 제출자들이 무작위로 선택되지 않았기 때문에 편향되기 쉽다.
	- 리뷰를 남기고자 하는 사람들은 안 좋은 경험이 있거나, 시설과 관련이 있거나, 리뷰를 남기지 않는 사람들과는 다른 유형의 사람들일 가능성이 높기 때문이다.
	- **상황을 파악하기 위한 지표로는 사용하기 어렵지만, 비슷한 종류의 시설과 단순 비교할 때는 더 신뢰할 만**하다. 비슷한 시설에는 같은 편향이 동일하게 적용되기 떄문이다.

### 랜덤표본추출 절차
- 가설을 구체적으로 명시하고, 랜덤표본추출 원칙에 따라 데이터를 수집하면 편향을 피할 수 있다.
1. 대상 정의
	- 무엇을 조사 대상으로 선택할 것인가? 
	- ex) 물건을 산 고객이라면, 소비 금액이 0원을 넘는 사람들이 대상일 것이다. 환불한 사람도 대상인가? 테스트 구매자도 포함? 사업자도 포함?
2. 표본추출 절차 정의
	- 무작위로 n명을 뽑는다
	- ex) 유동적인 상황(실시간 거래 고객, 웹 방문자 등)이라면 접근 시기가 중요할 수 있다(오전 10시와 오후 10시에 접속한 사람은 다른 유형일 수 있다)

#### 빅데이터가 정말 중요한 상황
- `랜덤표본추출`이 잘 이루어질수록 편향이 줄고, 데이터 탐색과 품질에 더 집중할 수 있다.
	- ex) 결측치, 특이값은 데이터가 수백만 개라면 평가하기 어렵지만 수천 개에선 가능할 수 있다.
- 빅데이터가 가치 있는 상황은 데이터가 크면서 희박할 때이다.
	- ex) 검색어 : 단어가 있으면 1, 없으면 0인 거대한 Sparse Matrix임
	- 이는 방대한 양의 데이터가 누적될 때 결과가 더 좋을 수 밖에 없다.
	- 현대 검색 기술이 유용한 점은 백만 번에 1번 발생하는 쿼리까지도 포함해 다양한 쿼리에 대해 신속하고 유용한 결과를 얻을 수 있다는 점에 있다.
	- 연관된(`Pertinent`) 레코드의 수는 수천 개 정도만 되도 효과적일 수 있다.
		- 그러나 연관된 레코드를 얻기 위해서는 수 조의 데이터 포인트가 필요하다.



### 선택 편향
`당신이 뭘 찾고 있는지 모르겠다면 더 열심히 찾아보라. 결국 찾게 될 것이다.`

<용어>
- `선택편향` : 데이터를 선택적으로 고르는 관행(의식 / 무의식)
	- 비랜덤표본추출, 데이터 체리피킹, 특정 통계효과 강조하는 시간 구간 선택, 흥미로운 결과가 나올 때 실험 중단 등
	- **모든 형태의 데이터 분석은 편향의 위험성을 늘 갖고 있다.**
- `데이터 스누핑Data Snooping` : 흥미로운 걸 찾아 광범위하게 데이터를 살피는 것
- `방대한 검색 효과 Vast Search Effect` : 중복 모델링, 너무 많은 예측 변수를 고려하는 모델링에서 비롯되는 편향, 비재현성

- 중요 ) 큰 데이터 집합을 갖고 반복적으로 다른 모델을 만들고 다른 질문을 하다보면 언젠가 흥미로운 것을 발견하게 된다 : **이건 정말 의미가 있는 걸까? 그냥 우연히 얻은 예외 경우일까?**
	- 1개 이상의 홀드아웃`holdout` 세트로 이를 방지할 수 있다.
	- `목푯값 섞기Target Shuffling`

#### 평균으로의 회귀
- 주어진 변수를 연속적으로 측정했을 때 나타나는 현상
- 예외적인 경우가 관찰되면 그 다음에는 중간 정도의 경우가 관찰되곤 한다. 따라서 **예외를 너무 특별하게 생각하고 의미를 부여하는 건 선택 편향으로 이어질 수 있다.**
	- ex) 소포모어 징크스 : 신인왕이 다음 해에 부진한 경우
		- 실력 + 행운 중,  행운은 꾸준하지 못한 경우가 많다.

#### 표본 분포
- 모집단에서 표본을 뽑을 때 표본마다 결과가 달들 것
- 따라서 표본의 변동성`Sampling Variability` 이 중요하다.

**`중심극한정리`**
- **표본 통계량의 분포는 데이터 자체의 분포보다 규칙적이고 종 모양일 가능성이 높다.**
- 표본크기가 충분하고 데이터가 정규성을 크게 이탈하지 않는다면!
- 이 덕분에 추론을 위한 표본 분포 : 신뢰구간이나 가설검정 계산 등에 t 분포 같은 정규근사 공식을 이용할 수 있다.
- **통계학에서 매우 중요함** : 가설검정, 신뢰구간에 대한 밑바탕이기 떄문
	- 데이터과학에서는 상대적으로 덜 중요함 : `부트스트랩`을 사용할 수 있기 때문이다.

`표준오차` (`!= 표준편차`)
- `표준편차`를 `표본 크기의 제곱근` 으로 나눈 값
- 고려할 사항
	1. 모집단에서 완전히 새로운 샘플들을 많이 수집한다
	2. 각 새 샘플에 대한 통계량을 계산한다
	3. 2단계에서 얻은 통계량의 표준편차를 계산하고, 표준오차의 추정치로 사용한다.
- `표준편차`는 개별 데이터의 변동성을 측정한다.
- `표본오차`는 표본 측정 지표의 변동성을 측정한다.
- **부트스트랩을 이용하면 중심극한 정리에 의존하지 않고 모든 통계에 사용할 수 있다. 아래 참고**

## 부트스트랩(중요)
- 현재 있는 표본에서 추가적으로 표본을 복원추출하고, 각 표본에 대한 통계량과 모델을 다시 계산함
	- 데이터나 표본통계량이 정규분포를 따라야한다는 가정 자체가 필요 없다.
	- 개념 ) 표본을 수천, 수백만번 복제하는 것
		- 이를 통해 가상의 모집단을 얻을 수 있고, 이 가상 모집단에서 표본 분포를 추정할 목적으로 표본을 수집할 수 있다.
- 알고리즘
	1. 샘플을 하나 뽑아 기록 후 복원
	2. n번 반복
	3. 재표본추출된 값의 평균 기록
	4. 1~3을 R번 반복
	5. R개의 결과를 이용해
		1. 그것들의 표준편차(=표본평균의 표준오차) 계산
		2. 히스토그램, 상자 그림을 그린다
		3. 신뢰 구간을 찾는다.
	- R은 임의로 설정하며, 반복 수가 많을수록 표준오차나 신뢰구간 추정이 정확해진다.

- `배깅` : `DT`를 사용해 **부트스트랩 샘플 여러 개로 트리를 여러 개 만든** 다음, **각 트리의 예측값을 평균(분류라면 과반수 투표)**내는 게 단일 트리보다 효과적이다.
- 부트스트랩의 목적 : 표본크기 보완 X / 새 데이터 만들기 X / 기존 데이터 보완 X
	- 단지 **모집단에서 추가 표본을 뽑을 때 그 표본이 원본과 얼마나 비슷할지**를 알려줌
- `재표본추출`
	- 여러 표본이 결합되어 비복원추출을 수행
	- vs 부트스트랩 : 부트스트랩은 항상 관측된 **데이터로부터 복원추출**함

### 신뢰구간
- `신뢰수준Confidence Level` : 같은 모집단으로부터 같은 방식으로 얻은,  신뢰구간의 백분율
- `구간끝점Interval Endpoint` : 신뢰구간의 최상위, 최하위 끝점

- 구하는 법(부트스트랩)
1. 데이터에서 복원추출 방식으로 크기 n인 표본을 뽑는다(재표본추출)
2. 재표본추출한 표본에 대해 원하는 통계량을 기록한다
3. 1 ~ 2 단계를 R번 반복한다.
4. x% 신뢰구간을 구하기 위해, R개의 재표본 결과로부터 분포의 양쪽 끝에서 `[(100 - x) / 2]%` 만큼 잘라낸다.
5. 절단한 점들은 `x%` 부트스트랩 신뢰 구간의 양 끝점이다.

### 정규분포
- `오차` : 데이터 값과 예측값(or 평균값)의 차이
- `표준화(정규화)` : 평균을 빼고 표준편차로 나눈다.
	- 척도만 동일하게 할 뿐, 데이터가 정규분포가 되지는 않는다. 정규분포에 대고 비교할 수 있게 만드는 것임.
- `z-score` : 개별 데이터 포인트를 정규화한 결과
- `표준정규분포` : N(0, 1)
- `QQ-plot` : 표본 분포가 정규 분포에 얼마나 가까운지 보여주는 그림

- **대부분의 원시 데이터는 전체적으로 정규 분포를 따르지 않는다.** `표본분포에서 대부분 통계량이 정규분포를 따른다는 점에서 정규분포의 유용함`이 드러난다. (중심극한정리와 연관이 있다)
- QQ그림은 데이터가 정규분포와 얼마나 연관이 있는지를 보여준다.  편차가 작을수록 y=x 플롯에 붙음

### t-분포
- 표본평균의 분포는 일반적으로 t-분포와 같은 모양이다
- 표본 크기에 따라 다른 계열의 t-분포가 있다. 클수록 더 정규분포를 닮은 t-분포가 형성된다.
$$\bar{x} \pm t_{n-1}(.05) \times {\operatorname{t}\over\sqrt{n}}$$
- $t_{n-1} (.05)$값은 (n-1) 자유도를 갖는 t분포의 양쪽 끝에서 5%를 잘라내는 t 통계량을 의미한다.
- t 분포는 표본평균, 두 표본평균 간 차이, 회귀 파라미터, 그 외 통계량들의 분포를 구할 때 t 분포를 사용한다.

- 데이터과학자가 t분포와 중심극한정리에 대해 알아야할 건 사실 별로 없다.
- 데이터과학자에게는 불확실성과 변동성을 이해하고 정량화하는 것이 중요하기 떄문이다. 
	- 경험적 부트스트랩 표본추출을 통해서도 표본 오차에 대한 대부분의 질문에 답을 얻을 수 있다.
	- 그러나 통계 소프트웨어나 A-B 테스트, 회귀분석 등의 통계 절차를 통한 t-통계량을 보게 되기 때문에 알아둘 필요가 있다.

### 이항분포
- 시행마다 성공확률(`p`)이 정해져있을 때 시행 횟수(`n`) 중 성공한 횟수(`x`)의 도수분포를 의미함
- 이항분포로 답하고자 하는 질문은 `1번의 클릭이 판매로 이어질 확률이 0.02일 때 200회 클릭으로 0회 매출을 관찰할 확률은?` 같은 것이다.
- 이항분포의 평균은 `np`, 분산은 `np(1-p)`이다. 
	- 시행횟수가 충분한 경우 정규분포와 구별이 어렵다. 
	- 대부분 평균과 분산으로 근사화한 정규분포를 사용한다.

### 그 외 분포
용어)
- 포아송 분포`Poisson Distribution` : 단위 시간, 공간에서 발생한 사건의 도수분포
	- `lambda` :단위 시간 / 면적당 사건 발생 비율
- 지수 분포`Exponential Distribution` : 한 사건 -> 그 다음 사건까지의 시간, 거리에 따른 도수분포
	- 똑같이 `lambda`값을 이용함
	- 예) 고장 발생 시간, 개별 고객 상담 소요 시간 모델링
- 위 두 분포에서 핵심은, **`lambda`가 해당 기간 동안 일정하게 유지된다**는 가정이다.
	- 전반적으로 적절하지 않은 가정임. 그러나 **시간 주기나 공간을 일정 기간 동안 충분히 동일하도록 영역을 잘 나눈다면 분석, 시뮬레이션이 가능**하다.

- 베이불 분포 : 사건 발생률이 시간에 따라 변화하는 지수 분포의 일반적인 버전
	- 사건 발생률이 시간에 따라 지속적으로 변한다면, 지수 또는 푸아송 분포는 더 이상 유용하지 않다. 
	- `형상 파라미터` $\beta$ 
		- 1보다 크면 시간이 지남에 따라 사건 발생률이 증가, 
		- 1보다 작으면 시간이 지남에 따라 사건 발생률 감소
	- 주로 고장 시간 분석에 사용되므로 2번째 인수는 특성 수명으로 표현되며, $\eta$ 로 표현된다.
	- $\beta$와 $\eta$ 가 사용되므로 주로 소프트웨어를 사용한다. 

### 마무리
- 정확한 추정이 요구되는 경우 랜덤표본추출의 원칙을 지키는 게 매우 중요하다.
	- 무작위 선택은 주어진 데이터를 그냥 쓰는 것보다 편향을 줄이고 실험적으로 더 좋은 데이터를 얻을 수 있다.
	- 다양한 표본 추출 및 데이터 생성 분포에 대한 지식을 바탕으로, 랜덤 변이로 인한 추정치의 잠재적 오차를 정량화할 수 있다.
- **부트스트랩은 표본 추정에서 잠재적 오차를 판별할 때 유용한 모든 문제에 적용 가능한 방법**이다.

