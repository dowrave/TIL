- `실험설계` : 어떤 가설을 기각하거나 확인하기 위해 진행됨
- 전형적인 통계 추론 과정
	- **가설 설정 -> 실험 설계 -> 데이터 수집 -> 추론 및 결론 도출**

### A/B 검정
- 실험군을 두 그룹으로 나누어 진행하는 방법
- 종종 아무런 처리를 진행하지 않는 그룹을 `대조군`이라고 한다.
	- `검정통계량Test Statistic` : 처리 효과를 측정하기 위한 지표
- 웹 디자인, 마케팅에서 일반적으로 사용된다.
	- 웹 : 디자인, 제품 가격, 헤드라인 어감 등
	- 주의) 웹에서 접할 수 있는 여러 조언에 주의하자 : ex) 1000명을 기다리고 1주일 동안 실행하시오 -> 통계적으로 의미가 없을 수 있음
- 피험자는 **무작위로 어느 처리에 할당**된다.
	- 이렇게 다른 그룹이 생기면, 그룹 간 차이가 생기는 이유는 다음 2가지 중 하나일 것이다.
		1. 다른 **처리의 효과**
		2. 어떤 대상이 어떤 처리에 배정되는가에 대한 경우의 수(무작위로 뽑았음에도 **우연**에 의해 어떤 대상들이 한쪽으로 집중되는 현상)
	- `검정통계량` 또는 `측정 지표`에 주의해야 한다.
		- 일반적인 지표는 `클릭 여부`, `구매 여부`, `사기Fraud 여부` 등이 있다.
- 대조군은 왜 필요한가?
	- `특정 조건`이 미치는 영향을 확인하기 위해 기준이 되어야 할 다른 그룹이 필요하다.
	- "이전 경험"과 비교할 경우, 지금 하는 실험과 다른 요소가 발생할 수 있기 때문이다.
- **테스트 이전에 미리 하나의 측정 지표를 결정해야 한다.**
	- 나중에 결정할 경우, `연구자 편향`이라는 함정에 빠질 수 있다.

### 가설 검정`Hypothesis Test` = 유의성 검정`Significance Test`
- 관찰된 **효과가 우연에 의해 발생했는가**를 알아내는 것
- 왜 가설이 필요한가?
	- 임의성을 과소평가하는 인간의 경향이 있기 때문이다. 
		- 동전을 50번 던졌다면
			1. 앞면이 5번 연속 나왔다면 **다음엔 뒷면이 나올 차례**라고 스스로 주문을 걺
			2. 앞면이 5번 연속 나온 게 **단순한 우연은 아닐 것이라고 생각하는 경향**이 있음
	- 무작위 사건을 어떤 중요한 의미가 있는 패턴을 갖는 것으로 오해하기도 한다.
	- **통계적 가설 검정**은 연구자가 **우연히 일어난 일에 속지 않도록 보호하기 위한 방법**으로 개발되었다.
- 적절하게 설계된 A/B 검정에서는 관찰된 차이가 다음 원인들로 설명될 수 있도록 데이터들을 수집한다.
	- 우연한 대상 선정
	- A와 B의 진정한 차이

#### 귀무가설(H0)
- 가설 검정의 논리 : "인간은 우연히 일어난 일을 우연이 아닐 것이라고 해석하는 경향이 있다. 따라서, **실험에서 얻은 그룹 간의 차이가 무작위성을 통해 얻을 수 있는 합리적인 수준과는 더 극단적으로 달라야 한다는 증거**를 보여야 한다."
- 즉, `귀무가설`이 틀렸음을 입증해서 그룹 간의 차이가 우연이 아님을 보여주는 것이다.

#### 대립가설(H1)
- **가설 검정은 귀무가설 + 대립가설을 포함**하며, 이 **두 가설이 모든 가능성을 설명할 수 있어야 한다**.

#### 일원/이원 가설검정
- 새로운 옵션(B)이 나와 테스트를 한다고 할 때, 기존 옵션(A)과 비교할 수 있다.
- 이 떄 가정은 B가 더 나은 옵션이라고 입증되지 않는 이상 A를 계속 사용한다는 것이다.
- `일원 가설 검정` : B는 A보다 낫다 
	- 우연에 의한 극단적인 결과에 대해 한 방향만을 고려한다.
- `이원 가설 검정` : A는 B와 다르며, 더 크거나 작을 수 있음
	- 우연에 의한 극단적인 결과가 양쪽에서 나타날 수 있다.
- 원래 옵션이 기본값으로 지정되어 있는 A/B 검정은 `일원 가설 검정`과 어울린다.
- 일반적으로 S/W는 `이원 가설 검정`이 디폴트이며, 전문가들도 좀 더 보수적인 `이원`을 선호한다.
- 근데 **`p-value`의 정확성이 데이터 과학에서는 일원 / 이원 여부가 그렇게 중요하지 않다**

### 재표본추출
- 관찰한 데이터의 값에서 표본을 반복적으로 추출함
	- ex) `Bagging Of Decision Tree`
- `부트스트랩`과 `순열검정`이라는 2가지 유형이 있다.
	- `부트스트랩`은 [[2장 - 데이터와 표본 분포]]에서 다뤘음. 추정의 신뢰성 평가에 이용한다.

#### 순열검정
- `순열` : 2개 이상의 표본이 관여됨. 
- 과정 (`랜덤 셔플링 = 임의순열검정`)
	1. 여러 그룹을 단일 데이터 집합으로 합친다.
	2. 결합된 데이터를 섞고, 그룹 A와 동일한 크기의 표본을 무작위(& 비복원) 추출한다.
	3. 나머지 데이터에서 그룹 B와 동일한 크기의 표본을 무작위(& 비복원) 추출한다.
	4. 다른 그룹들에도 동일한 작업을 수행한다.
	5. 원래 샘플에 대해 구한 통계량, 추정치가 무엇이었든, 지금 추출한 재표본에 대해 모두 다시 계산하고 기록한다.
	6. 1~5를 R번 반복해 검정 통계량의 순열 분포를 얻는다.
- 새로운 그룹들의 차이(재표본)가 기존 그룹들의 차이에 들어가 있다면 관찰된 차이는 우연에 의해 일어날 수 있는 범위 내에 있다는 뜻이다.
- 한편, 관찰된 차이가 순열 분포 밖에 있다면 우연 때문이 아니라고 결론내릴 수 있다. 이를 통계적으로 유의미하다`Statistically Significant`고 표현한다.
- `대리변수 Proxy Variable` : 참된 관심 변수를 대신하는 변수.

- 예제 ) A/B 테스트 결과, 페이지 B가 방문객들을 21.4초 더 웹에 붙잡아뒀다고 하자. 이 차이가 우연에 의한 것인지 통계적으로 중요한 것인지 판단할 필요가 있다.
- 그룹 A는 21세션, 그룹 B는 15세션이라고 하자.
	- 이 떄 순열 검정을 적용할 수 있다. 모든 세션 시간을 결합한 뒤, 21개의 그룹과 15개의 그룹으로 반복하여 표본을 추출한다.
	- 이 추출된 표본 간 세션 시간의 차이를 계산하고, 다시 비복원 추출을 R번 반복하면 세션 시간 차이에 대한 히스토그램을 얻을 수 있다.
	- 이 히스토그램의 분포 내에 실제 관찰된 세션 시간의 차이가 들어간다면, 이는 확률 분포의 범위 내에 들어가 있음을 의미한다. 따라서 실제 관찰된 값이 통계적으로 유의미하지 않게 된다.

다른 순열 검정도 있다 : 
- `전체순열검정Exhaustive Permutation Test` 
	- 데이터를 무작위로 섞고 나누는 대신, **실제로 나눌 수 있는 모든 가능한 조합**을 찾는다.
	- `임의순열검정`에 비해 더 정확한 결론을 보장하기 때문에 `정확검정`이라고도 한다.
- `부트스트랩 순열검정Bootstrap Permutation Test`
	- `임의순열검정`의 2, 3단계에서 비복원추출 대신 복원추출로 하면 된다.
- 둘 모두 통계학에서 자주 나오지만, **데이터 과학 입장에선 별로 실용적이지 않다.**

#### 데이터과학에서 순열검정에 대한 결론
- **순열검정**은 랜덤한 변이가 어떤 역할을 하는지 알아보기 위해 사용되는 휴리스틱한 절차이다.
- **코딩, 해석, 설명이 쉽다.** 
- 리샘플링의 장점 중 하나는 "모두에게 맞는" 접근 방식이라고 할 수 있다는 점이다. 
	- 데이터의 형태(숫자, 이진) 모두 쓸 수 있음
	- 샘플 크기가 달라질 수도 있음
	- 데이터가 정규분포를 따라야 한다는 가정도 필요 없음

### 통계적 유의성과 p값
- `통계적 유의성` : 실험자가 자신의 실험 결과가 우연히 일어난 건지, 우연히 일어날 수 없는 극단적인 것인지 판단하는 방법.
	- 즉 우연히 일어날 수 있는 변동성의 바깥에 실험 결과가 존재한다면 통계적으로 유의하다고 할 수 있다.
- 용어
	- `p-value` : 귀무가설을 구체화한 모델이 주어졌을 때 관측된 결과처럼 특이하거나 극단적인 결과를 얻을 확률
	- `alpha` : 의미 있는 것으로 간주되기 위해, 우연에 의한 기회 결과가 능가해야 하는 비정상적인 가능성의 임계 확률
	- `type I error` : 우연에 의한 효과가 실제 효과라고 잘못 결론 내리는 것
		- 보통은 **1종 오류를 최소화하도록 가설을 설계**한다.
	- `type II error` : 실제 효과를 우연에 의한 효과라고 잘못 결론 내리는 것
		- 실제론 오류라기보다는 표본 크기가 너무 작아 효과를 알아낼 수 없다고 판단하는 것과 같다. 
		- 예를 들면 p값이 5%를 초과했다면(= 통계적 유의성에 미치지 못했다면) 그 의미는 `효과가 아직 입증되지 않았다`이다. 표본이 클수록 p값이 작아진다.

- 예시)  (옵시디언 서드파티 - Advanced Table 적용)
| 결과   | 가격 A | 가격 B |
| ------ | ------ | ------ |
| 전환   | 200    | 152    |
| 전환 X | 23539  | 22406  | 

- 전환율을 비교했을 때, 가격 A는 가격 B보다 약 5%(0.0368%p) 우수했다.
- 근데 표본 크기에 매우 중요한 값은 전체 데이터 수에 비해 매우 적음(200개 내외)
- 이 때 재표본추출 절차가 매우 유용할 수 있다.
	1. 모든 표본을 담는다. (45945개의 전환 X와 382개의 전환 O 데이터이며, 0.8246%)
	2. 크기 23739와 22558의 표본을 무작위로 뽑고,  그 중 전환O의 데이터 수를 기록한다.
	3. 2.의 두 표본 간 비율 차이를 기록한다.
	4. 이를 반복한다.
	5. 얼마나 자주 0.0368% 보다 우수한 값이 나오는가?

#### p-value
- 그래프를 일일이 그리는 것보다, `p-value`와 같이 정확히 측정하기 위한 지표가 필요하다.
- `p-value`는 확률 모형이 관찰된 결과보다 더 극단적인 결과를 만드는 빈도이다.

#### 유의수준
- 통계학계에선 임계값을 미리 지정하는 것을 선호한다.
- 미리 지정된 임계값이 `유의수준 = alpha`이다. 
	- 통상 `5%`와 `1%`가 많이 쓰인다.
	- 올바른 유의 수준을 보장하는 프로세스는 없다.
- 의미 : "우연히 일어날 확률"이 아니라, "**랜덤 모델이 주어졌을 때 극단적인 결과가 나올 확률"을 판단**하기 때문이다.
	- 즉 랜덤 모델의 적합도를 역으로 추적하는 것이고, 그에 대한 판단은 확률로 나타나지 않는다

#### p-value의 의미
- p값이 실제로 전달하는 것은 "**랜덤 모델이 주어졌을 때, 그 결과가 관찰된 결과가 더 극단적일 확률**"이다. 
- 사람들이 흔히 "**결과가 우연에서 비롯될 확률**"로 심지어는 학계에서조차 오해한다.
- 심지어 통계 협회에선 이런 원칙까지 나왔다.
	1. p값은 이 데이터가 특정 통계 모델과 상반된 정도를 나타낼 수 있다.
	2. p값은 연구 가설이 사실일 확률과 데이터가 랜덤하게 생성되었을 확률을 측정하는 게 아니다.
	3. **과학적 결론, 비즈니스 , 정책 결정은 p 값이 특정 임계값을 통과하는지 여부를 기준으로 해선 안된다.**
	4. 적절한 추론을 위해선 완전한 보고와 투명성이 요구된다.
	5. p값이나 통계적 유의성은 효과의 크기나 결과의 중요성을 의미하지 않는다.
	6. p값 자체는 모델, 가설에 대한 증거를 측정하기 위한 좋은 지표가 아니다.

#### 데이터 과학에서의 p값
- 관심 있고 유용한 모델의 결과가 일반적인 랜덤 변이의 범위 내에 있는지를 알고 싶을 때 유용한 지표.
- **모든 실험에서 의사 결정을 좌우하는 도구로 쓰여서는 안된다.** 어떤 결정에 관련된 일부 정보일 뿐이다.
	- 예를 들면 p값을 통해 머신러닝 모델에 입력으로 들어갈지 말지를 결정할 수 있다.

### t-검정
- `검정 통계량Test Statistic` : 관심의 차이, 효과에 대한 측정 지표
- `t-통계량` : 표준화된 형태의 검정 통계량
- `t-분포` : 관측된 t 통계량을 비교할 수 있는 기준 분포 (H0에서 파생)

- 모든 유의성 검정은 `검정 통계량`을 지정하고, 관찰된 효과가 정상적인 `랜덤 변이`의 범위 내에 있는지 판단하는 데 도움을 준다. 
- 데이터를 표준화하여 표준 t 분포와 비교할 수 있는데, 통계 소프트웨어들에 다 있다. 파이썬에는 `scipy.stats.ttest_ind`에 있는 듯.
- 컴퓨터가 널리 보급되기 전에는 재표본 검정이 실용적이지 않았음
	- 이 때 사용된 게 표준적인 분포였고, 널리 사용되는 것 중 하나가 `t-분포`임

#### 다중 검정
- ex) 임의로 생성된 20개의 데이터가 있고, 그 중 하나가 **임의로 생성된 타겟값**이라고 가정하자
	- 이 때 1종 오류(의미가 없는 걸 의미가 있다고 결론을 내림)가 발생할 확률은 0.05
	- 시행횟수가 20번이라고 하면, 모든 "무의미하다"라는 결론을 내릴 확률은 $1-0.95^{20} = 0.64$이다. 
- 이는 `오버피팅` : 모델이 잡음까지 학습하는 문제와 관련이 있다. 
	- 변수가 많을수록 우연을 유의미하다고 판단할 확률이 커진다.
- 지도학습에서는 이런 확률을 낮추기 위해 `홀드아웃 세트`를 이용해, 이전에 보지 못했던 데이터로 모델을 평가한다. 이를 쓰지 않으면 지속적으로 통계적 잡음에 근거한 결론을 내리게 된다. 
	- `홀드아웃 = train_test_split()`  훈련 세트와 테스트 세트를 분리하는 것
		- 더 나아가 검증 세트를 분리하는 것도 포함하는 것 같은데 검증 세트는 하이퍼파라미터 판단할 때 쓰는 거 아니었나?

#### 자유도
- 표본 데이터에서 계산된 통계량에 적용됨. 변화가 가능한 값들의 개수를 나타낸다.
	- ex) 10개의 값으로 이뤄진 표본에서 평균 + 9개의 값을 안다면 나머지 1개의 값은 자연스럽게 알 수 있다.
- 많은 통계 검정에서 입력으로 주어지는 값이다. 분산, 표준편차에 대한 계산에서 분모의 `n-1`을 자유도라고 부른다. (**`n-1`을 사용하면 표본 -> 모집단 추정값에 편향이 발생하지 않는다는 게 알려져있다.**)
##### 데이터과학에서의 자유도
- 유의성 검정 측면에선 **그리 유용하지 않은데**, 
1. **통계 검정이 데이터 과학 분야에서 드물게 사용된다**는 점
2. **데이터 크기가 충분히 커서 n이나 n-1이나 큰 차이가 없다**
는 2가지 이유 떄문이다.
- 그러나 `회귀`에서 `요인 변수(Factor Variable)`를 사용할 때는 관련성이 있다.
	- ex) 1주일은 7일이지만 요일을 지정할 때 자유도는 6이다(6개의 요일을 지정한다면 나머지 1개의 요일은 자유가 없이 지정하게 됨).

### 분산분석(ANalysis Of VAriance = ANOVA)
 - 여러 그룹 간의 통계적으로 유의미한 차이를 검정하는 통계적 절차
 - ex) 4개의 웹 페이지에 대한 방문자가 페이지에서 보낸 시간을 측정한다고 하자. 
	 - 이 때 4개의 그룹을 비교해야 한다면, 2개씩 비교한다고 했을 때 경우의 수가 6가지가 된다.
	 - 그런데 비교하는 횟수가 증가할수록 우연에 속을 가능성이 커진다.
	 - 이 때 `총괄검정`을 이용할 수 있다. "모든 케이스가 동일하고, 각각의 차이는 우연에 의한 것인가?"
 - `ANOVA 재표본추출 과정`
	1. 모든 데이터를 한 상자에 모은다.
	2. 5개의 값(각 그룹의 크기)을 갖는 4개의 재표본을 섞어 추출한다
	3. 각 그룹의 평균을 기록한다
	4. 네 그룹 평균 사이의 분산을 기록한다
	5. 2~4를 여러번 반복한다
	- 여기서 재표집된 분산이 관찰된 변화를 초과한 시간이 `p-value`이다.
#### F-통계량
- 잔차 오차로 인한 분산과 그룹 평균의 분산에 대한 비율을 기초로 한다. 비율이 높을수록 통계적으로 유의미하다.
- 내용이 좀 빡센데?

### 카이제곱검정
- `A/B테스트`를 넘어 종종 여러 처리를 한번에 테스트할 필요가 있다.
- `카이제곱검정chi-square test`은 횟수 관련 데이터에 주로 쓰이며 예상 분포에 얼마나 잘 맞는지를 검정한다.
-----------------
- 헤드라인 예시
|        | 헤드라인 A | 헤드라인 B | 헤드라인 C |
| ------ | ---------- | ---------- | ---------- |
| 클릭   | 14         | 8          | 12         |
| 클릭 X | 986        | 992        | 988        | 
- 각각 1.4%, 0.8%, 1.2%로 A는 B보다 거의 2배의 클릭을 유도했다고 할 수 있다.
- `재표본추출`을 통해, 클릭률이 우연히 발생한 것보다 유의미한 정도로 큰 것인지 검정할 수 있다.
	- 이 검정에 필요한 건 클릭의 `기대분포`이며, 이 때 귀무가설은 "각 헤드라인 모두가 동일한 클릭률을 갖는다"는 가정이다.
- <귀무가설 테이블 : 모든 헤드라인은 동일한 클릭률을 갖는다>
|        | 헤드라인 A | 헤드라인 B | 헤드라인 C |
| ------ | ---------- | ---------- | ---------- |
| 클릭   | 11.33      | 11.33      | 11.33      |
| 클릭 X | 988.67     | 988.67     | 988.67
- 위의 각 column에 속하는 값들을 모두 합친 다음 3으로 나눈 평균값 테이블이다.
- `피어슨 잔차Pearson Residual`  $$R = {관측값 - 기대값 \over \sqrt {기댓값}} $$
- 피어슨 잔차 테이블
|        | 헤드라인 A | 헤드라인 B | 헤드라인 C |
| ------ | ---------- | ---------- | ---------- |
| 클릭   | 0.792      | -0.990     | 0.198      |
| 클릭 X | -0.085     | 0.106      | -0.021

- `카이제곱통계량` : 피어슨 잔차들의 제곱합
$$ \chi^2 = \sum_{i}^{r}\sum_{j}^{c}R^2$$
- $r$, $c$는 각각 행, 열의 수를 의미한다. 이 경우 카이제곱 통계량은 1.666이다.
- 이 값이 귀무가설로부터 얻을 수 있는 함수보다 큰가? 이는 재표본추출 알고리즘으로 검정할 수 있다.
	`재표본추출 알고리즘`
	1. 34개의 클릭한 경우와 2966개의 클릭하지 않은 경우가 들어있는 상자를 만든다
	2. 1000개의 표본을 3번씩 무작위로 가져온 뒤 각각의 클릭 수를 계산한다
	3. 이렇게 얻은 클릭 수와, 기대 클릭 수의 차이를 제곱해서 합산한다
	4. 2~3단계를 1000번 반복한다
	5. 재표본추출을 통해 얻은 편차의 제곱합이 **얼마나 자주 관측값을 초과**하는가? 이게 p값이다.
- (책) `R`에서는 `chisq.test` 함수로 이를 계산한다.
- `Python`에서는 `scipy.stats`의 `chisquare(관찰값, f_exp = 기댓값)`을 쓴다
-------------------
#### 피셔의 정확검정
- 사건 발생 횟수가 매우 낮을 경우에도 재표본추출 방법으로 정확한 p값을 얻을 수 있다. 
- 근래의 대부분의 통계 소프트웨어에서는 모든 조합(순열)을 실제로 열거하고, 빈도를 집계하고, 관찰된 결과가 얼마나 극단적으로 발생할 수 있는지를 정확하게 결정하는 절차를 제공한다. 이를 `피셔의 정확검정`이라고 한다.
- `Python`에서는 `scipy.stats`의 `fisher_exact(table, alternative = 'two-sided')`로 제공됨.

### 데이터과학과 카이제곱, 피셔의 관계성
- 데이터과학에서 대부분의 실험 목표는 **최적의 처리 방법을 찾는 것**이다.
- 이를 위해서는 Multi-Armed Bandit 방법이 더 정확한 해결책이라고 할 수 있다.
- 그러나 카이제곱, 피셔의 정확 검정을 활용하는 예도 있다. **웹 실험에서 적합한 표본의 크기를 판별하는 일**이다.
	- **클릭률이 매우 낮기 때문에 수천 번의 실험에도 집계 비율이 너무 낮아** 실험을 통해 확실한 결론을 내리기 어려운 상황
	- 이 때 피셔의 정확검정, 카이제곱검정 등은 검정력이나 표본 크기를 계산하는데 유용할 수 있다.

## 멀티암드 밴딧 알고리즘(MAB)
- 명시적인 **최적화와 더 빠른 의사 결정**을 가능하게 함
---------------------
<용어>
- `멀티암드 밴딧` : 고객이 선택할 수 있는 손잡이가 여러 개인 가상의 슬롯머신. 각 손잡이는 각기 다른 수익을 가져다준다.
- `손잡이` : 실험에서 어떤 하나의 처리
- `상금(수익)` : 슬롯머신으로 딴 상금에 대한 비유 (`고객의 링크 클릭 수`)
------------------
`A/B 테스트`는 두 처리 방법 중 어느 쪽이 더 좋은가?에 대한 답을 준다.   
그러나 몇 가지 어려움이 있을 수 있다.
1. 결론을 내리기 어려울 수 있다
	- 실험 결과, 효과가 있다는 걸 "유추"할 수는 있지만, 입증할 만한 크기의 표본이 없을 수 있다.
2. 실험이 끝나기 전에 이미 얻은 결과를 이용하기 시작할 수도 있다.
3. 실험이 끝난 뒤 들어오는 데이터를 기반으로 다른 걸 시도하고 싶을 수도 있다.
- 실험, 가설검정에 대한 전통적인 방법은 현대의 컴퓨터 성능 & 소프트웨어가 출현하기 전에 나온 것으로 유연하지 않다. **데이터 과학과 비즈니스 전반**에는 통계적 유의성보다는 **제반 비용과 결과를 최적화**하는 데 더 관심이 있다.

- 목표는 가능한 많은 이익을 얻는 것이고, 그 중에서도 **어떤 손잡이가 많은 이익을 주는지 가능한 빨리 확인하는 것**이다.
	- 그러나 **이익을 얼마나 주는지는 손잡이를 당겨보지 않는 이상 모른다**.

- 가정) 어떤 손잡이를 택하든 금액은 모두 같으나 확률이 다름
	- ex1) 3개의 선택지를 골랐을 때 각각 50번씩 시도했고 그 중 A의 당첨률이 가장 높았다면, `A만을 고르는 게` 합리적일 것이다. 그러나 실제로 B나 C의 확률이 더 높았다면, 이 사실을 **발견할 기회를 놓치게 된다.**
	- ex2) 모두가 무작위인 것 같으니 `똑같이 고르자` : 다른 것들의 확률을 알 수 있는 **최대한의 기회가 제공**되지만, **수익이 낮을 것으로 예상되는 행위 또한 지속**된다.
	- 두가지 모두 극단적인 예시임

- MAB는 하이브리드 접근 방식을 취한다.
	- 당첨률이 가장 높은 걸 계속 당기되, 다른 것들을 포기하진 않는다.
	- 실험이 지속되며 **성과가 변동하면, 그 성과의 변동에 따라 기회의 수도 변동한다.**
	- ex) A > B > C 순이었다가 B의 당첨률이 올라가면 B>A>C로 바뀔 수도 있는 것임

- 그렇다면 기회 수에 대한 파라미터는 무엇이 되어야 하는가?

- `앱실론 - 그리디 알고리즘` : A/B 테스트를 위한 간단한 알고리즘
	1. 0부터 1 사이의 난수 생성
	2-1. 이 숫자가 0과 $\epsilon$ (0과 1 사이의 값, 매우 작음) 사이에 존재하면 5:5 확률로 동전 뒤집기를 시행
	2-2 . 앞면이면 제안 A를 표시, 뒷면이면 제안 B를 표시
	1. 숫자가 $\epsilon$보다 크면 지금까지 가장 좋은 결과를 보인 제안을 제시한다.
- 따라서 **이 알고리즘은 $\epsilon$ 으로만 제어**된다.
	- 값이 1이라면  `A/B 테스트 : 실험자를 무작위로 A or B에 할당` 
	- 값이 0이라면 `그리디 알고리즘 : 알려진 가장 좋은 제안에만 할당`이 된다.

- 더 나아가면 `톰슨의 샘플링`이라는 게 있음
- 각 단계마다 표본을 추출, 연속적인 추출을 통해 얻는 수익을 관찰함
- `베이지언 방식` 을 사용한다.
	- `베타 분포 : 베이지언 문제에서 사전 정보를 이용하는 일반적인 매커니즘`를 사용해 수익의 일부 사전 분포를 가정한다. **추출 정보가 누적되면서 정보가 업데이트되기 때문에, 최고 손잡이를 선택할 확률을 효과적으로 최적화**할 수 있다.

### 검정력과 표본 크기
--------------------------------

<용어>
`효과 크기Effect Size` : 통계 검정을 통해 판단할 수 있는 효과의 최소 크기  
`검정력Power` : 주어진 표본 크기로 주어진 효과 크기를 알아낼 확률
`유의수준Significance Level` : 검증 시 사용할 통계 유의수준  

---------------------

- 표본크기에 대한 고려는, "가설 검정이 실제로 처리 A와 B의 차이를 밝혀낼 수 있을까?"라는 질문과 연결된다. `가설 검정의 결과 : p값`은 A와 B 사이에 실제 차이가 있는지에 따라 달라진다.
	- ex) 3할5푼 타자와 2할 타자를 구분하기 위해 많은 타석이 필요하진 않지만, 3할 타자와 2할 8푼타자를 구분하기 위해선 더 많은 타석 정보가 필요할 것이다.
- `검정력` : 특정 `표본조건`에서 특정한 `효과크기`를 `알아낼 수 있는` 확률을 의미한다. 
	- ex) 25타석`표본조건`에서 3할 3푼타자와 2할타자를 구분할 확률이 0.75(가정)라고 할 수 있다.
		- 여기서 `효과크기`란 0.13(1할3푼 : 두 타자 타율의 차이)을 의미한다.
		- `알아낸다` : 차이가 없을 것이라는 영가설을 기각, 실제 효과가 있다고 결론을 내리게 되는 것
		- 즉 두 타자를 대상으로 한 25타석 실험은 0.130의 효과크기에 대해 0.75의 검정력을 가진다고 볼 수 있다.

- 대부분의 데이터 과학자들은 검정력을 구하기 위해 형식적인 절차를 모두 지킬 필요는 없다. 그러나 **데이터 수집과 처리에 대한 비용이 발생할 때 가끔 쓰일 수 있다.**
- 이런 비용이 발생할 경우를 위한 직관적인 방법
	1. 최대한 결과 데이터가 비슷하게 나올 수 있는 가상의 데이터를 생각해보자.
		ex) 2할 타자를 위한 20개의 1과 80개의 0이 들어있는 상자.
	2. 첫 표본에서 원하는 효과크기를 더해 두 번째 표본을 만든다. 
		ex) 33개의 1과 67개의 0을 가진 두 번째 상자
	3. 각 상자에서 크기가 n인 부트스트랩 표본을 추출한다.
	4. 두 부트스트랩 표본에 대해 순열 가설검정(or 수식 기반의 가설검정)을 진행한다. 통계적으로 유의미한 차이가 있는지도 기록한다.
	5. 3~4단계를 여러 번 반복한 후, 얼마나 자주 유의미한 차이가 발생하는지를 알아본다. 이게 `검정력 추정치`이다. 

#### 표본크기
- 검정력 계산을 하는 이유는, 표본크기가 어느 정도 필요한가를 추정하는 것이다.
- **더 작은 차이를 보고 싶을수록 훨씬 더 큰 표본이 필요**하다.
	- ex) 현재 클릭률 1.1%, 10% 증가한 1.21%의 클릭률을 보고 싶다고 하자
		- 이 때 두 상자(110개의 1 + 9890개의 0 / 121개의 1 + 9879개의 0)를 생각할 수 있다.
			- 각 상자에서 300개를 뽑고, 결과가 각각 1/3, 1/5이라고 가정하자.
			- 이 표본크기(`300개`)와 효과크기의 차이(`10%`)는 가설검증을 통해 보이기엔 너무 작다.
	- ex2) 현재 클릭률 1.1%, 50% 증가한 1.65%의 클릭률을 보고 싶다
		- 2000개를 뽑았고 그 결과가 1/19, 1/34라고 하자.
		- 유의성검정을 하더라도 이전보다 더 유의미하지만, 그래도 유의미하지 않다는결론이 나긴 할 것이다.
- 따라서 검정력이나 필요한 표본크기의 계산에 대한 4가지 중요한 요소가 있다.
	- 표본 크기
	- 탐지하고자 하는 효과 크기
	- 가설검정을 위한 유의수준
	- 검정력
- 이 중 3가지를 정하면 나머지 하나를 알 수 있다.
- R에서는 `pwr` 패키지가 제공되며
- `Python`에서는 `from statsmodels.stats.power import TTestIndPower`이 제공된다.
