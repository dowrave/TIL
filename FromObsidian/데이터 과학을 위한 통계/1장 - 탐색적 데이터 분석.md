## 1. 정형화 데이터의 요소

- 기존 통계학은 적은 표본으로 큰 모집단에 대한 결론을 도출하기 위한 과정이었다.  
- `탐색적 데이터 분석(EDA : Exploratory Data Analysis)` : 1977년에 정립되었음
	- 오늘날 누구나 사용할 수 있는 데이터 분석 소프트웨어가 나왔고, EDA는 그 원래 범주를 훨씬 뛰어넘었다.
	- 새로운 기술 + 더 많은 데이터 + 양적 분석 -> 통계학을 이끄는 원동력이 되었다.
- 데이터 과학에서의 가장 중요한 도전은, 폭발적인 양의 원시 데이터`Raw Data`를 활용 가능한 형태의 정보로 변환하는 것이다.
- 데이터의 종류 : `수치형`(`이산형 & 연속형` ), `범주형`(+ `순서형`)
	- 시각화, 해석, 통계 모델 결정에 데이터 종류는 중요한 역할을 한다.

## 2. 테이블 데이터
`데이터프레임`, `피쳐(특징, 속성, 변수)`, `결과(종속변수, 응답, 출력)`, `레코드(관측값, 샘플)`

- 테이블 형식이 아닌 데이터 구조
	- 시계열 데이터 : 동일한 변수 안에 연속적 측정 값을 갖는다
	- 공간 데이터 : 
		- `객체` : 객체와 공간 좌표 
		- `필드` : 공간을 나타내는 단위와 적당한 측정 기준값
	- 그래프 데이터 : 물리적, 사회적, 추상적인 관계 표현에 사용됨.

## 3. 위치 추정
- 데이터를 살펴보는 가장 기초적인 단계는 각 변수의 `대푯값Typical Value`을 구하는 것이다.

1. `평균` : 설명할 필요 있는지?
	- `절사평균Trimmed Mean` 
		- 크기 순으로 정렬한 뒤, 양 끝에서 일정 개수의 값을 삭제한 뒤 남은 값들로 구하는 평균 (ex : 다이빙 대회에서 5명의 심판 중 최소 / 최댓값을 제외하고 계산)
		- 극단값의 영향을 제거한다.
	- `가중평균Weighted Mean`
		- $\bar{x_w} = \frac{\Sigma^n_{i=1}w_ix_i}{\Sigma^n_i w_i}$
		- 각 데이터의 선형 결합의 합을 가중치로 나눈 값
			- 어떤 값이 더 큰 변화량을 가질 때, 더 작은 가중치를 줄 수 있음
			- 데이터가 부족한 소수 그룹에 더 높은 가중치를 주기도 함

2. `중간값, 로버스트 추정`
	- 중간값 : 평균값보다 `특잇값` 에 더 로버스트함.
		- `가중 중간값` : 데이터를 일렬로 정렬한다. 각 데이터는 해당하는 가중치를 가졌으며, 어떤 위치를 기준으로 `상위 절반의 가중치의 합이 하위 절반의 가중치의 합과 동일한 지점`이다.
	- `특잇값` 
		- 잘못된 데이터일 수도 있지만, 항상 그렇지는 않다.
	- `절사평균` 또한 로버스트한 편이며, 중간값과 평균의 절충안이라고 할 수 있다. 
	- 통계학적으로 로버스트 & 효율적인 위치 추정법이 정말 많은데, 어느 정도 크기 이상의 데이터에서는 장점이 있다고 하기 어렵다.

## 4. 변이 추정
- 위치는 데이터의 특징을 요약하는 요소 중 하나이다.
- `변이Variability` : 데이터의 산포도`dispersion`를 나타낸다. 

1. 표준편차와 추정값
- `편차` : $\bar{x} - x_i$
	- 평균을 기준으로 편차의 합은 항상 0이므로, 편차의 절댓값의 평균을 구하는 방법이 있다. 이를 `평균절대편차`라고 한다.
- 한편 제일 유명한 방법은 `분산`, `표준편차`이다.
	- `분산` : $s^2 = \frac{\Sigma(x-\bar{x})^2}{n-1}$
	- `표준편차` : $s$
	- 표준편차를 평균절대편차보다 식이 어려운데도 자주 쓰는 이유는, **수학적으로 제곱한 값이 절댓값보다 다루기 쉽다는 통계 이론이 알려져 있기 떄문**이다.
	- `분산, 표준편차, 평균절대편차` 모두 로버스트하지 않다. *평균을 이용하니까*
		- `중위절대편차MAD` : $median(|x_1-m|, |x_2-m|, ...)$
		- 비슷한 방법으로 `절사표준편차`도 계산할 수 있다.
- `자유도Degrees Of Freedom` :  분산을 구하는 식에서 `n-1`로 나누는 이유?
	- `n`으로 나누게 된다면 분산과 표준편차의 참값을 과소평가하게 된다. 이를 `편향Biased 추정`이라고 부른다.
		- 왜 편향이 되냐 : 표준편차는 표본의 평균에 따른다는 하나의 제약 조건을 갖고 있기 때문이다. 그래서 자유도가 `n-1`이라고 하는 거임. 이해가 안되면 저 사실만 알고 그냥 넘겨도 무방하다.
2. 백분위수에 기초한 추정
- 정렬(순서) 데이터를 나타내는 통계량을 **순서통계량**이라고 부른다. 
- 가장 기본이 되는 척도는 `범위 : 최댓값 - 최솟값`이다. 그러나 특잇값에 매우 민감함.
	- 특잇값에 민감한 성질을 피하기 위해, `백분위수`사이의 차이를 이용해 추정하는 경우도 있다.
		- `백분위수` : 작은 값부터 큰 값까지 쫙 정렬했을 때 `n%`에 위치한 값
			- ex) 중간값 : 50번째 백분위수
- `사분위범위IQR` :` 75번째 백분위수 - 25번째 백분위수`

## 5. 데이터 분포 탐색하기
1. 백분위수와 상자 그림
	- 상자그림의 상한과 하한은 각각 `75번째 백분위 수 + 1.5IQR`, `25번째 백분위 수 - 1.5IQR`이며 이를 벗어나는 값들은 `각각 점`으로 표시된다.

2. 도수분포표와 히스토그램
	- 히스토그램은 도수분포표를 시각화하는 방법이다.

3. 밀도 추정
	- `커널밀도추정` 을 통해 데이터로부터 직접 계산된다.
	- 부드러운 버전의 히스토그램.

## 6. 이진 데이터와 범주 데이터 탐색
- `막대도표`는 어떤 범주형 자료를 보여줄 때 주로 사용되며, 가장 흔한 시각화 방법이다. 
	- `히스토그램`과의 차이
		- `막대`는 서로 다른 범주
		- `히스토그램`은 서로 붙어있음
	- `파이차트`가 비슷한 역할을 하지만, 통계학이나 데이터 시각화 전문가 모두 **시각적으로 효과적이지 않다**는 이유로 잘 쓰지 않는다.

1. 최빈값(`mode`)
	- 데이터에서 가장 자주 등장하는 값

2. 기댓값(`expectation`)
	- 각 범주에 해당하는 수치형 변수가 존재할 때, 기댓값은 `각 결괏값과 발생 확률을 모두 곱한 다음 모두 더함`

## 7. 상관관계
- `상관계수Pearson Correlation Coefficient`
$$r = \frac{\Sigma^N_{i=1}(x_i - \bar{x})(y_i - \bar{y})}{(N - 1)s_xs_y}
$$
	- $s_xs_y$는 각 변수의 표준편차 값을 의미함.
	- 이 값 자체가 두 변수 사이의 상관관계를 `항상 같은 척도에 놓고 추정`하는 것이다.
	- 상관계수는 항상 `+1 ~ -1` 사이에 존재한다.
- 변수들이 선형적인 관계가 아니라면, 상관계수는 더 이상 유용한 측정 지표가 아니다.
- 각 범주마다 상관관계를 나타내는 `상관행렬corrplot`을 그릴 수도 있다.

1. 산점도
	- 두 변수 사이의 관계를 시각화하는 가장 기본적인 방법.

## 8. 두 개 이상의 변수 탐색하기
- `평균, 분산`은 한 번에 하나의 변수를 다루는 `일변량분석Univariate Analysis`
- `상관분석`은 `이변량분석Bivariate Analysis`
- 셋 이상을 `다변량분석Multivariate Analysis`이라고 한다.

1. 육각형 구간과 등고선(수치형 변수 : 수치형 변수)
	- 육각형 구간 그림
	- 등고선 도표
	- 히트맵
2. 분할표(범주형 변수 vs 범주형 변수)
	- 엑셀의 피벗 테이블 기능을 활용할 수도 있고.. `groupby`를 쓸 수도 있고..
3. 범주형 변수 vs 수치형 변수
	- 상자그림
	- 바이올린그림
4. 다변수 시각화하기
	- `조건화Conditioning` : 2변수 비교용 도표(산점도, 육각형 구간, 상자그림)를 더 여러 변수를 비교하는 용도로 확장하여 사용할 수 있다.  `조건화 변수facet` 개념.
