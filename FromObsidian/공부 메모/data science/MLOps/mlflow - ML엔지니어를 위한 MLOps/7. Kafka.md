# 1. 카프카 소개

## 메시징 시스템
- **서로 다른 어플 간 정보 교환을 위한 메시지** 생성, 전송, 전달, 장을 가능케 하는 **시스템.**
- 주로 1개의 어플리케이션이 `여러 외부 앱`이나 `어떤 앱에 의해 1회 이상 처리된 데이터`를 전달받고 싶을 때 사용한다. 
- `메시지` : 하나의 엔티티 -> 다른 엔티티로 정보를 전송하는데 사용되는 통신 아티팩트.
- `Kafka`, `RabbitMQ`, `Active MQ`, `Java JMS` 등이 있다.

- 고전적인 분산 컴퓨팅 모델에 비해, **메시지 생산자와 소비자 사이의 `약한 결합성Loose Coupling`** 을 갖도록 한다.
	- `Loose Coupling` : 한 쪽이 끊기거나 변경이 있어도 다른 쪽에 미치는 영향이 작은 것

- 메시지 생산자와 소비자는 서로를 알지 못한다.
	- 소비자의 시점에서 생산자의 위치나 메시지의 생성 시기가 중요하지 않게 된다.
	- 이는 **동적이고 신뢰성 있고 유연한 시스템**을 구축하도록 해준다.
	- 시스템의 나머지 부분에 영향을 주지 않고 하위 어플리케이션의 전체 구성을 바꿀 수 있다.

- 높은 확장성 & 다른 네트워크 사이의 쉬운 통합성 & 안정성

- 이런 특징들로 인해 메시징 시스템은 워크플로우, 네트워크 관리, 통신 서비스, 고객 관리, 일기 예보 시스템 등 다양한 앱의 기반이 된다.


### 용어 정리
- `Message Oriented Middleware(MOM)`
	- 독립된 앱 간에 데이터를 주고받을 수 있도록 하는 시스템 디자인
		- 함수 호출, 공유 메모리 방식이 아님
		- 메시지 교환을 이용하는 중간 계층에 대한 인프라 아키텍처
		- 분산 컴퓨팅이 가능해지고, 서비스 간 결합성이 낮아진다.
	- 비동기 메시지 전달
	- `Queue`, `Broadcast`, `Multicast` 등의 방식으로 메시지를 전달함
	- `Publish/Subscribe` 구조
		- 메시지 발행자인 `Publisher`
		- 메시지 소비자인 `Subscriber`

- `Message Broker`
	- 메시지 처리 or 메시지 수신자에게 메시지를 전달하는 시스템. MOM 기반으로 구축됨

- `Message Queue(MQ)`
	- `MOM` + `Message Broker`를 구현한 소프트웨어
	- `RabbitMQ`, `ActiveMQ`, `Kafka` 등

- `Advanced Message Queueing Protocol(AMQP)`
	-  메시지를 안정적으로 주고 받기 위한 프로토콜
	- `MOM`은 메시지 전송을 해야 하므로 `AMQP`를 구현함

- Kafka는 `AMQP`를 구현한 `MOM` 시스템이다.

## Kafka
- Open-Source Distributed Event Streaming System
	- `Event Streaming` : DB, 센서, 모바일 기기, 앱 등에서 발생하는 데이터를 `Event Stream` 형태로 저장해서 나중에 검색할 수 있도록 함
		- 즉 발생하는 데이터를 실시간으로 처리하고, 필요한 타겟 시스템으로 이벤트 스트림을 라우팅해줌

### 주요 특징
- Event Streaming Platform
	- `Event Stream`을 실시간으로 처리 & 계속 쌓이는 데이터를 지속적으로 보관하다가 데이터가 필요한 타겟 시스템이 가져갈 수 있도록 제공한다.

- Pub/Sub 구조
	- 다른 시스템에서 데이터를 가져와서 Kafka에 Publish할 수 있음
	- Kafka로부터 데이터를 Subscribe(구독, 읽기)할 수 있음

- Decoupling
	- 카프카는 Producer와 Consumer가 존재한다. 두 객체는 완벽하게 분리되어 있다.
		- Producer : Kafka에 이벤트를 Publish하는 Client app
		- Consumer : Kafka로부터 이벤트를 Subscribe하는 Client app

### 카프카 구조와 구성요소
![[Pasted image 20230103145838.png]]

#### 1. Broker
- 메시징 서비스를 담당하는 Kafka 서버 또는 시스템
- 1개의 브로커는 1개의 카프카 브로커 프로세스를 의미함
- `Kafka를 구성한다`, `Kafka를 통해 메시지를 전달한다` 에서 Kafka는 브로커를 의미한다.
- 클러스터를 구성하는 다양한 방법이 있는데, 주로 다중 브로커를 사용한다. 이 때 각 브로커는 ID로 식별한다.
- 주요 역할 : `토픽Topic` 내의 `파티션Partition`을 분산 & 유지 & 관리
	- **브로커 내부에는 여러 토픽이 생성될 수 있고, 토픽들에 의해 파티션이 생성**된다.
	- 브로커는 파티션의 데이터를 분산저장하므로 예기치 못한 오류가 발생해도 안전하게 데이터를 사용하게 해준다.
	- 브로커는 토픽의 일부 파티션을 포함하지만, "데이터의 일부분인" 파티션을 갖고 "전체 데이터를 갖지 않는다."

#### 2. Kafka Cluster
- 여러 개의 브로커로 이뤄진 집합체.
- 보통 3대 이상의 브로커를 1개의 클러스터로 구성한다.

#### 3. Topic
- 브로커에서 `이벤트(데이터)`를 관리하는 기준이나 어떤 이벤트를 저장할 지 정하는 주제이다.
- `이벤트 = 폴더 속 파일`
- 전통 메시징 시스템과 달리, 메시지를 `Subscribe`해서 받더라도 메시지가 삭제되진 않는다.
- 대신 Topic마다 지정된 기준에 따라 Event 유지 여부를 정할 수 있는데, 설정된 기간과 용량에 따라 event를 유지한다.

> K-MOOC 강의 내용 중
>> 토픽은 논리적 버퍼로, 논리적으로는 1개의 공간이지만 **물리적으로는 여러 노드(`=브로커`)에 걸쳐 분산될 수 있음**
>> Topic을 여러 노드에 걸쳐 분산하면 실시간 데이터를 로드 밸런싱할 수 있다.

#### 4. Partition
- `토픽에는 파티션이 존재`하며 모든 파티션은 `Producer`로부터 전달된 데이터를 보관하는 역할을 한다.

- `리더 파티션(Leader Partiton)`
	- 항상 존재
	- `Producer` or `Consumer`와 직접 통신함
- `팔로워 파티션(Follower Partition)`
	- 옵션
	- `Producer`에 의해 리더 파티션으로 전달된 데이터를 복제하여 저장함
	- 그러다가 **리더 파티션이 속한 브로커에 문제가 발생하면 팔로워 파티션이 리더 파티션의 지위를 갖게 된다.**

- 리더 파티션과 팔로워 파티션의 갯수는 `Replication Factor`의 수에 의해 달라지게 된다.
![[파일_000 (3).png]]
- 기본값은 3으로, 리더 파티션의 데이터를 복제해서 팔로워 파티션 2개에 복제된다.
- 만약 `Replication Factor` 값이 1이라면 리더 파티션에만 데이터를 저장한다. 

#### 5. Zookeeper
- 분산 시스템에서 시스템 간 정보 유지, 상태 체크, 서버들 간의 동기화 등을 처리해주는 `분산 코디네이션 서비스Distributed Coordination Service`
- 직접 앱을 조율하지 않음. 대신 조율하는 것을 쉽게 개발할 수 있도록 함
- API를 이용하여 동기화하거나 마스터 선출 등의 작업을 쉽게 구현할 수 있도록 도와준다.
- 데이터는 분산 작업을 저장하기 위해 트리 형태의 데이터 저장소에 `스냅샷`을 저장한다.

- **Zookeeper Ensemble**
	- 주키퍼 서버의 클러스터
	- 보통 홀수로 구축, 최소 3개, 일반적인 경우 5개 권장
	- 파티션처럼 리더 서버와 팔로워 서버가 있다.
		- 리더 서버 : `Write`
		- 팔로워 서버 : `Read`

#### 6. Producer & Consumer

- **Producer**
메시지를 생산, 브로커의 토픽으로 메시지를 보내는 앱 또는 서버
	- 데이터 전송 시 리더 파티션의 브로커와 직접 통신
	- 원하는 토픽의 파티션에 전송만 한다
	- 어떤 Consumer에 전송되는지는 신경쓰지 않는다.

- **Consumer**  
토픽의 파티션에 저장된 메시지를 소비하는 역할을 하는 앱 또는 서버 
	- 데이터 요청 시 리더 파티션을 가진 브로커와 통신해 토픽의 파티션으로부터 데이터를 가져감
	- 운영 방법은 2가지가 있다.
		1. 토픽의 특정 파티션만 Subscribe하는 Consumer 운영
		2. 1개 이상의 Consumer로 이뤄진 Consumer 그룹 운영
	- Producer처럼 Consumer도 메시지 발신원을 확인하지 않고 원하는 토픽의 파티션을 읽고 필요한 메시지만 받는다. 

# 2. Producer & Consumer

## 1. 주키퍼 & 브로커 서비스 작성 

- **주키퍼 서비스**를 띄우는 `naive-docker-compose.yaml` 파일   

`naive-docker-compose.yaml`
```yaml
version: "3"  
  
services:  
  zookeeper:  
    image: confluentinc/cp-zookeeper:7.3.0  
    container_name: zookeeper  
    ports:  
      - 2181:2181  
	environment:  
	  ZOOKEEPER_SERVER_ID: 1  
	  ZOOKEEPER_CLIENT_PORT: 2181
```
- 환경변수
> `ZOOKEEPER_SERVER_ID` : 클러스터에서 해당 주키퍼를 식별할 ID를 지정함
> `ZOOKEEPER_CLIENT_PORT` : 주키퍼의 기본 포트 `2181`

2. **브로커 서비스**
`naive-docker-compose.yaml`
```yaml
services:  
  broker:  
	image: confluentinc/cp-kafka:7.3.0  
	container_name: broker  
	depends_on:  
	  - zookeeper  
	ports:  
	  - 9092:9092  
	environment:  
	  KAFKA_BROKER_ID: 1  
	  KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181  
	  KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092  
	  KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT  
	  KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT  
	  KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1  
	  KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
```
- 환경변수
> `KAFKA_SERVER_ID` : 브로커의 ID 지정, 단일 브로커에선 없어도 무방하나 여기선 `1`로 지정함
> `KAFKA_ZOOKEEPER_CONNECT` : 브로커 -> 주키퍼 연결 주소 지정
>> `주키퍼 서비스 이름 : 주키퍼 서비스 포트` 형식으로 작성 -> `zookeeper:2181`
> `KAFKA_ADVERTISE_LISTNERS` : 내부나 외부에서 접속하기 위한 리스너를 지정함
>> `internal`, `external` 를 같이 설정하며 `,`로 연결함
>`KAFKA_LISTENER_SECURITY_PROTOCOL_MAP` : 보안을 위한 프로토콜 매핑을 지원함
>> `KAFKA_ADVERTISED_LISTENERS`와 함께 `key/value` 값으로 매핑된다.
>`KAFKA_INTER_BROKER_LISTENER_NAME` : 컨테이너 내부에서 사용할 리스너 이름 설정
>`KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR` : 토픽을 분산해서 저장할 Replication Factor를 설정함
>> 여기선 브로커를 1개만 쓰기 떄문에 `1`로 지정함
>`KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS` : 카프카 클러스터에서 초기 리밸런싱할 때 Consumer가 Consumer Group에 Join할 때 대기하는 시간으로, 여기선 `0`으로 설정함

- 전체 `naive-docker-compose.yaml` 
```yaml
version: "3"  
  
services:  
  zookeeper:  
    image: confluentinc/cp-zookeeper:7.3.0  
    container_name: zookeeper  
    ports:  
      - 2181:2181  
	environment:  
	  ZOOKEEPER_SERVER_ID: 1  
	  ZOOKEEPER_CLIENT_PORT: 2181

  broker:  
	image: confluentinc/cp-kafka:7.3.0  
	container_name: broker  
	depends_on:  
	  - zookeeper  
	ports:  
	  - 9092:9092  
	environment:  
	  KAFKA_BROKER_ID: 1  
	  KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181  
	  KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092  
	  KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT  
	  KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT  
	  KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1  
	  KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
```

- 실행
```sh
docker compose -p part7-naive -f naive-docker-compose.yaml up -d

# 확인 (IMAGE에 `cp-kafka`, `cp-zookeeper` 확인)
docker ps
```
> `-p` : `Project Name` - 여기서 지정하는 이름
> `-f` : `File Name` - 실행할 명세서 이름

- **트러블 슈팅**
> `cp-kafka`가 실행되었다가 꺼지는 현상
>>`docker logs <컨테이너 id>` 입력
>>> `Error creating broker listeners from 'PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092': No security protocol defined for ㅑlistener PLAINTEXT_HOST`
> - 원인 : `naive-docker-compose.yaml` 파일에 오타 -  `KAFKA_LISTNER_SECURITY_PROTOCOL_MAP` 로 작성했음;

## 2. Producer & Consumer 생성

- `cp-kafka, cp-zookeeper` 컨테이너 실행되는 거 보고 진행

### 1. 토픽 생성
```sh
docker exec broker kafka-topics --create \
--topic topic-test \
--bootstrap-server broker:29092 \
--partitions 1 \
--replication-factor 1
```
- `kafka-topics` : 토픽 명령 실행
- `--create` : 토픽 생성
- `--topic` : 토픽 이름 지정
- `--bootstrap-server` : 브로커 서비스에 대한 호스트 이름, 포트 지정
- `--partition` : 토픽 내의 파티션 갯수

> 원본 가이드에는 `docker compose exec`라고 나와 있는데
> `no configuration file provided : not found` 에러가 발생함
>> `docker compose`로 접근하려면 `docker compose -p part7-naive exec broker` 로 작성해야 함

- 생성 확인
```sh
docker exec broker kafka-topics \
--describe \
--topic topic-test \
--bootstrap-server broker:29092
```
- `--describe` : 생성된 토픽에 대한 상세 설명
> 여기도 마찬가지 : `docker compose exec`로 나와 있었는데 `docker exec`가 맞는 것 같다. (`compose`를 쓰겠다면 해당 `docker compose`  프로젝트의 이름을 명시해야 함)

### 2. Consumer 생성
- Consumer를 먼저 실행하는데, 일반적으로 Consumer가 메시지를 Subscribe하려고 대기하는 상태에서 Producer가 메시지를 생성해서 보내기 때문임

- `Broker` 컨테이너 접속
```sh
docker compose -p part7-naive exec broker /bin/bash
```

- 컨슈머 실행
```sh
kafka-console-consumer --topic topic-test --bootstrap-server broker:29092
```
- 이후 수신 대기 상태가 되며, **아래 내용은 다른 탭을 띄워서 진행함**

### 3. Producer 생성
- `Consumer`를 띄운 채로 진행
- `Broker` 컨테이너 접속은 위와 동일
```sh
docker compose -p part7-naive exec broker /bin/bash
```

- Producer 실행
```sh
kafka-console-proucer --topic topic-test --broker-list broker:29092
```

- Producer 탭에 메시지를 입력했을 때 Consumer에서 같은 메시지가 확인되면 성공임
- **Producer** 탭에서 입력한 내용
![[Pasted image 20230103170534.png]]
- Consumer 탭
![[Pasted image 20230103170621.png]]

- 종료 : 주키퍼, 브로커 모두 종료
```sh
docker compose -p part7-naive down -v
```

- 위에 오류 내용 수정에 기여하고 싶으니까 잠깐 보류함

# 3. Connect & Connector
- [여기부터 계속](https://mlops-for-mle.github.io/tutorial/docs/kafka/connect-connector)
