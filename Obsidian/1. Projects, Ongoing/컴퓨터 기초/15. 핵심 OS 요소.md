# 프로그램 vs 스레드
응용 프로그램 개발자로서 알아야 할 OS의 구체적인 요소에 대해 살펴본다.

현대 OS의 필수 요소 중 하나는 `멀티태스킹Multitasking`이다. **하나의 CPU 상에서 동시에 여러 프로그램이 실행되는 기술**인데, 사용자가 느끼기에 여럿이고 실제로는 매우 빠른 실행 전환`Context Switching`해주는 것이다. 

OS는 멀티태스킹을 구현하기 위해 수행 코드 전환 외에도 다른 인프라를 구현하고 있다. 

이러한 대표적인 요소로 `프로세스Process, 태스크Task`가 있다. 
- `프로세스Process` : 윈도우즈에서 **실행 중인** 개별 프로그램(파워포인트, mp3 등등)
> 즉 하드 디스크에 있는 프로그램 이미지는 프로세스가 아니다.

프로세스란, 하나의 프로그램이 실행되는 단위로 생각할 수 있다. 하나의 프로그램이 돌아가기 위해서는 여러 요소가 필요하다.
- 실행하고자 하는 프로그램의 코드
- 프로그램의 데이터가 있는 이미지

프로그램은 메인 메모리에서 실행되므로, 예를 들어 파워포인트를 두 번 실행시키더라도 1개의 이미지에서 2개의 프로세스가 생성되고 독립적으로 다른 내용을 작성할 수 있다.

일반적으로 표현하자면, **프로세스는 프로그램이 수행되기 위한 `자원Resource` 소유의 단위**로 생각할 수 있다. 자원의 가장 큰 요소가 메모리로, 각 프로세스는 독립된 프로그램으로서 동작하기 위해 자신만의 메모리를 확보한다. 
- `자원`으로 불릴 수 있는 다른 요소로 `핸들`이 있다. 
	- 제한된 하드웨어를 다수의 프로그램(프로세스)이 동시에 사용하기 위해서는 각 프로그램이 임의로 하드웨어를 제어하는 게 아니라, OS한테 제어를 요청하고 OS가 일괄적으로 묶어서 이를 처리해준다. 
	- 이 때, OS는 `핸들`이라는 고유값을 프로그램에게 넘겨준다. 프로그램이 어떤 파일을 열거나, 네트워크 장치를 사용하는 등의 요청이 있다면 OS는 핸들 값을 넘겨주며, 해당 파일이나 장치에 데이터를 쓰거나 읽거나 할 때에도 항상 핸들을 갖고 있어야 한다.
	- 이러한 핸들값도 프로그램마다 할당되는 것으로, 해당 프로그램이 종료되면 함께 폐기처분된다.

프로세스의 또다른 중요한 요소는 `실행Dispatching` 단위라는 점이다. 앞에서도 언급했듯 메모리 상에서 CPU에 의해 실행되고 있는 프로그램인데, 따라서 이들은 `자원`을 독립적으로 소유하는 것 외에도 `CPU를 사용할 수 있는 권한`도 얻어야 한다. 프로그램 수가 늘어날수록 CPU 수행 시간이 분배될 것이며, 프로세스는 이러한 CPU 수행 시간을 분배받는 단위이기도 하다.

최근(07년 기준)에는 이러한 전통적인 개념을 약간 탈피하게 되었다. 과거의 프로세스는 하나의 실행 단위로 생각되었는데, **효율성 이슈로 점점 프로세스와 실행 단위를 구별하게 되었다.** 일반적인 응용 프로그램에서는 1개의 수행 단위로 충분하지만, 논리적으로 볼 때 2개의 수행 단위가 편한 경우가 발생한다든가, 많은 수의 IO 처리를 하는 경우에는 1개의 프로세스 임에도 여러 수행 단위를 얻어 작업하는게 효율적인 경우가 많아졌다.

워드 프로세서에서 오타에 빨간 밑줄을 긋는 로직을 생각해보자. 사람이 타이핑할 때마다 체크할 수도 있지만, 느린 PC에서는 타이핑 속도를 문법 검증 속도가 따라오지 못하는 경우가 발생할 수도 있다. 이런 경우에는 워드 프로세서라는 하나의 프로세서 안에 `사용자의 타이핑을 대기하고 화면의 글자를 뿌리는 루틴`과는 별개로, 다른 수행 단위를 만들어 `타이핑된 글자들을 항상 모니터링해서 잘못된 내용을 찾는 루틴`으로 이용하는 걸 생각해볼 수 있다.
이를 아예 별도의 프로그램이나 프로세서로 빼는 것도 가능하긴 하지만, 문법 체크 루틴이 별도의 프로세스가 되어버리면 워드 프로세스에 할당된 메모리와는 다른 공간을 할당받고 독립적인 프로세스가 되면서 서로의 메모리 공간에 접근하기 힘들어진다. 즉, 같은 메모리를 놓고 수행 단위만 별도로 놓는 게 편리하다.

그래서 이를 반영하고자 **프로세스에서 수행 단위를 분리해서 `스레드Thread`라는 개념을 도입**하게 되었다.

스레드가 도입되면서 프로세스는 수행의 단위가 아니라 단지 자원 소유의 단위로 바뀌었다. 대신, **수행 단위인 CPU 시간을 할애받는 것도 하나의 자원으로 인식되어 스레드**라는 이름으로 다른 여러 자원과 함께 프로세스에 종속되는 형태가 되었다. 
즉, 1개의 프로세스가 여러 개의 스레드를 가질 수 있고, 곧 여러 개의 수행 단위를 가질 수 있게 되었음을 의미한다. 이제 프로세스는 기본적으로 최소 1개의 스레드를 보유해야 하며, 프로세스가 생성될 때 기본 스레드가 함께 생성된다. 

> 이 쯤에서 제미나이로 점검함
> - 전체적으로 **잘못된 내용은 없음**
> - 25년 기준으로 추가할 내용을 정리해보면
> 1. 위 서술은 `단일 CPU 코어 환경`의 `빠른 전환을 통한 동시성`에 초점을 맞췄으나, 현재는 대부분의 컴퓨팅 환경이 **멀티 코어 프로세서를 사용하면서 여러 스레드나 프로세스가 실제로 동시에 여러 코어에서 병렬적으로 실행될 수 있게 되었다. 스레드의 중요성이 더욱 커짐.**
> 2. 스레드 관련 추가 서술 : 스레드는 프로세스의 자원, 특히 메모리 공간을 공유하기 때문에 `스레드 간 통신ITC`은 `프로세스 간 통신IPC`보다 효율적이다. 대신 한 스레드에서 발생한 문제가 다른 스레드로 퍼지거나 전체 프로세스를 중단시킬 위험도 있다.
> 3. `자원Resource`은 메모리, 핸들 외에도 파일 디스크립터, 소켓, 보안 컨텍스트(권한) 등을 소유하고 관리하는 단위다.
> 4. `가상화 및 컨테이너 기술` : 프로세스보다 높은 수준에서 격리된 실행 환경을 제공하지만, 기반에는 여전히 OS의 프로세스 / 스레드 관리 매커니즘이 동작한다. 컨테이너는 호스트 OS의 커널을 공유하면서 프로세스 공간, 네트워크 등을 격리하는 방식이다.
> 5. `비동기 프로그래밍 모델의 발전` : 많은 언어와 프레임워크에서 비동기 프로그래밍 모델이 사용된다. 이는 단일 스레드 혹은 적은 수의 스레드 내에서 I/O 작업 등으로 인한 대기 시간 동안 다른 작업을 처리하여 효율을 높이는 방식이다. 스레드를 효율적으로 활용하는 프로그래밍 기법이다.

---

- 무한히 변수 `i`를 1씩 증가시키고, 이를 출력하는 코드가 있다고 해보자.

1. 이 코드가 컴파일되면 `exe` 파일이 생긴다. 
2. `exe` 파일을 실행하면, 탐색기 프로그램이 선택된 파일의 이름을 인자로 넘기고, 윈도우즈에서 제공하는 `CreateProcess`라는 `API 함수`를 호출한다.
	- `Kernel32.dll`이라는 동적 라이브러리에 포함된 함수
3. `CreateProcess`는 실행 파일 경로를 인자로 받고, 해당 코드를 하드디스크에서 읽어 메모리로 로드한다. 
4. 이 때 OS 내부에서는 필요한 메모리 외에도 실행할 프로그램에 필요한 여러 정보를 저장할 변수를 준비한다.
	- 다르게 표현하면 파일 `이미지`로부터 새로운 `프로세스`가 생성되고, OS는 여기에 필요한 `자원`을 확보하는 것이다. 프로세스에 필요한 핸들 엔트리, 코드나 데이터를 위한 메모리 등등.
	- `스레드`도 프로세스의 자원이라 이 과정에서 생긴다. 

스레드가 약간 추상적이지만, 멀티태스킹 OS 상에서 프로그램 간의 실행 전환`Context Switching`이 일어날 때 전환의 대상이 되는 주체이다. 

조금 더 자세히 살펴보면
하나의 프로그램이란, 인스트럭션이 연속적으로 실행되어 하나의 의미 있는 동작을 할 수 있도록 `문맥Context`을 형성하는 상태를 의미한다. 인스트럭션이 글자 하나라면, 프로그램은 문장 혹은 글이라고 볼 수 있다. 
하지만 CPU는 원칙적으로 한 번에 하나의 인스트럭션만 수행할 수 있다. 사람이 글을 읽을 때 최소 단위가 글자인 것과 마찬가지이다. 글자들이 의미를 이루려면 앞의 내용들을 기억해야 한다. 마찬가지로 프로그램이란, **앞의 수행 결과를 레지스터에 보관**해가면서 **순차적으로 수행되도록 나열된 인스트럭션을 의미**한다.
문제는 글이 여러 개 있는 경우인데, **멀티태스킹 OS에서는 글 하나를 다 읽고 다음 글로 넘기는 게 아니라, 번갈아가면서 글을 조금씩 읽는다.**

이러한 비유의 측면에서 이미지는 책장에 있는 책들, 프로세스는 책상 위에 펼쳐둔 책에 비유할 수 있다.

그렇다면 스레드는 어떨까? 책이 10권이라고 책 내부에 있는 글이 총 10편인 건 아니다. 단편이라면 한 권에 여러 글이 실려있을 수도 있다. 이러한 번갈아 읽는 글의 단위를 스레드에 비유할 수 있다. **한 프로세스 내에서도 여러 단위의 문맥이 존재해서 이들을 동시에 실행해 나갈 수 있는데, 이 문맥의 실행 단위가 스레드이다.** 

글 사이에 전환이 일어나는 상황을 생각해보자. **한 스레드가 실행되는 동안, 연속적으로 인스트럭션이 실행되며 레지스터에 실행 결과가 축적된다.** 그러다가 **`문맥 전환`이 발생하게 되면, 레지스터의 정보는 해당 스레드와 연계된 메모리에 보관되고, 다시 실행될 때 메모리에서 불러오는 방식**이다. 이런 동작은 `LOAD, STORE` 같은 인스트럭션으로 수행되는데 이는 상당한 부담이 된다. 스레드 간의 문맥 전환이 자주 일어나면 코드 수행보다 문맥 전환에 CPU 파워를 더 많이 쓰게 되어서 자주 일어나지 않게 하는 게 중요한 이슈 중 하나다.

> 지금의 CPU는 어떨까?
> 1. 멀티 코어 & 동시 멀티 스레딩(+하이퍼스레딩)
> - 현대 CPU는 대부분 코어가 여러 개라서, 1명이 아니라 여러 명이 앉아서 동시에 여러 책(프로세스)이나 이야기(스레드)를 읽을 수 있게 되었다
> - `SMT, 하이퍼스레딩` : 더 나아가, **하나의 물리적인 코어가 동시에 여러 스레드의 문맥을 유지할 수 있는 기술**이다. CPU 내부적으로 각 스레드에 필요한 레지스터 세트 등을 일부 복제하거나 효율적으로 관리해서, 아주 짧은 지연시간으로 스레드 간 전환을 가능하게 한다. 1명의 독서가가 2개의 북마크를 꽂은 채 거의 동시에 다른 이야기를 번갈아 보는 것과 비슷하다. 
> 2. `LOAD, STORE` 같은 인스트럭션 자체의 효율성이 개선되었고, 문맥 전환을 효율적으로 수행할 수 있도록 돕는 특수한 명령어도 생겼다.
> 3. 더 크고 빠른 캐시 메모리
>- CPU는 메인 메모리보다 훨씬 빠른 캐시 메모리를 여러 계층(L1, L2, L3)으로 갖고 있다. 문맥 전환 시 저장해야 할 레지스터 정보나 다음에 실행될 스레드 정보가 캐시 메모리에 존재할 확률이 높다. `캐시 히트Cache Hit`가 발생하면 메인 메모리까지 접근할 필요 없이 훨씬 더 빠르게 데이터를 로드/스토어할 수 있어서 문맥전환의 오버헤드를 줄이는 데 기여한다.
>- 07년 기준, cpu는 이미 L1, L2 캐시를 갖고 있었다.
>	- L1 캐시 : CPU 코어에 가장 가깝고 빠르며 용량은 수십kb 수준이다. 명령어 캐시 / 데이터 캐시로 분리되어 있는 경우가 많았다.
>	- L2 캐시 : L1 캐시보다 크고(수백kb ~ 수십mb) 약간 느리다. 코어마다 L2 캐시를 갖거나, 여러 코어가 공유하는 경우도 있었다.
>	- 위 2개의 설명은 07년 기준이고 현대에는 L2 캐시도 기본 MB 단위, L3 캐시는 수십 MB에 달한다. 캐시 용량이 커지면 더 많은 데이터와 명령어를 저장할 수 있어 캐시 히트율이 높아지고 문맥 전환 시 메인 메모리 접근 횟수를 줄여 성능 향상에 기여했다.
>4. 정교해진 운영체제 스케줄러
>- 스케줄러는 불필요한 문맥 전환을 최소화하고, 전환이 필요할 때는 가장 효율적인 방식으로 스레드를 코어에 할당하려고 한다. 예를 들면 가능한 같은 코어의 SMT 스레드 간의 전환을 유도하거나, 캐시에 데이터가 남아있을 가능성이 높은 스레드를 우선적으로 꺠우는 최적화 등을 한다. 

---
위에서 1씩 증가하는 코드를 살짝 바꿔서, `CreateProcess`라는 프로세스가 아니라 스레드를 생성한다고 하자.
```c
int g_idx = 0;
unsigned int NewThread(void* pParam) 
{
	while (1)
	{
		g_idx ++; 
	}
}

int main(int argc, char* argv[])
{
	CreateThread(
		NULL,
		0,
		(LPTHREAD_START_ROUTINE) NewThread, // 함수 주소를 넘겨주는 부분
		0,
		0,
		NULL
	);

	while (1)
	{
		printf("g_idx : %d\n", g_idx++);
	}
	
	return 1;
}
```
> `NewThread`라는 함수 주소를 넘겨주면서 **새로 생성된 스레드는 메인 스레드와는 별개로 `NewThread` 함수를 수행한다.** 

프로그램이 실행되면 OS가 새로운 스레드를 만들고, 이 스레드의 수행 코드 주소를 `main`으로 주는 것과 마찬가지다. 실제로는 다른 곳에서 시작해서 `main` 함수를 호출하는 것이지만, 개념적인 측면에서.

따라서 `main` 함수의 리턴 후에는 메인 스레드가 종료되고 프로세스가 종료되듯이, 새로 생성된 스레드도 마찬가지로 지정받은 함수가 리턴하면 자동으로 종료된다. 여기선 두 스레드가 모두 무한히 존재하게 된다.

위 코드의 결과는 어떨까? 새로 생성된 스레드를 생각하지 않는다면 1씩 증가하는 결과가 쭉 출력되지만, 새로 생성된 스레드가 `NewThread` 코드를 별도로 수행하고 있기에 `g_idx`의 증가는 `main` 함수와 `NewThread` 함수 양쪽에서 함께 증가한다. 단, `printf` 출력은 `main` 함수에서만 이뤄지고 있다.

책에서 나온 위 코드의 결과는, `g_idx`의 증가 폭이 1이 아님을 알 수 있다, 아예 17000 ~ 18000 단위로 증가함. 왜냐하면, **`main` 스레드에서 값을 1 증가시키고 결과를 출력하는 동안 새로 생성한 스레드에서 값을 17000번 이상 증가시키고 있기 때문이다.** 

여기서 중요하게 생각할 건 **`CreateThread`로 생성된 별도의 스레드는 같은 프로세스 내의 모든 변수나 코드, 자원 등을 공유할 수 있다**는 것이다.

나중에 점차 효율적인 프로그램을 생각하게 될 때, 메인 스레드 외에 별도의 스레드를 만들어 사용하는 걸 생각하게 된다. 복수의 스레드가 존재하게끔 프로그램을 짜는 것을 `멀티스레딩MultiThreading`이라고 한다. 물론 별도의 스레드가 필요 없이 프로그램을 만들 수 있다면 그렇게 하는 게 더 좋다. 스레드가 많아지고 스레드 간의 문맥 전환이 발생하면 CPU가 레지스터를 메모리에 저장하고 복구하는데 자원을 쓰므로 효율이 떨어지기 때문이다. 

특히, 한 프로세스 안에서 2개 이상의 스레드가 동시에 동작할 때 문제가 되는 게 `동기화Synchronization` 부분이다. 위에서 언급한 `같은 프로세스의 모든 변수, 코드, 자원`에 접근할 수 있다는 게 문제가 된다. 독립적으로 작동하는 여러 스레드가 동시에 같은 변수에 접근한다면? 

따라서 메인 스레드와 별도의 스레드 간에는 같은 변수를 놓고 동기화하는 작업이 필요하다. 예를 들어 메인 스레드가 1씩 증가시키면, 다른 스레드가 2 증가시키거나 하는 규칙을 만드는 것이다. 윈도우즈에서는 `동기화 객체`라는 게 있다.

물론 말은 쉽고, 코드가 길어지고 프로그램이 복잡해지면서 개발자의 퇴근을 막는 큰 원인 중 하나이다. 동기화로 인해 발생하는 버그는 능숙한 경험이 없으면 찾아내기 어렵다. 따라서 **가능하면 단일 스레드로 프로그램을 작성하되, 멀티스레딩이 필요하다면 몇 가지 동기화 원칙을 유념해서 그 원칙에 맞춰 간결하게 작성하는 게 중요**하다.

# 2. 동기화
멀티스레딩이 어려운 이유, 멀티스레딩을 이용해야 하는 상황을 본다.

**`멀티스레딩MultiThreading`이란 하나의 프로세스에서 메인 스레드 외의 다른 스레드를 만들어 복수의 스레드가 동시에 돌아가는 프로그램 기법**이다. 1개의 CPU로 동시에 여러 코드를 수행할 수 있다는 것이다. (실질적으로 인스트럭션 단위까지 보면 한 번에 수행되는 인스트럭션은 1개고, 논리적인 단위에서만 '동시에 여러 개를 수행'하는 것처럼 보이는 것이다.)

앞의 예제 코드에서, 규칙을 조금 바꾼다. 
```c
int g_idx = 0;
unsigned int NewThread(void* pParam) 
{
	while (1)
	{
		g_idx ++; 
		Sleep(50);
	}
}

int main(int argc, char* argv[])
{
	CreateThread(
		NULL,
		0,
		(LPTHREAD_START_ROUTINE) NewThread, // 함수 주소를 넘겨주는 부분
		0,
		0,
		NULL
	);

	while (1)
	{
		printf("G_idx : %d", g_idx);
		printf("g_idx * 2 = %d\n", g_idx * 2);
		Sleep(500);
	}
	
	return 1;
}
```
> 변수의 증가는 새로 생성된 `NewThread`에서만 하고, `main` 스레드에서는 `g_idx`와 2를 곱한 값을 출력하기만 한다. `Sleep()`은 빠른 속도 증가를 막기 위함이며 ms 단위임.
> 즉 `main`의 루프는 `NewThread` 대비 1/10의 속도로 돌아간다. 

- 이것의 결과를 살펴보면 재밌는데,
```
g_idx : 8 g_idx * 2 : 18
g_idx : 16 g_idx * 2 : 34
```
1. 각 간격이 예상한 것처럼 돌아가지는 않음. 10에 가깝기는 하지만.
2. 같은 줄에 출력된 결과들이 정확히 2배가 아님. 

**2번째 이슈가 바로 2개의 스레드가 독립적으로 실행되기 때문에 발생한다.** 왜냐하면 `g_idx`와 `g_idx * 2`를 코드 단위에서는 동시에 출력하고 싶다고 작성했지만, 인스트럭션 단위로 내려가면 동시에 진행되지 않기 때문이다.

**`g_idx++`를 어셈블리 코드로 살펴보면 3개의 인스트럭션으로 되어 있지만, 메인 스레드에서는 `printf`를 2번 호출하는데 이 함수는 3줄보다 훨~씬 긴 인스트럭션으로 이뤄져 있다.** 메인 스레드에서 `printf` 코드를 수행하는 동안 `NewThread` 함수가 계속 수행되고, 겁나 긴 인스트럭션으로 이뤄진 `printf`가 2번 수행되면서 `g_idx`도 2번 참조되는데, 그 동안에 `g_idx`의 값이 바뀌어버리고 만 것이다.

이런 경우가 바로 동기화가 필요한 경우이다. 2번의 `printf` 코드는 서로 다르지만 동일한 `g_idx`를 참조시키는 게 목적이므로 논리적으로 한 단위로 이뤄져 있어야 한다. 따라서, **2번의 `printf`가 수행되는 동안에는 `NewThread`가 `g_idx` 값을 변경하는 것을 막아야 한다.** 

이를 위해 멀티태스킹 OS에서는 **`동기화 객체Synchronization Object`** 라고 불리는 걸 제공한다. `크리티컬 섹션Critical Section`이나 `뮤텍스Mutex` 등이 있는데, 근본적인 기능은 동일해서 크리티컬 섹션에 대해 살펴본다.

**크리티컬 섹션은 1명만 사용할 수 있는 화장실**이다. 누가 들어가 있으면, 다른 사람은 그 사람이 나올 때까지 대기해야 한다. 마찬가지로 한 스레드가 섹션을 이용하고 있으면`락lock` 다른 스레드가 다시 그 세션을 이용`락`하려고 할 때, 앞의 스레드가 사용을 마칠 때까지`언락unlock` 기다리게 된다. 즉, 스레드가 대기 모드로 전환되면서 더 이상 코드가 수행되지 않는다.`블로킹Blocking` 
앞의 스레드가 언락되면, 대기 중인 스레드가 해당 섹션을 락하면서 수행이 계속된다. 

모든 스레드가 위의 원칙을 지킨다면, 공용 자원은 한 시점에 한 스레드에 의한 액세스만 가능해진다. 

이를 코드로 살펴보면

```c
int g_idx = 0;
CRITICAL_SECTION g_csFor_g_idx; // 추가

unsigned int NewThread(void* pParam) 
{
	while (1)
	{
		EnterCriticalSection(&g_csFor_g_idx); // 추가
		g_idx ++; 
		LeaveCriticalSection(&g_csFor_g_idx); // 추가
		Sleep(50);
	}
}

int main(int argc, char* argv[])
{
	InitializeCriticalSection(&g_csFor_g_idx); // 추가

	CreateThread(
		NULL,
		0,
		(LPTHREAD_START_ROUTINE) NewThread, // 함수 주소를 넘겨주는 부분
		0,
		0,
		NULL
	);

	while (1)
	{
		EnterCriticalSection(&g_csFor_g_idx); // 추가
		printf("G_idx : %d", g_idx);
		printf("g_idx * 2 = %d\n", g_idx * 2);
		LeaveCriticalSection(&g_csFor_g_idx); // 추가
		
		Sleep(500);
	}
	DeleteCriticalSection(&g_csFor_g_idx); // 추가
	return 1;
}
```
> 1. 크리티컬 섹션 객체 `g_csFor_g_idx`을 선언
> 2. `main`의 시작에서 크리티컬 섹션 초기화
> 3. `g_idx`를 증가시킬 때 및 출력시킬 때에 대해 크리티컬 섹션을 지정, 해당 과정이 수행되는 동안에는 다른 스레드가 해당 변수에 접근하지 못하게 구성
> 4. 실제로는 무한 루프를 도니까 `DeleteCriticalSection`이 작동하지는 않음.

- 이렇게 구현하면 `g_idx`의 증가폭 자체는 여전히 정확히 10은 아니지만, **같은 줄에 출력되는`g_idx` 및  `g_idx * 2`이 정확히 2배 값을 유지하게 된다.**

`동기화 객체`에는 이외에도 `뮤텍스Mutex`나 `세마포어Semaphore` 등이 있는데, 뮤텍스는 크리티컬 섹션과 거의 동일하되 다른 프로세스의 스레드끼리 동기화할 때도 쓸 수 있다는 차이점이 있고, 세마포어는 락을 여러 번 할 수 있다는 차이가 있지만 근본적으로는 동일하다.

- 멀티스레딩의 동기화 원칙
1. 2개 이상 복수의 스레드에서 **함께 사용하는 자원(주로 변수)마다 동기화 객체를 생성**
2. 각 공용 자원이 사용되는 논리적 단위마다 해당 동기화 객체로 묶는다
	- 위의 코드에서 `g_idx`를 증가시키는 부분과 출력시키는 부분에 해당
3. **가능한 한 동기화 객체로 보호되는 논리적 단위(이 말 자체가 크리티컬 섹션이기도 하다)를 작게 잡는다.** 
	- 위에서 메인 스레드의 크리티컬 섹션의 영역은 `Sleep()`을 포함하지 않았다. 그걸 포함하면 0.5초 씩 계속 변수들이 묶이게 되니까 서브 스레드에서 0.05초마다 값을 변경하는 로직이 정상적으로 작동하지 못하게 되고, 성능의 저하로 이어진다.

실질적으로, 멀티 스레딩이 필요할 정도의 복잡한 환경에서는 논리적 단위를 어디까지 끊을 것인가가 굉장히 어렵다. 어떤 경우는 아예 공용 자원을 사용하는 코드가 있는 함수 전체를 묶기도 하지만, 성능 면에서는 큰 손해를 본다. 그렇게 한다고 해도 한 군데에서만 실수가 있어도 없던 일이 되어버릴 수도 있다. 

---

멀티스레딩으로 발생하는 골치 아픈 상황이 또 있다. `데드락Deadlock = 교착 상태`는 여러 프로세스 간에서도 발생할 수 있지만, 대부분 멀티스레딩 프로그램에서 발생한다. 
	- 프로세스 간의 데드락은 OS로서도 해결책이 없어 재부팅해야 한다.

반면 멀티스레딩에서의 데드락은 대부분 개발자의 미스에서 발생한다. 데드락의 필수 조건으로, `두 스레드가 서로 다른 자원을 하나씩 소유한 채 서로 쌍방이 소유한 자원을 요청하고 기다림`이 있다. 이는 두 스레드 이상의 상황에서 모두 발생할 수 있다.

```
스레드 1 : A 자원 소유
스레드 2 : B 자원 소유
스레드 3 : C 자원 소유

스레드 1이 B 자원 요청 -> 스레드 2가 소유해서 블로킹됨
스레드 2가 C 자원 요청 -> 스레드 3이 소유해서 블로킹
...
```
대충 이런 상황. 위에서 크리티컬 섹션에서 배울 때, 블로킹되면 해당 스레드는 이용하고자 하는 자원이 언락될 때까지 유휴상태가 된다고 했다. 그래서 모든 스레드가 멈추는 상황이 발생함.

위 상황이 일어날까? 싶다면 **정말 흔하게 발생하는 일**이라고 한다. 운이 좋은 경우 타이밍적으로 어긋나서 발생하지 않을 수도 있지만, 발생할 수 있는 조건이 있다면 언젠가는 발생하고 프로그램은 멈춘다. 개발하는 입장에서도 원인을 찾기란 쉽지 않다.

책의 예제에서는 2가지 변수를 1씩 증가시키되, 서브 스레드에서는 b->a 순으로 락을 하고 메인 스레드에서는 a->b 순으로 락을 하는 상황일 때 데드락이 발생했으며, 두 스레드의 락 순서를 동일하게 해서 해결했다. `서로 다른 자원을 소유`하는 상황을 막은 것.

이렇게 까다로운 멀티스레딩을 쓰는 이유는 여러 가지가 있지만, I/O 처리 상황에서 특히 유용하기 때문이다.

# Blocked I/O vs Non-blocked I/O
어떤 CPU라도 입출력 기능은 반드시 갖고 있으며, 가장 기본적인 입출력이 메모리이다. CPU는 인스트럭션을 메모리에서 읽어와 수행하고 다시 저장한다. 

메모리 외에도 I/O 포트라는 걸 CPU가 갖고 있는데, 외부 장치와 통신할 수 있다. 여러 외부 장치(HDD, 프린터, 마우스, 키보드)를 연결할 수 있다. 어떤 경우는 `Memory Mapped I/O`라고 해서 메모리 연결 라인을 통해 데이터를 주고 받게 연결하는 장치도 있다.

어쨌든 CPU는 외부 장치와 데이터를 주고 받을 수 있고 이를 `I/O`라고 한다.

프로그램을 만들 때 사용하는 대표적인 I/O가 파일 입출력이다. 데이터를 읽고 쓰기 위해, 개발자는 단순히 OS나 C 컴파일러가 제공하는 함수를 호출하는 일만 하지만, 결과적으로 그 함수를 통해 외부 장치의 데이터를 읽고 쓸 수 있다.

하지만 이들은 **겁나 느리다.** 메모리도 CPU에 비하면 느린 편이라 CPU 내에 저장하는 캐쉬 메모리를 이용하는데, HDD 같은 기계 장치도 느릴 수밖에 없다. 그래서 CPU가 데이터를 읽어오려 하면 다른 인스트럭션을 수행할 수도 없고, 대기하는 수밖에 없다. 이를 `블로킹Blocking`되었다고 하며, 이런 방식의 I/O를 `Blocked I/O`라고 한다.

> 참고) 현대의 SSD도 느림. 저장 장치의 속도를 비교하면 CPU > RAM > SSD
> - CPU 내부 레지스터 및 메모리 : 접근 시간은 `ns` 내지는 `ps` 단위까지 내려가며, CPU 클럭 속도와 거의 동기화되어 작동한다.
> - RAM : 수십 `ns` 수준, 데이터 전송 속도는 `수십 GB/S`
> - SSD : `NVMe`의 접근 시간은 `수십~수백 마이크로초`, 순차 읽기/쓰기 속도는 `수 GB/S` 정도
> 	- `SATA`의 접근 시간은 `수백 마이크로초`, 최대 전송 속도는 `550MB/s` 정도.

이러한 대기하는 이슈를 위해 하드웨어와 소프트웨어의 개선이 이뤄졌다.

하드웨어의 경우 I/O 장치와 직접 통신하는 대신 중간에 `컨트롤러`를 둬서 컨트롤러와 통신을 시켰다. CPU는 컨트롤러에게 데이터를 읽기 위해 요청하거나 쓰기 위해 보내주기만 하고, 그 이후에 실제 장치랑 통신하면서 데이터의 읽고 쓰기가 완료될 때까지 기다리는 책임은 컨트롤러가 담당시켰다. 컨트롤러는 요청한 작업이 끝나면 `인터럽트Interrupt`라는 걸 통해 작업이 끝났음을 알린다. 

**`인터럽트`란 CPU에 마련된 특별한 핀에 시그널이 들어오면 CPU는 기존 작업을 중단하고 지정된 주소로 점프해서 작업을 수행하고 돌아오는 특별한 매커니즘**이다. CPU는 작업 중이던 레지스터의 주소값을 어딘가에 저장하고 미리 지정된 주소로 점프한 뒤, 해당 주소의 인스트럭션을 수행하고 `iret`이라는 특별한 인스트럭션을 만나면 앞에서 저장한 PC 레지스터의 값으로 다시 점프하게 된다.

예시로, 코드 중에 외부 장치로 대용량 데이터를 전송하는 작업이 있다고 하면, 해당 **코드는 컨트롤러에 전송할 데이터의 소스 주소, 타겟 주소, 전송할 양만 지정**하고 곧바로 기존에 수행 중이던 다음 인스트럭션을 실행한다. 컨트롤러는 지정된 주소끼리의 데이터 전송 작업을 하고, 이 작업이 완료되면 CPU에 인터럽트 신호를 준다. CPU는 인터럽트 종류에 맞춰 지정된 주소로 점프하는데, 점프할 주소는 개발자가 지정할 수 있도록 약속된 메모리나 레지스터에 저장한다. 이렇게 점프 주소를 저장하는 곳을 `인터럽트 벡터 테이블`이라고 한다. 

`인터럽트 루틴`에서는 일반적으로 해당 I/O 작업에 대한 완료 처리를 한다. 더 보낼 데이터가 있다면 다시 컨트롤러에 데이터 전송 요청을 하고, 전송 완료를 사용자에게 알려야 한다면 완료 메시지를 출력하도록 할 수도 있다. 

위와 같은 방식을 `Non-Blocked I/O` 혹은 `비동기 I/O`라고 한다.

---

그래도 여전히 문제가 있다. 하드웨어적으로 작업을 요청하고 다음 인스트럭션을 바로 수행할 수 있다고 해도, 개발자가 작성하는 코드는 I/O 결과를 알아야 다음 작업을 할 수 있는 경우가 많다. 이런 상황에서 Non-Blocked I/O로 동작하면 호출하자마자 데이터가 읽히기도 전에 리턴이 될 것이다. 중요한 건, **데이터가 다 읽힌 다음에 리턴이 되어야 한다**는 점이다.  이런 경우, `Non-Blocked I/O`는 실질적으로 `Blocked I/O`와 별다른 성능 차이를 보이지 않는다. **오히려 `Blocked I/O`가 훨씬 직관적이고 단순하게 프로그램을 만들 수 있다.** 실제로, 일반적으로 단일 응용 프로그램에서는 `Non-Blocked I/O`가 큰 의미가 없다. 파일 복사 프로그램에서 진행률 표시 외에, 파일이 복사되는 동안 할 일이 뭐가 있을까? 그리고 프로그램 작성도 훨씬 까다롭다. 

따라서, 실제로는 `Non-Blocked I/O` 방식으로 동작하지만, `ReadFile/WriteFile` 같은 `I/O용 API`들은 내부적으로 컨트롤러로부터 작업이 완료되었다는 인터럽트가 들어올 때까지 리턴하지 않고 블로킹하도록 만들기도 한다.  도스의 `getch`가 그런 함수였음.

하지만 멀티태스킹 OS에서는 매우 중요한 기능이다. 한 스레드가 I/O 작업을 하려고 할 때, 이게 끝날 때까지 CPU가 기다려야 한다면 다른 스레드가 모두 같이 대기해야 하는 상황이 벌어진다. 하지만 다른 일을 할 수 있다면 나머지 스레드들은 코드를 수행할 수 있다. 

이런 질문이 있을 수 있다 : "I/O를 요청한 스레드에서 ReadFile/WriteFile 등이 블로킹하고 있기 때문에 별 의미 없지 않나?" -> 하드웨어에서 `Blocked I/O`만을 지원해서 어쩔 수 없이 `I/O` 함수가 블로킹 하는 것과 내부적으로 OS 차원에서 대기하는 건 큰 차이가 있다. **하드웨어 차원에서 블로킹되면 CPU 자체가 멈추기 때문이다. 하지만 OS 단위라면 다른 스레드를 실행시킬 수 있다.**

즉, `I/O`를 요청한 스레드는 어차피 `Non-Blocked I/O`를 하드웨어가 지원하더라도 함수가 `Blocked I/O`처럼 동작하므로 성능 향상이 없지만, **나머지 스레드를 돌릴 수 있다는 게 큰 차이점이자 이득**이다. 

- 따라서 많은 경우 **하드웨어에서 `Non-Blocked I/O`를 지원하면서도 OS의 함수는 `Blocked I/O` 모드로 동작하는 게 일반적이다.**

# 멀티스레딩과 서버
태초에는 프로세스 + 스레드를 합쳐서 태스크라는 이름으로 불렀는데, 스레드가 분리된 이유는 크게 2가지가 있다.

1. 자연스러운 논리 흐름이 멀티스레딩과 부합하는 경우가 존재했다.

논리적으로 2가지 작업이 동시에 일어나야 하는 경우, 하나의 스레드에서 흉내내는 것보다 실제로 작업 갯수만큼 스레드를 만들어 각 작업에 할당하는 게 이상적일 수 있다. 
게임을 예로 들면 5명의 적이 화면에서 움직일 때 각각의 적마다 스레드를 만들어 독립적인 알고리즘으로 개별적인 수행을 하는 것이 더 이치에는 맞아 보인다. 물론 실제로는 완벽하게 독립적일 수는 없고(같은 맵에서 움직여야 한다고 하면 공유해야 하는 변수가 반드시 발생함), 멀티태스킹을 통한 구현은 효용성이 떨어진다. 
실제로 대부분의 게임은 단일 스레드로 동작하지만, 논리적으로는 그런 경우가 될 수 있다는 예시일 뿐이다. 

2. 실질적인 성능 향상

CPU가 하나라면 멀티스레딩은 성능적인 손해를 볼 수밖에 없지만, 2개의 스레드와 2개의 CPU가 있다면, 두 스레드는 논리적으로 독립된 수행을 하므로 각각이 하나의 CPU에 할당되어 수행될 수 있게 된다. 이 경우 문맥 전환이 필요 없어지고, 이론적으로 수행 시간도 절반으로 단축시킬 수 있다.
그렇지만 복수의 CPU를 사용한다면 "어떻게 작업을 분배할 것인가"라는 이슈가 있다. 

멀티 스레딩이 빛을 발하는 경우는, 여러 경우가 있지만, 특히 대용량 I/O 처리를 할 때이다. 

---

예를 들어 온라인 게임용 서버 프로그램을 작성한다고 하자. 네트워크 프로그래밍은 책 한 권 분량이지만 개념 위주로만 설명한다.

C로 파일을 열고 데이터를 읽고 쓰는 작업에 대해 정리해보면, C에서 제공하는 `fopen`이나 윈도우즈 API 함수인 `CreateFile` 함수로 파일을 열고 핸들을 얻는다. 그리고 핸들로 C의 `fread/fwrite`나 `ReadFile/WriteFile`이라는 API 함수를 호출해서 작업한다. 핸들이 필요한 이유는, I/O의 대상이 되는 장치(특정 파일)는 한 프로그램만 사용하는 것이 아니기 때문이다. 따라서 이러한 공용 장치로 I/O하는 과정은 항상 OS가 제공하는 I/O API 함수로 실행한다. 

네트워크 프로그래밍에서도 마찬가지인데, 네트워크 카드는 하나만 꽂혀 있지만 이걸로 수많은 다른 PC/장치와 통신한다. 따라서 일반적으로 이러한 네트워크 통신을 위해 핸들과 유사한 **`소켓`** 이라는 개념을 쓴다. 

`소켓`이 파일과 다른 점은, 파일은 여는 주체가 항상 사용자(프로그램)이고 사용자(프로그램)의 의지에 따라 읽히고 쓰이는 수동적인 존재라면, **소켓은 사용자가 연다는 개념이 아니라 상대방에게 접속을 하거나 당하는 2가지 입장을 다 갖는다**는 것이다. 데이터를 쓰는 건, 파일처럼 사용자의 의지대로 하지만 읽는 건 통신 상대방의 의지이다. 

따라서 파일을 다루는 프로그래밍과는 방식이 달라지는데, 데이터를 읽거나 쓰거나에 따라 열고 그에 맞춘 작업을 하는 것으로 완료될 것이다.

하지만 네트워크 프로그래밍에서는 접속이 이뤄지고 나면 상대방과 데이터를 주고 받으면서 데이터 내용에 따라 다음 행동이 결정되는 `프로토콜Protocol`이라는 게 있다. 즉, **상대가 보내는 것에 따라 내가 보내야 하는 규칙**이 발생한다.

네트워크 통신에는 접속하는 쪽과 당하는 쪽이 있는데, 당하는 쪽은 **불특정 다수에 대해 연결을 대기**한다. **상대가 접속하면 필요한 정보를 주고 `제공`하는 역할을 담당한다. 이를 `서버Server`** 라고 한다. 반대로 **접속하는 쪽은 상대방인 서버의 주소를 명확히 알고 있어야 하고, 접속한 뒤에 데이터를 주로 요청하는 입장**에 있게 된다. 이를 **`클라이언트Client`** 라고 한다. 

1:1 통신이라면 단일 스레드로 충분하다. 예제 코드를 보자.
```c
int main(int argc, char* argv[]) 
{
	char data[100];

	// 소켓 생성
	SOCKET s = socket(..);
	
	// 접속
	connect(s, 접속 주소);

	// Hello 문자 보내기
	send(s, "Hello");
	
	// 대기 - 답이 올 때까지 블로킹
	data = recv(s);
	
	if (data == "world")
	{
		printf("Correct Server");
	}
	else 
	{
		printf("Wrong Server");
	}
	
	send(s, "123");
	data = recv(s);
	if (data == "246") 
	{
		printf("Correct Server");
	}
	else 
	{
		printf("Wrong Server");
	}
	
	return 1;
}
```
- 전형적인 클라이언트 코드의 예제이다.
- 여기서 사용된 `connect, send, recv`라는 함수들은 모두 `BSD Berkeley System Distribution`이라는 미국 버클리 대학의 변종 Unix 시스템에서 제안한 네트워크 프로그래밍 라이브러리에서 정의된 함수이다. `버클리 소켓`이라고 불리는데, 미 국방성에서 BSD 시스템을 채용하면서 네트워크 프로그래밍의 표준 인터페이스가 되었음.
- 따라서 시스템을 막론하고 네트워크 프로그래밍 라이브러리를 제공하는 플랫폼에서는 버클리 소켓의 인터페이스를 기본으로 제공하며, 해당 플랫폼에 특화된 형식의 코드를 함께 제공한다. 
- 윈도우즈는 `WinSock`이라는 라이브러리로 `WSAConnect, WSA` 등의 새로운 함수도 제공한다.

중요한 건, 위 함수들 모두 CPU 입장에서는 네트워크 카드와의 I/O 함수이다. 따라서, `Non-Blocked I/O` 방식으로 동작하지만 함수는 `Blocked I/O`로 동작한다. 가령, `send` 함수를 호출하고 나면 전송 될 때까지, 혹은 전송 실패까지 리턴하지 않는다. (소켓 설정에 따라 바꿀 수는 있음)

일반적으로 클라이언트 프로그램에서는 단일 스레드로도 충분하다.

---

하지만 서버라면 얘기가 달라진다. 1:1 통신을 해도 마찬가지인데, 언제 통신이 들어올지 모르기 때문에 항상 대기하고 있어야 한다. `accept` 함수로 대기를 하는데, 이것도 `Blocked I/O` 방식으로 동작한다.

또, 서버는 단순히 대기만 하고 있으면 안된다. 서버가 클라이언트의 접속을 기다리기 위해 `accept` 함수를 호출하면, 이 함수는 접속 전까지는 블로킹 상태로 있게 되지만 1번째 클라이언트가 접속하고 나서가 문제다. 클라이언트가 접속하면, `accept` 함수는 접속한 소켓과 함께 리턴하고, 그 다음에는 접속한 소켓을 갖고 데이터를 주고 받는 작업도 해야 한다. 
```c
int main(int argc, char* argv[]) 
{
	char data[100];
	
	// 접속 대기 소켓 생성
	SOCKET server_sock = socket(...);
	
	// 클라이언트 소켓
	SOCKET client_sock;
	
	// 접속 대기
	listen(server_sock, ...);
	
	while (1) 
	{
		// 클라이언트 접속 대기, 접속하면 소켓 리턴
		client_sock = accept(server_sock);
		
		// 접속한 소켓으로 데이터를 주고 받음
		
		// 클라이언트가 bye를 보낼 때까지 반복
		do 
		{
			// 데이터 수신 대기
			recv(client_sock, data, ...);
			
			// Hello를 받으면 World를, 숫자를 받으면 2를 곱해준다
			if (data == "Hello") 
			{
				send(client_sock, "World", ...);
			} else if (data == 숫자) {
				send(client_sock, data * 2, ...);
			}
		} while (data != "bye");
		close(client_sock);
	}
	return 1;
}
```

클라이언트가 접속하고 나서를 생각해보자. 접속한 클라이언트가 `bye`를 보내기 전에는 `while`문을 빠져나올 수 없다. 즉, **다시 `accept` 함수를 부르지 않기 때문에 다른 클라이언트의 접속을 받을 수 없다.** 중간에 랜선이 뽑혔다고 하면, 접속이 끊기므로 접속의 단절을 알 방법이 있어야 한다. 이를 감지하고 다시 `aceept`로 클라이언트의 접속을 대기해야 하니까.

이렇게 끊기지 않았다고 해도, 누군가 접속 중이라면 다른 사람은 접속할 수 없기도 하다. 

따라서 이런 경우, 접속 중인 사람이 있더라도 뒤의 접속자를 대비해 항상 접속을 가능하게 만들고, 대신 인증 문자 등으로 뒤에 접속하는 사람이 우선권을 갖게 해야 한다. 하지만 위의 방식으로는 불가능하다. 

표준 소켓 라이브러리는 이런 문제를 해결하기 위해 `accept, send, recv` 등의 소켓 함수를 `Non-Blocked` 모드로 동작하도록 설정하는 옵션이 있다. 그러면 `accept` 함수를 불러도 곧바로 리턴한다. 대신 `select` 라는 함수만 블로킹을 하고 클라이언트가 접속한거나 이미 접속된 클라이언트로부터 데이터를 수신하거나 하면 리턴한다. 그리고 어떤 이벤트가 발생했는지에 따라 `accept` 함수나 `recv` 등을 불러 처리할 수 있게 된다. `select`는 소켓 배열을 받아 여러 개의 소켓을 처리할 수 있어서, 여러 클라이언트를 동시에 핸들링할 수도 있게 한다. 

위의 예시는 유닉스에서 단일 스레드로 서버를 제작하는 방법인데, 직관적이지 않다는 단점이 있다.

이를 멀티스레딩으로 바꿔 구현하면 아래와 같다.
```c
unsigned int ClientThread(void* pClientSock) 
{
    SOCKET client_sock = (SOCKET)pClientSock;
    // 접속한 클라이언트 소켓으로 데이터를 주고 받는다. bye를 보낼 때까지 반복.
    do {
        // 데이터 수신 대기
        recv(client_sock, data, ...);

        // Hello를 받으면 World를 보내주고, 숫자를 받으면 *2를 해서 보내준다.
        if (data == "Hello") {
            send(client_sock, "World", ...);
        } else if (data == 숫자) {
            send(client_sock, data * 2, ...);
        }
    } while (data != "bye");
    close(client_sock); // 클라이언트 소켓 종료
}

int main(int argc, char* argv[]) 
{
    char data[100];
    SOCKET server_sock = socket(...);
    SOCKET client_sock;

    listen(server_sock, ...); // 클라이언트 접속 대기

    while (1) {
        // 클라이언트 접속 대기, 접속 시 소켓 리턴
        client_sock = accept(server_sock);

        // 새로운 스레드를 만들어 접속한 클라이언트 소켓을 인자로 넘겨줌. 
        // 이후 클라이언트와의 통신은 새 스레드에서 진행
        CreateProcess(..., ClientThread, ..., client_sock, ...);
    }
    return 1;
}
```
메인 함수가 `accept` 함수에서 블로킹되어서 클라이언트가 접속할 때까지 실행이 멈추는 건 앞과 동일한데, **`accept` 후에 접속한 클라이언트 소켓과 통신하며 요청한 응답에 대응하는 작업을 새로운 스레드를 생성해서 한다**는 차이가 있다.

즉, **메인 스레드는 클라이언트가 접속하면 접속된 클라이언트에 매달리지 않고, 새로운 스레드를 생성해서 해당 스레드가 일 처리를 하게 하고, 자신은 다시 `accept` 함수를 불러서 다음 클라이언트의 접속을 대기**한다. 이렇게 하면 OS가 허락하는 한 새로운 스레드를 계속 만들며 해당 클라이언트와의 통신을 전담할 수 있게 된다. 코드가 심플해지고, 직관적이다.

이 방식도 유닉스에서 전통적으로 사용되던 멀티스레딩 서버 제작 방식이다. 

그러면 이 방식이 소켓 함수들을 `non-blocked` 모드로 동작하게 하고 `select` 함수를 사용해 단일 스레드로 처리하는 방식과 비교하면 좋은 점만 있을까? MS가 살펴보니 멀티스레딩이 생각보다 좋지 않았다. 

왜냐하면 접속한 클라이언트 수가 많을수록 `select`를 사용하는 단일 스레드 방식 서버에 비해 성능이 점차 떨어지게 된다. 멀티스레딩 방식은 접속된 클라이언트 수만큼 스레드가 만들어지고, 이 스레드들은 CPU가 스레드 갯수만큼 있지 않은 이상 OS가 계속 스케줄링을 통해 문맥 전환하기 때문이다. 

그래서 단일스레드 vs 멀티스레드는 어느 정도 단일 스레드가 좋다는 쪽의 결론이 났지만, 아직 의견이 분분하기는 하다. 실제 클라이언트의 I/O 작업 패턴, 양에 따라 상황이 달라질 수 있기 때문이다.

하지만 윈도우즈에서는 IOCP라는, 최강자 타이틀을 거머쥔 방식이 존재한다.

> 2025년으로 오면 어떻게 됐을까?
> 1. 클라이언트마다 스레드를 생성하는 방식은 높은 동시성 요구 환경에서는 비효율적이라는 게 명확함.
> 2. **단일 스레드 + select 모델의 아이디어가 진화, 이벤트 기반 비동기 I/O 모델이 고성능 네트워크 서버의 표준 아키텍처**가 되었다.
> 3. 실제 구현에서는 이벤트 루프와 워커 스레드 풀을 결합하거나, 언어/런타임 수준에서 지원하는 경량 스레드/코루틴을 활용하는 게 일반적이다
> 4. **IOCP는 여전히 윈도우 환경에서 가장 강력하고 효율적인 비동기 I/O 모델**이다.
# 윈도우즈의 최강자 서버 - IOCP
멀티스레드 얘기가 나온 김에 이것도 짚는 느낌이다.

`Overlapped I/O`라는 게 있다. 유닉스 계열에서는 I/O 장치를 포함한 모든 게 파일 형태로 존재하고, 외부 장치와의 I/O도 파일 입출력과 마찬가지의 형태로 이뤄진다. 윈도우즈에서도 이 부분은 어느 정도 마찬가지로, `RS-232C`로 대표되는 시리얼 통신 장치나 네트워크 소켓까지도 `ReadFile/WriteFile`로 데이터를 주고 받을 수 있다. **`Overlapped I/O`란, 이 두 API 함수가 `Non-Blocked I/O` 형태로 동작하는 걸 일컫는다.** 
- 이것 외에도, 내부적으로 실제 디바이스 - 응용 프로그램 간의 주고받는 데이터도 같은 메모리를 사용함으로써 데이터 복사 시간을 줄였다는 장점도 있다.

중요한 건, `Overlapped I/O`가 `Non-Blocked`으로 동작하면서 I/O 작업을 요청하고 다른 일을 할 수 있게 되었다. 근데 이 방식도 서버 프로그램의 기능을 떡상시키지는 못했는데, `Overlapped I/O` 방식으로 파일이나 장치가 오픈되면, API 함수들이 곧바로 리턴하긴 하지만 **요청된 I/O 작업이 끝났다는 사실을 프로그램이 전달받으려면 API 함수를 호출한 스레드가 `Sleep` 함수 등을 호출해서 `대기 모드Waiting Mode`로 들어가야 하기 때문**이다.  

`Blocked I/O`는 해당 API 함수들 자체가 완료되기 전에는 리턴하지 않으니까 작업 완료 통지가 필요 없지만, `Overlapped I/O`는 곧바로 리턴되므로 요청된 작업이 끝났다는 걸 알려주는 방식을 `콜백 함수`나 `이벤트 객체`를 통해 이뤄진다. `콜백 함수`는 함수의 주소를 넘겨주면 후에 그 함수가 호출되어 실행되는 방식이고, `이벤트 객체`는 해당 이벤트 객체를 `시그널링Signaling`하여 알려주는 방식이다.

예시로 보자.
```c
unsigned int OnComplete(void* pOverlapped)
{
	// ReadFile의 읽기 요청이 끝나서 전달받은 인자로 데이터 액세스 가능
}

int main(int argc, char* argv[])
{
	// ...
	
	// 데이터 읽기를 요청, 곧바로 리턴하고 읽기가 완료되면 OnComplete 호출
	ReadFileEx(..., OnComplete)
	
	// OnComplete 콜백 함수가 불리게 하기 위해서는
	// 자발적으로 Sleep 함수 등을 불러 대기 모드로 스레드를 전환시켜야 함
	Sleep(...);
	return 1;
}
```

`ReadFileEx`로 데이터를 읽어오라고 하면, `ReadFileEx`는 요청을 전달하고 리턴한다. 데이터가 다 읽히고 나면, 인터럽트가 걸리고 인터럽트를 처리하는 루틴에서 `ReadFileEx`를 호출할 때 `OnComplete` 함수를 불러준다. 

**문제는 어떤 스레드로 `OnComplete`을 수행시키느냐인데, `Overlapped I/O`에서는 `ReadFileEx`를 호출한 스레드에서 실행한다.** 

그러면 위 코드에서는 `main` 함수 내에서 `ReadFileEx`를 호출했으니, 메인 스레드가 `OnComplete` 함수를 실행해야 하는데, 만약 다른 코드를 실행 중이라면 어떻게 될까? 실행 중인 걸 멈추고 `OnComplete`를 실행할까?

아니다. 스택에도 `대기 큐Queue`라는 게 있어서 해당 스레드가 실행시키고자 하는 루틴의 시작 주소를 대기시킬 수 있다. 문제는 이 큐의 루틴을 실행하려면 기존에 실행하던 루틴에서 `Sleep` 같은 API 함수를 호출해서 스레드를 대기 모드로 전환해야만 한다. 

이게 어떤 문제를 발생시킬까? 위에서 말한 유닉스의 멀티스레딩 서버와 달라질 게 없다. 똑같이 대기 모드로 있다가 I/O 작업이 끝나면 리턴하는 방식임. 대기 모드로 들어가는 게 내장되어 있느냐 직접 지정해주느냐 차이일 뿐이다.

`ReadFile`을 쓰게 되면, `OVERLAPPED`라는 구조체 안에 `Event` 객체의 핸들을 지정해두고 이 이벤트 객체를 시그널링 해서 작업 완료를 알려준다는 점만 다르고 마찬가지이다.
```c
int main(int argc, char* argv[]) 
{
	HANDLE hComplete = CreateEvent(...);
	
	OVERLAPPED ov;
	ov.hEvent = hComplete;
	
	// 데이터 읽기 요청. 곧바로 리턴 후 읽기가 완료되면 이벤트 객체를 시그널링해줌.
	ReadFile(..., &ov);
	
	// hComplete 이벤트 객체가 시그널링될 때까지 스레드를 대기시킴
	WaitForSingleObject(hComplete, ...);
	
	// hComplete가 시그널링 되면 ov 구조체의 다른 인자들로 데이터에 액세스 가능
	...
	
	return 1;
}
```

결국  스레드가 많아짐 -> 문맥 전환이 많아짐 -> CPU 파워 낭비 라는 본질적인 이슈는 동일하다.

이를 해결하기 위해 MS에서 내놓은 게 `IOCP(I/O Completion Port)`이다.

IOCP는 "가장 이상적인 케이스는 문맥 전환의 오버헤들르 없애고, 모든 CPU 파워를 필요한 일에 집중시키기"라는 결론에서 나온 방식이다. 핵심은 **I/O 작업 스레드 간의 문맥 전환을 없앴다**는 것이다.

- `select` 방식의 단점 : CPU가 여러 개 있어도 단일 스레드로만 동작하므로 CPU를 1개만 사용함
- `멀티스레딩` 방식의 단점 : 스레드가 많아지면 효율이 떨어짐

이 두 방식의 단점을 극복한 게 IOCP 방식이다.

I**OCP 방식은 기본적으로 CPU 갯수만큼만 스레드를 미리 생성**한다. 대략적인 예시로, 시스템에 3개의 CPU가 있다면 3개의 스레드를 미리 생성한다. 그리고 **이 스레드들을 `스레드 풀Thread Pool`이라고 부르고, 각 스레드들을 `워커 스레드Worker Thread`** 라고 부른다. 

이것과 함께 필요한 것이 `IOCP`라는 객체이다.

IOCP도 **`Non-Blocked I/O`로 동작**한다. `Overlapped`이 I/O 작업의 완료를 호출한 스레드를 통해 콜백 함수를 실행해서 통지했다면, I**OCP에서는 IOCP 객체를 I/O 장치와 연동해 해당 I/O에 대한 작업 완료 통지가 IOCP 객체로 전달**된다. 이후 **IOCP 객체는 워커 스레드 중 대기 모드에 있는 걸 하나 선택해 해당 스레드를 통해 작업 완료**를 알려준다. 

어려운 이야기이니 예제로 들어간다.

1. IOCP 객체가 생성되었고, 파일을 하나 열었다. 열린 파일 핸들은 IOCP 객체와 연동되어 있다. 

2. 어떤 스레드에서 열린 파일로 `ReadFile` 함수를 호출했다. 이 때 파라미터 변수가 하나 넘어가는데, `OVERLAPPED` 구조체라 불리는 변수로, 작업 완료 시의 신분증 역할을 한다. 즉, 어떤 I/O 작업이 완료되었는지를 파악할 수 있게 한다.

3. 이 `ReadFile` 함수는 `Non-Blocked` 모드로 동작하고, I/O 장치로 데이터를 읽으라고 요청하고 곧바로 리턴한다.  

4. I/O장치의 데이터 읽기가 완료되면, 이 사실이 IOCP 객체로 전달된다. 이 때, `OVERLAPPED` 구조체 변수가 함께 날아온다.

5. IOCP 객체는 내부적으로 큐를 갖고 있어서, 완료된 작업에 대한 목록을 `OVERLAPPED` 구조체 변수와 함께 저장한다. 

6. 스레드 풀에 있는 스레드 중 대기 모드에 있는 스레드를 선택해 미리 주어진 함수가 실행된다. 이 때, 함수의 인자로 넘어가는 것이 `OVERLAPPED` 구조체 변수이다.
- 즉 `ReadFile`에서 넘겨준 `OVERLAPPED` 구조체 변수는 데이터가 다 읽히고 나면 스레드 풀에 있는 하나의 스레드가 실행되면서 인자로 넘어가게 된다.

IOCP의 장점은, **CPU 갯수만큼 스레드를 생성**하고 이것들만으로 모든 I/O작업을 하므로 **쓸데 없는 문맥 전환이 일어나지 않는다. 또, 단일 스레드와 달리 쉬는 CPU가 발생하지도 않는다.**  스레드 풀을 사용해서 얻는 이점으로, 스레드를 생성하는 수고를 덜게 된다. 

비유) 자동차 공장과 작업공. 모터는 컨베이어 벨트를 돌리는 요소라고 해보자.
- 단일 스레드 : 한 사람이 모든 공정을 책임지는 방식. 모터가 더 있어도, 컨베이어 벨트가 하나라서 활용할 수 없다.
- 멀티 스레드 : 부품 종류 수만큼 작업자와 컨베이어(스레드)를 늘리는 방식. 모터가 컨베이어 수만큼 있지 않다면, 적은 수의 모터만으로 여러 벨트를 오가면서 써야 한다.
	- 벨트가 3개인데 모터가 1개라면 컨베이어를 돌리는 시간보다 모터를 옮기는 데에 시간을 다 쓴다.
- IOCP : 모터에 중점을 둔 방식으로, **모터 수만큼 컨베이어와 작업자를 마련**하는 방식.

슬슬 글이 눈에 안 들어온다. 새벽 3시여서 대충 이 정도의 개념만 잡고 마무리함.

