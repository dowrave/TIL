# 프로세스 vs 메모리
- 프로그램을 만들 때, 흔히 다른 프로세스와의 공존을 신경쓰면서 제작하지는 않는다.

이런 제작 방식이 단일 프로그램을 실행하는 OS 하에서는 당연했지만, 멀티태스킹 OS 상에서는 당연한 게 아니다. 프로그램은 PC 위에서 수행 중인 여러 프로세스 중 하나이고, 이들은 모두 공통된 하드웨어 자원을 사용하기 때문이다. 따라서, 이러한 **여러 프로세스가 동시에 시스템에서 돌아가려면 각 프로세스가 서로 정해진 규칙 하에 메모리나 I/O 장치 등을 독점하지 않고 나눠 써야 한다.**

가장 중요한 자원은 CPU, 메모리다. 
- 시스템 전체 스레드의 갯수는 OS가 `스케줄링`을 통해 해결해준다. 
- 메모리의 경우, 프로그램이 실행되면 코드와 데이터가 메모리에 올라가야 하며, 동적으로 메모리가 더 필요할 수도 있다.
	- 어쨌든 한 프로그램에서는 최소 자신의 코드 + 데이터 사이즈만큼 메모리를 써야 해서, 멀티 프로그래밍 OS에서는 동시에 여러 프로그램이 돌아가니까 **프로세스에 따라 메모리도 구분해서 사용**한다. 파워포인트는 0~1000번지까지, 워드는 1001~2000번까지 사용하는 방식임.

그런데 **응용 프로그램을 개발하는 시점에서는 그 프로그램이 돌아갈 환경을 예측할 수 없다.** 함께 돌아가는 프로그램, 설치된 메모리 양 등을 전혀 알 수 없다. 

하드웨어 사양이 낮았던 시절에는 게임, 컴파일러, 워드 등 많은 데이터를 필요로 하는 프로그램은 메모리 한계를 극복하기 위해 개발자가 프로그램 구조를 잘 조절해야 했다. 게임이라면 이미지를 다 로드하는 대신 매 스테이지마다 한다든가, 워드에서는 눈에 보이는 데이터만 메모리에 유지하고 스크롤마다 갱신한다든가 하는 식의 관리를 개발자가 작업했다.

외부 데이터가 많은 경우는 그나마 나은 편인데, 코드 자체의 사이즈가 큰 경우는 더 난감하다. 데이터는 필요에 따라 로드할 수 있지만 코드는 이런 정리 과정이 더 복잡해질 수밖에 없기 때문이다. 

위의 문제들은 지금의 윈도우즈 같은 OS에서는 별 게 아닌 기능이 되었지만, 도스 시절에는 개발자가 모듈을 구성할 때 다 알아서 처리해야 했다. 
- 메모리의 로드 위치, 로드를 위해 어떤 코드나 데이터를 메모리에서 제거해야 하는지 등, 메모리에서 실제 프로그램이 어떻게 동작하는지를 꿰고 있어야 했다. 

하지만 지금은 이런 부분에 대해 걱정하지 않아도 된다. OS가 똑똑해졌기 때문이다.

이제 프로그램은 컴퓨터에 메모리가 얼마나 꽂혀있든 32비트 컴퓨터 기준 총 4gb라는 메모리 공간을 마음대로 활용할 수 있게 되었다.(엄밀한 의미에서는 다소 제한이 있다. OS에서 직접 메모리에 접근하는 건 위험한 일임.) 

그리고 이 공간이 다른 프로그램에 의해 침범당할 우려도 없는데, **모든 프로그램이 자신만이 쓸 수 있는 4gb의 메모리를 할당**받아 쓰기 때문이다. 실제로 램이 몇 개 꽂혀 있든, 10개의 프로그램이 돌아간다면 총 40gb의 메모리가 배정되는 것이다. (실제로 이 때 당시 가정용 pc에 40gb를 꽂는 경우는 없었음. 지금은 64gb도 꽂지만..)

게다가 모든 메모리는 0번지부터 시작해서 주소가 겹치는데, 그럼에도 서로의 영역을 침범하지 않는다.

이렇게 **각 프로세스마다 받아 사용하는 고유의 메모리를 `가상 메모리Virtual Memory`** 라고 부른다. `4gb`로 제한되는 이유도 단순히 cpu가 32비트이기 때문으로, 32비트 cpu에서는 모든 레지스터가 32비트로 이뤄져 있고, 이는 읽어올`Fetch` 인스트럭션 주소를 지정하는 `프로그램 카운터PC`레지스터의 경우도 마찬가지다. **32개의 비트로 표현할 수 있는 범위가 0 ~ 4gb**라서 4gb인 거고, 64비트라면 `2^64`의 가상 메모리를 사용할 수 있다는 것이다.

그렇다면 OS가 가상 메모리를 사용하게 하는 것일까?

# 프로그램이 실행되기까지

우선, 프로그램이 어떤 과정을 거쳐 실행되는지를 보자.

```c
#include <stdio.h>

int Add(int a, int b)
{
	return a + b;
}

main() 
{
	int Sum = Add(3, 5);
	printf("3 + 5 = %d\n", sum);
}
```
이 코드를 타이핑하고 빌드 버튼을 누르면, 실행 파일이 생성된다.
그런데 고급 언어로 작성된 코드가 컴파일을 거쳐 곧바로 실행 가능한 파일이 되는 것은 아니다. `링킹Linking`이라는 과정을 거친다.

우선, C 소스 파일을 컴파일러가 해석한다. 타겟 CPU에 따른 적절한 인스트럭션을 생성한다.

위부터 쭉 소스를 훑으면서 먼저 나온 `add` 함수에 대한 인스트럭션을 생성하고, `main` 함수의 코드도 생성한다. 그런데 `main` 함수는 `add`와 `printf`를 호출한다.

위 과정을 수행하기 위해, 컴파일러는 앞에서 본 코드 중 `add` 함수가 있는지를 살펴본다. 위 예시의 경우는 당연히 문제가 없을 것이다.

그 다음으로 **`printf`를 호출**하는 루틴을 만나는데, `add`와는 상황이 다르다. 
우선, **`printf`라는 것이 무엇인지를 검사**한다. 이 과정에서 `#include<stdio.h>`에 기술된 `stdio.h`라는 파일도 함께 검사한다. 하지만 이 안에는 **단순히 `형Prototype`만 정의되어 있고 실제 `printf`를 구현하는 내용은 없다.**
여기서 컴파일러는 중요한 결정을 한다. **`printf`라는 함수가 존재하는 것인지를 검사**한다. 형이 존재하는 건 확인했으니, `printf`을 호출하는 부분에서 인자 등이 `stdio.h`에 정의된 **형식에 맞게 호출하고 있는지를 확인하고, 이상이 없다면 무사히 컴파일을 마치게 된다.**
문제는, 이 `printf`가 문법에 맞다는 건 확인했지만 **이 함수를 호출하는 인스트럭션 `call`을 생성하려고 해도 함수가 구현되지 않았기 때문에 `call` 인스트럭션의 타겟 주소를 생성할 수 없다.**
하지만 컴파일러는 **`printf`가 정의되어 있기 때문에, 다른 소스 파일이나 라이브러리에 구현되어 있을 것이라 믿고 `call` 인스트럭션의 타겟 주소 생성을 뒤로 미루게 된다.** 대신, `printf`를 호출하고 있다는 일종의 체크만 해둔다.

위 과정으로 컴파일러에 의해 생성된 파일이 `목적파일`인 `.obj` 파일이다. 소스코드가 `xxx.c`였다면 오브젝트 파일은 `xxx.obj`가 된다. 목적 파일은 완전한 실행 코드가 아니다. `printf`라는 함수를 호출하는 부분이 생성되지 않았기 때문인데, **남은 부분을 `링커Linker`가 맡는다.**

**링커는 컴파일러가 생성한 `목적 파일`과 따로 지정된 `라이브러리 파일`들을 모두 검사한다. 이들을 합쳐서 최종적으로 실행 파일을 생성한다.** `yyy.lib`라는 라이브러리 파일이 있다면, 링커는 `xxx.obj`와 `yyy.lib`을 합쳐서 최종적으로 `zzz.exe` 파일을 생성한다. 
링커는 컴파일러가 목적 파일에 체크해둔 부분을 완성한다. 프로젝트 상의 모든 목적 파일과 지정된 라이브러리를 검사해서 체크한 함수가 존재하는지 확인하고, 존재한다면 실행 파일에 복사해와서 복사된 주소를 호출하도록 체크한 부분을 채워넣는다.
최종적으로, `add, main`이라는 함수의 코드는 `xxx.obj` 파일에서 가져오고, `printf`는 `yyy.lib`에서 가져와서 컴파일러가 체크해둔 부분을 찾아 최종적으로 `printf`의 코드가 있는 곳을 호출하도록 코드를 완성한다.

위 과정은 함수 호출 외에도 전역 변수 참조에서도 마찬가지이다. `abc.c` 파일에서 선언된 `int VAR` 전역 변수를 `xyz.c`에서 참조하고 싶다면, `xyz.c`에서 `extern int VAR`로 선언해줘야 한다. 그러면 컴파일러는 `xyz.c` 소스 파일을 컴파일하면서 VAR 변수 공간을 생성하는 대신 VAR을 참조하는 곳마다 체크해둔다. 컴파일러가 `abc.obj`와 `xyz.obj`을 생성하면, 링커가 모든 목적 파일과 지정된 라이브러리 파일을 검사하고 취합한다. 

이러한 링커가 하는 작업을 `링킹Linking`이라고 한다.

링킹 과정에 대해 더 자세히 살펴보면, `add`와 `printf` 함수를 호출하는 부분은 `call add, call printf` 인스트럭션으로 번역된다. `call` 인스트럭션은 지정된 타겟 주소로 점프하라는 명령인데, 타겟 주소를 결정하는 게 중요하다. 
`add`가 100바이트, `main`이 150바이트, `printf`가 70바이트이고 프로그램이 메모리로 넘어올 때 500번지라고 하면, `call` 인스트럭션의 타겟 주소는 `add`에서는 `500`, `printf`에서는 `750`이 된다. `printf`는 `add + main` 만큼 뒤에 위치하니까.
그런데 **프로그램이 메모리로 로드되는 최초 주소는 상황마다 달라진다.** 0번지로 넘어온다면 `add`는 `0`, `printf`는 `250`이 된다. 이런 케이스가 있기 때문에 링커가 주소를 결정해서 코드를 수정한다. 

> 솔직히 정확히 이해는 안 되어서 제미나이랑 얘기를 좀 해봄
> - 컴파일러 : 소스 코드를 기계어(오브젝트 파일)로 번역. 다른 파일의 함수, 변수의 위치는 정확히 모름. 주소는 상대적이거나 미완성 상태.
> 	- 컴파일러 단계에서 링킹이 불가능한 이유
> 		- **컴파일러는 한 번에 하나의 소스 파일만을 처리**한다. 외부 라이브러리 파일 안에 있다면, 해당 파일을 열어서 내부 코드를 보지 않는다.
> 		- **라이브러리는 이미 컴파일됨.** 컴파일러가 기계어 코드를 참조해서 주소를 알아내는 건 역할 범위 밖이다.
> 		- **최종 주소 미정.** 컴파일러가 라이브러리 코드의 위치를 알 수 있다고 하더라도, 프로그램 전체가 메모리의 어느 시작 주소에 위치할 지는 알 수 없다.
> - 링커 : 여러 오브젝트 파일과 라이브러리를 합쳐 하나의 실행 파일 생성. 외부 함수의 실제 위치를 찾아 연결`심볼 해석`** 하고, 프로그램이 메모리에 로드될 위치를 기준으로 코드 내의 주소들을 최종적으로 결정하고 수정`주소 재배치`
> 	- 그러면 링커는 프로그램의 시작 주소를 어떻게 알까?
> 		- 링커도 **프로그램이 실행될 때의 최종적인 실제 메모리 주소를 정확히 알지는 못한다.** 하지만 실행 파일을 만들기 위해 **`가상의 시작 주소Base Address`를 가정해서 작업을 수행**한다.
> 		- 위에서 말한 `주소 재배치`라는 개념이 이건데, 링커는 **프로그램이 메모리에 로드될 가상의 시작 주소를 가정**하고, 가상 시작 주소를 기준으로 모든 함수와 데이터의 가상 절대 주소를 계산하고, `call` 명령어 등에서 사용하는 주소를 이 계산된 주소로 수정한다.
> 			- 여기서 말하는 **가상** 개념이 `가상 메모리`와 이어지는 개념임
> 		- 프로그램을 실제 메모리에 로드하고 실행하는 건 OS의 `로더Loader`가 하는 역할이다. 링커는 미래의 OS가 프로세스를 OS의 어디에 띄울 지 알 수 없다.

> 참고) 내부 구성에 따라 코드 내에 작성되어 있던 `add` 함수를 호출하는 부분 역시 절대 주소로 지정되려면 링커가 결정할 수 밖에 없다. 이건 사실 컴파일 옵션에 따라 달라져서, 절대시작주소를 컴파일러가 지정하게 할 수도 있고, `printf`처럼 링커에게 맡길 수도 있다.

하지만 위처럼 절대 주소를 사용하는 방식은, OS가 있는 환경이라면 힘들어진다. 임베디드 시스템의 펌웨어는 별도의 로딩 과정 없이 롬이나 플래쉬 메모리에 직접 바이너리를 물리적으로 적재시키지만, **OS는 파일 시스템을 이용하고 이를 통해 동적으로 실행 바이너리를 로드**하기 때문이다.

왜 문제냐면, OS 자체도 하나의 프로그램 코드라서 메모리에 상주하고, 이 코드나 데이터 크기가 동적으로 변한다든가, OS가 버전업이 되어서 사이즈가 바뀐다든가 할 때, 절대주소 체계를 쓰고 있다면 재컴파일 / 링킹이 필요해진다. 멀티 프로그래밍을 지원한다면 마찬가지로 메모리의 상황이 시시각각 바뀐다.

이런 불편함을 없애는 게 `재배치Relocation` 및 `적재 시간 주소 바인딩 Load Time Address Binding`이다. 

**`주소 바인딩`이란 주소를 코드와 결합**시키는 것이다. 앞에서 `call` 인스트럭션을 통해 다른 함수를 호출하려 했는데 이 호출될 함수의 주소를 언제 결정하느냐 하는 문제가 있어서 생긴 개념이다. 
위에서 `링커 or 컴파일러`가 절대 주소를 생성하는 과정은 **`컴파일 시간 주소 바인딩`** 이라고 부른다. 즉, **컴파일 과정에서 주소가 결정**되는 것이다. 구조가 간단하지만, **환경이 바뀌어 로드 지점이 달라지만 컴파일을 다시 해야 한다.** 도스 시절에는 `com 파일`의 형태로 이를 지원했다.

이를 해결한 게 **`적재 시간 주소 바인딩`** 이다. **프로그램을 메모리로 로드할 때 주소를 결정**하자는 것이다. 컴파일 과정에서 컴파일러나 링커가 메모리 주소를 필요로 하는 인스트럭션의 주소를 결정하지 않는다. 대신, 메모리로 로드되는 시점에서 주소를 확정 짓도록 하는 것이다. 

이를 위해 프로그램은 `재배치`가 가능한 형태로 컴파일되어 있어야 한다. 즉, 컴파일러는 메모리 주소가 필요한 인스트럭션에서 절대주소를 만드는 대신 0번지를 기준으로 한 상대 주소만 생성하고, 실행 파일의 헤더에 인스트럭션의 위치를 표시해두는 것이다. 그러면 로더가 프로그램을 로드하면서 로드된 시작 지점의 주소를 상대 주소에 더해 최종적인 타겟 주소를 만드는 것이다.

여기서 한 단계 더 업그레이드 된 것으로, `실행시간 주소 바인딩Execution Time Address Binding`이 있다. 주소의 결정 타이밍이 컴파일도, 메모리로 로드되는 시간도 아니다. 최종적으로 **CPU가 해당 인스트럭션을 실행시킬 때 결정**하는 것이다. 이게 왜 필요할까? OS 만으로 가능할까?

# 멀티 프로그램을 위한 메모리 관리
멀티 프로세싱은 여러 프로세스가 **번갈아가면서** 작업을 진행하는 방식이고, 이 과정에서 `문맥 전환Context Switching`이 발생한다. 그런데 메모리가 2개의 프로세스를 모두 온전히 담지 못한다면, 문맥 전환과 함께 `스와핑Swapping` 과정을 거쳐야 한다.

**스와핑이란, A 프로세스의 문맥 정보, 즉 코드나 데이터, 레지스터 백업 값 등을 메모리에서 보조 기억장치로 옮긴 뒤, 새로 실행되는 B 프로세스의 문맥 정보를 읽어오는 것**을 말한다. 하드디스크로 빼내는 것을 `롤 아웃Roll Out`, 반대를 `롤 인Roll In`이라고 한다. I/O 과정이니까 문맥 전환보다도 훨씬 오래 걸릴 것이다.

가장 쉬운 해결책으로 `다중 분할 할당Multiple-Partition Allocation`이 있는데, 대용량의 메모리를 쓰고 한 프로세스가 모든 메모리를 차지하지 않고 메모리가 가득 찰 때까지 모든 프로세스를 메모리에 보관하고 스와핑하지 않는 것이다. 이후 생성된 프로세스는 가용 메모리 공간이 생길 때까지 기다리게 하는 방법이다. 

여기서 발생하는 문제점은, 
1. 메모리 공간이 나지 않으면 들어오려는 프로세스는 무한 대기. 
2. 메모리의 위치와 크기에 따라 프로세스 할당이 해제되더라도 새로운 프로세스가 들어오지 못할 수도 있음. `단편화Fragmentation`라는 이슈로, 단순히 메모리에 얼마의 공간이 있느냐가 문제가 아니라 **연속된 공간이 얼마 있느냐가 중요하기 때문이다.**
	- 여기서의 단편화는 특히 `외부 단편화External Fragmentation`라고 한다.

외부 단편화 문제를 해결하기 위해, 빈 공간을 활용하는 여러 방법이 알려져 있다. 자잘한 빈 공간을 몰아서 큰 공간을 만드는 `압축Compaction`이라 불리는 방법이 있다. 빈 공간을 찾는 여러 방법이 있지만, `다중 분할 할당` 자체가 선호되는 방법이 아니니 패스. `압축`도 현재 메모리상의 프로세스를 이어붙여야 하는데 컴파일 타임 / 적재 시간 주소 바인딩으로는 해결하기 어렵다. 프로세스가 실행되기 전에 인스트럭션의 타겟 주소값들이 결정나버려서 함부로 옮길 수 없기 때문이다.

여기서 필요한 게 **`실행시간 주소 바인딩Execution Time Address Binding`이다. 인스트럭션의 타겟 메모리 주소가 해당 인스트럭션이 CPU에 의해 패치되기 직전에 결정나게 하는 방식이다.**

이를 구현하기 위해, **컴파일러나 링커는 `call printf` 코드를 생성할 때 항상 0번지를 기준으로 시작한다고 전제하고 타겟 주소를 생성**한다. 그러면 `call 0x0` 같이 주소가 생길 거다. 이 코드가 **CPU로 패치되는 시점**에서, 비로소 **`메모리에 위치한 프로세스의 시작 주소`에 더해져 최종 주소가 결정**된다.

실행시간 주소 바인딩은 OS의 힘만으로는 구현하기 힘들다. 매 인스트럭션 수행마다 OS로 다시 제어권이 넘어가 수행되고, 다음 인스트럭션의 주소 바인딩을 위해 인스트럭션을 수정해서 다시 메모리에 저장해야 하는데 속도가 엄청 떨어진다. 따라서 하드웨어의 지원이 필수로 대부분 지원하고 있음.

한 예시로, 메모리를 참조하는 인스트럭션은 CPU가 읽을 때(`Fetch`) 그냥 읽지 않고 타겟 주소를 항상 특정 레지스터 값에 더해서 읽는다. (`재위치Relocation 레지스터`) 그러면 각 프로세스는 실행될 때 필요한 자신의 주소를 문맥이 전환될 때마다 재위치 레지스터에 저장하는 것만으로 모든 메모리 주소를 참조하는 인스트럭션이 정상적인 메모리를 참조할 수 있게 된다.

즉, `컴파일러`의 0번지에서 시작하게끔 하는 컴파일 + `OS`의 프로세스 활성화 시 시작 주소를 재위치 레지스터에 저장 + `CPU`의 메모리 참조 인스트럭션일 때 항상 주소 값을 재위치 레지스터 값에 더함 이라는, 컴파일러, OS, CPU 각자의 역할이 있는 것이다.

하지만 이 방식으로도 문제가 있다. 압축을 어느 시점에 할 지도 문제고, 압축하더라도 프로세스가 늘면 메모리가 가득차게 될 것이다. 그 이후의 프로세스는 무한 대기해야 하나? 아니면 스와핑해서 문맥 전환마다 한 프로세스 전체를 하드로 롤인했다가 롤아웃해야 할까? 둘 다 비현실적이다. 

그럼에도 대부분 아무 문제 없이 윈도우에서 수많은 창을 띄우고 작업할 수 있는데, 이건 `페이징` 때문에 가능하다.

# 페이징

- 앞서 발생한 문제점
멀티 프로그램을 구현하기 위한 하나의 방법이 다중 분할 할당이었음. OS의 스케줄링을 통해 각 프로세스가 조금씩 실행되는 게 최우선이나, 문맥 전환마다 스와핑하는 건 비효율적이라 다중 분할 할당을 택했다. 하지만, 메모리가 가득 찼을 때는 스와핑한다든가, 후속 프로세스가 대기한다든가, 외부 단편화가 발생한다든가.. 등의 이슈가 있었다.

- 단편화 아이디어 : 프로세스를 꼭 연속된 공간이 아니라 **잘 쪼개서** 빈 공간에 넣으면 어떨까?
- 스와핑 아이디어 : 프로세스를 통째로 롤아웃/롤인하지 않고, **조금씩** 하는 건 어떨까?

---

프로그램에는 `구역성Locality`이라고 하는 성질이 있다. 

- 배열의 연속된 공간에 잡히는 성질
- `for`문의 같은 구역에서 실행되는 코드
- `스택`의 연이어 쌓이는 데이터
- `지역 변수`의 위치가 인접함
- 모든 프로그램은 순차적으로 실행됨. 위에서 아래로.

위의 성질들이 구역성인데, 구역성에는 `공간 구역성Spatial Locality`과 `시간 구역성Temporal Locality`이 있다.

**공간 구역성이란, 어떤 프로세스가 메모리의 한 곳을 액세스하기 시작하면 인접한 곳도 사용될 확률이 높다**는 걸 의미한다. 순차적인 코드, 배열 등등.

시간 구역성도 비슷하지만, 약간 관점이 다르다. **시간적인 관점에서 한 번 액세스된 데이터는 다시 액세스될 확률이 높음**을 의미한다. 변수 `i`에 대한 루프를 돌 때, `i`는 시간적으로 가까운 시기에 여러 번 읽히게 된다. 스택도 함수 안에서는 계속 액세스되니까 시간구역성이 있다.

구역성이 왜 중요할까? : **한 프로세스는 메모리의 여기저기를 오가면서 실행되는 게 아니라, 비슷한 구역의 데이터를 비슷한 시간에 몰아서 액세스하는 경향**이 있다.

즉, 프로세스의 모든 부분을 메모리에 다 올려서 항상 쓰는 게 아니라, 각 프로세스마다 **현재 수행 중인 코드나 액세스되고 있는 데이터 근방의 일정 크기만큼만 메모리에 올리면**, 적어도 한 동안은 그 안에서만 액세스가 일어나므로 많은 메모리가 필요 없다.

하지만 언젠가는 다른 구역의 데이터/코드를 액세스하는 시점이 온다. 그 때에도, 공간구역성을 활용해서 프로세스 전체를 스와핑하지 않고 **액세스가 발생한 작은 영역에 대해서만 스와핑**하면 속도도 빨라지고 들어온 데이터는 한동안 활용되므로 스와핑이 자주 발생하지도 않을 것이다.

따라서, 이 경우 프로세스 전체를 문맥 전환이 일어날 때마다 스와핑하는 부담이 사라진다.

단편화 문제도 쉽게 해결될 수 있다. **구역의 크기를 일정하게 하면 외부 단편화가 발생하지 않는다.** **프로세스를 4kb 단위로 쪼갠 걸 `페이지`, 메모리를 쪼갠 걸 `프레임`** 이라고 하자.

예를 들어, 파워포인트를 실행했다고 하자. 예전과는 달리, **OS는 실행 파일에서 코드랑 데이터를 메모리로 로드하지 않는다.** 프로세스라는 형식만을 갖춘다. 곧 OS는 파워포인트로 문맥 전환을 한다. 이걸 모른 채 CPU가 PC 레지스터가 가리키는 메모리 주소에서 인스트럭션을 패치해오게 되면, CPU는 메모리에서 값을 읽는 대신 `메커니즘`에 의해 패치하려는 메모리 주소에 정상적으로 프로세스의 코드 혹은 데이터가 올라왔는지를 살펴본다. 지금의 경우, 프로세스만 생겨 있고 코드나 데이터가 로드된 건 아니니까 에러를 발생시킨다. 이러한 에러를 `페이지 폴트Page Fault`라고 부른다. 

페이지 폴트는 일종의 인터럽트로, 인터럽트가 걸린 CPU는 수행하던 걸 멈추고 종류에 따라 이를 처리할 수 있는 코드로 점프한다. 페이지 폴트를 처리할 코드는 OS 자신이 되는데, 부팅 때 이런 작업을 미리 해둔다.

1번째 페이지 폴트가 발생하면, OS의 페이지 폴트 코드로 CPU가 점프한다. 이 코드는 **필요한 페이지를 메모리로 로드하는 역할**을 수행한다. 이 루틴이 리턴하고 나면 CPU는 하던 일을 계속한다. 즉, 메모리에서 인스트럭션을 읽어온다. 지금은 페이지가 로드됐으니, CPU는 정상적인 인스트럭션을 패치할 수 있게 되었다.

곧 다음 코드를 수행할텐데, 일반적으로는 페이지 폴트가 발생하지 않는다. `4kb`에 해당하는 한 페이지만큼을 읽어왔기 때문에, 지역성에 의해 다음 인스트럭션도 이 `4kb` 안에 있을 확률이 높기 때문이다. 

만약 페이지 폴트가 또 발생하더라도, 다시 페이지 폴트 루틴이 실행되어서 폴트가 발생한 페이지를 읽고 메모리의 프레임 중 적절한 곳에 배치할 것이다. 

이런 식으로 프로세스의 전체 코드, 데이터를 메모리로 로드하지 않고, CPU가 읽어갈 때마다 페이지가 메모리상에 로드되었는지 여부를 검사하고 없다면 로드시키고 수행을 재개하는 방식을 `요구 페이징Demand Paging`이라고 한다. 즉, `요구`할 때마다 페이지의 부재 여부를 확인해서 없다면 로드하는 것이다.

요구 페이징의 장점으로는
1. 다중 분할 방식보다 훨씬 많은 프로세스를 동시에 수행할 수 있다. 당장 수행에 필요한 코드, 데이터만을 올리기 때문이다.
2. 외부 단편화가 발생하지 않는다. 4kb보다 작은 3kb 같은 페이지가 로드되는 경우가 있는데, 이것도 단편화를 발생시킬 수 있다. `내부 단편화`라고 하는데, 그래도 외부 단편화보다 훨씬 작은 용량이 낭비되는 것이다.

# 페이징을 활용한 가상 메모리
- 용어 정리
	- `페이지` : 프로세스를 쪼갠 단위
	- `프레임` : 메모리를 쪼갠 단위

페이지 폴트가 발생했다면, 어느 프레임에 페이지를 로드해야 할까?

1. 프로세스의 형태를 지니면서 순서대로 채워나간다 : 페이징의 장점이 없어진다. 한꺼번에 모두 올리지 않았다 뿐이지 언젠가 올릴 공간을 확보하는 것이니까. 

2. **페이지를 임의의 프레임에 로드할 수 있어야 한다.** 

하지만 CPU는 순차적으로 프로세스의 코드를 수행하는데, 페이지가 메모리의 이곳저곳에 있다면 순차 수행이 애초에 불가능하다.

여기서 등장한 게 `가상 메모리Virtual Memory`이다. 실제 물리 메모리 주소와 CPU가 읽고 쓰는 메모리 주소가 1:1 매치되는 것이 아니라, **중간에 어떤 룰을 정해서 CPU가 요구하는 논리적 주소와 실제 메모리 주소의 물리적 주소를 변환하는 발상**에서 비롯되었다.

**`페이지 테이블Page Table`이라는 걸 마련해서 실제 메모리 주소와 CPU가 읽으려 하는 논리 주소를 변환**한다.

페이지 테이블을 어떻게 구성해야 할까?

논리 주소 상의 페이지 번호를 실제 메모리 상의 프레임 번호로 바꾸는 게 목표다. 페이지 크기 = 프레임 크기이므로 한 페이지는 한 프레임으로 그대로 맵핑되며, 오프셋도 그대로 사용할 수 있다.

페이지 테이블에서 **페이지 번호로 프레임 번호를 찾는 가장 쉬운 방법은 페이지 번호를 테이블의 인덱스 값, 즉 테이블 상의 몇번째 항목이냐를 나타내도록 하는 것**이다. 32비트 CPU라면 20비트가 페이지 번호에 할당되므로, 1048576(2^20)개의 항목을 가진 테이블을 만들고 논리 주소의 페이지 번호 값으로 테이블의 몇 번째 값인가를 결정한다.

```
인덱스 | 물리 주소의 프레임 번호
0 10023
1 8
. .
. .
. .
1048675 5330
```

예를 들어 논리 주소가 아래와 같다면
```
0000 0000 0000 0000 0001 | 0000 0000 0000 0011
```
> 앞은 페이지 번호, 뒤는 오프셋이다. 

페이지 번호가 10진수로 1이므로 테이블 상의 1번 인덱스를 찾으면, 거기에는 `8`이라는 프레임 번호가 있다. CPU가 위의 논리 주소를 액세스하면 실제 메모리 상에서는 8번 프레임의 4번째 바이트(2진수는 0에서 시작하므로 0011은 4번째)에 액세스한다.

이런 구조로, **페이지 테이블을 이용하면 프로세스의 어떤 페이지도 메모리 안의 임의의 프레임으로 맵핑할 수 있기 때문에 메모리 상에서 프로세스 페이지가 연속으로 존재할 필요가 없다.** 또, 페이지 테이블을 프로세스마다 별도로 가진다면 모든 프로세스는 메모리 상의 어떤 위치에라도(프레임 단위) 임의의 페이지를 옮겨놓을 수 있다.

> 요점) 원래는 물리적으로 연속적인 공간을 메모리상에서 한 프로세스가 가져야 했는데, 이를 논리적인 공간에서 연속적인 인덱스로 넣고, 거기에 대응하는 물리 주소를 저장시켜서 물리적으로는 흩뜨려뜨려도 상관 없게끔 만들었다는 얘기

그런데 32비트 CPU에서 필요한 테이블의 크기는, 20비트가 페이지 번호로 할당되니 2^20 = 1048576개의 항목이어야 한다. 메모리가 256개의 프레임을 구성할 수 있다면, 페이지 테이블의 각 항목은 8비트, 즉 1바이트가 된다. 따라서 페이지테이블의 크기는 1048576 * 1 바이트 = 1024kb = 1mb가 된다. 이게 프로세스마다 존재하니까.. **1mb의 메모리를 가진 시스템에서 10개의 프로세스를 돌리기 위해 10mb의 테이블 페이지용 메모리가 필요하다면 배보다 배꼽이 커질 수 있다.**

가장 쉬운 해결책은 페이지를 크게 잡는 것이다. OS 코드에서는 그렇게 쓰는 경우가 있지만, **일반적인 프로세스에서는 심각한 내부 단편화 문제가 발생**한다. 즉, 한 프로세스마다 평균적으로 페이지 크기의 절반인 `2mb` 정도의 공반이 낭비된다. `구역성Locality`도 4mb 내에서 적용되느냐 하는 문제가 있지만, 정답이 있는 얘기는 아니고 경험적으로 얻어진 값이다.

대안으로, **페이지 테이블을 위한 또 다른 페이지 테이블**을 구성하는 게 있다.

앞에서는 프로세스의 코드, 데이터를 페이지로 쪼개고 메모리도 프레임으로 쪼개서 페이지 - 프레임을 매핑하는 용도로 페이지 테이블을 마련했따면, 여기서는 **이 페이지 테이블을 하나의 프로세스처럼 다시 일정한 크기의 구획으로 쪼개고 이 구획을 메모리상에 맵핑하는 것**이다.

그냥 그런 게 있다고 하고 넘길게~~ `논리 주소 -> 페이지 테이블 -> 물리 주소였던 게 논리 주소 -> 외부 페이지 테이블 -> 페이지 테이블 메모리 -> 물리 주소`

이러면 전체 페이지 테이블 크기에 상관 없이 원하는 크기만큼 페이지 테이블 메모리로 마련해서 사용할 수 있으니 메모리를 아낄 수 있다. 속도 면에선 떨어지나, 페이지 테이블 또한 공간 구역성이 적용되어서 메모리 절약 효과에 비해 퍼포먼스 손실이 크게 떨어지지 않는다.

윈도우즈에서도 이개념을 그대로 사용하고 있음.

하지만 가상 메모리에는 장점만 있지 않은데, **페이지 테이블로 인해 메모리 액세스 횟수가 증가**한다.


# 페이지 테이블을 위한 캐쉬 메모리 - TLBS

CPU가 인스트럭션을 패치해올 때, 물리 메모리 주소와는 상관 없이 프로세스 기준으로 논리 주소를 생성한다. (PC 레지스터의 값이 논리 주소이다.) 만약 1단계 페이징이라면 논리 주소는 페이지 테이블의 인덱스로 활용될 것이다.

한편 페이지 테이블은 하나로도 용량이 적지 않아서 프로세스 정보와 함께 메모리에 위치하게 된다. 그래서 논리 주소가 나옴 -> 페이지 테이블에서 프레임 번호를 읽어 옴 -> 논리 주소의 오프셋과 합쳐서 메모리로부터 최종 인스트럭션을 가져옴

이렇듯 메모리에 2번 액세스해야 하므로 성능에 큰 이슈가 생긴다. 이를 해결하기 위해, 가상 메모리를 지원하는 CPU에는 독특한 하드웨어가 추가되어 있다. **`연관 레지스터Translation Look-aside Buffers, TLBs`라고 부르는 일종의 캐쉬 메모리**이다.

`캐쉬 메모리`란, CPU 외부에 탑재하는 느린 DRAM과 달리 속도가 빠른 SRAM이 CPU 내에 내장된 것이다. 캐쉬 메모리 또한 구역성 이론에 근거해 패치하고자 하는 인스트럭션이나 데이터를 한꺼번에 큰 덩어리로 가져온다. 그러면 캐쉬 내에서 해결할 수 있으니 속도 향상이 이뤄진다.

`TLBs`는 페이지 테이블을 전담하는 장치로, **CPU 내부에 탑재하고 메모리 액세스를 할 때마다 페이지 테이블을 검색하기 전에 TLBs을 살펴본다.**

2개의 항을 가진 테이블로 구성되어 있는데, **1번째 항은 논리 주소의 페이지 번호가, 2번째 항은 물리 메모리의 프레임 번호**가 들어간다. **논리 주소가 생성되면, 페이지 번호 비트들은 TLBs의 모든 행의 1번째항과 동시에 비교하고, 일치하는 행이 발견되면 그 행의 프레임 번호를 곧바로 활용**한다. TLBs만으로 물리 주소가 생성되는 것이다.
만약 없다면 페이지 테이블로 가서 프레임 번호를 읽어온다. 이와 함께, TLBs의 한 행에 막 액세스한 페이지 번호와 프레임 번호를 기록해둔다.
TLBs의 행 수가 그렇게 많지 않더라도(실제로도 2000행 내외) 구역성에 의해 비슷한 페이지로 계속 접근하기 때문에 성능 향상이 크다.


# 페이징을 통한 프로세스 간 메모리 공유
페이징의 장점은
- 외부 단편화 문제 해결
- 많은 프로세스를 메모리에 올릴 수 있음

이외에도, 페이징을 사용하면 각 프로세스는 각 페이지 테이블을 이용해 물리 메모리에 접근하게 되므로, 페이지 테이블만 잘 조작하면 서로 다른 프로세스가 같은 주소의 물리 메모리를 액세스할 수 있다. 

예를 들어 웹서핑을 한다고 하면, 팝업 창이라든가, 다른 창을 띄운다든가 할 수 있다. 이 때 창이 뜰 때마다 새로운 프로세스가 생기고, 각자의 페이지 테이블을 유지한다. 그런데 익스플로러가 코드 / 데이터로 명확히 나뉘어 있다면, **굳이 모든 인터넷 익스플로러 프로세스에서 코드 부분을 따로 메모리로 로드할 필요는 없다. 코드 부분이 어차피 동일하니까.** 이 경우 코드는 실제 메모리에 딱 1번만 로드하고, **데이터에 한해서만 프로세스를 나눠서 로드할 수 있다.** 각 프로세스의 페이지 테이블에서는 코드 부분은 공통적으로 사용하고, 데이터 부분만 각자의 데이터를 가리키면 된다.

이를 모든 프로세스에 적용하면, **모든 프로세스의 공용 코드를 1번만 메모리에 로드하고 모든 프로세스가 페이지 테이블을 잘 조작해서 공용 코드가 로드된 주소를 가리키는 방식으로 메모리를 절약**할 수 있는데, 윈도우즈에서는 **`동적 연결 라이브러리Dynamic Linking Library, DLL`** 이라는 이름으로 이 기술을 활용하고 있다.

윈도우즈에서는 4gb의 프로세스 공간 중 상위 2gb는 항상 dll을 위한 공간으로 활용하고 있다. 그리고 `win32 api`로 불리는 윈도우즈의 시스템 함수들은 모두 `dll` 형태로 구성되어 있다. 윈도우즈 응용 프로그램들의 상당 부분이 API 호출이므로, 이들을 `dll`로 구성하는 것만으로 윈도우즈는 상당한 메모리를 절약하는 것이다.

단, **`dll`도 마찬가지로 코드 부분만 공유**된다. 예를 들어 `CreateWindow`로 창을 띄울 때, 그 안에 들어가는 여러 파라미터나 내부 변수는 프로세스마다 다를 것이다. 이런 **데이터 부분**은 메모리 상에서 공유되면 안되고, API 함수가 호출될 때마다 서로 다른 메모리를 차지하게 해야 하는데 이는 **스택**으로 해결한다.

이전에도 다뤘듯, **모든 변수나 인자는 스택 안에 생성되며, 스택은 스레드마다 보유하는 고유의 영역**이다. 프로세스보다 작은 단위인 스레드마다 스택을 보유하고 이 스택 안에 dll 함수를 포함한 모든 함수의 변수들이 생성되므로, 각 `dll` 함수라고 해도 코드만 공유되고 데이터 자체는 호출될 때마다 다른 메모리에 생성된다.

# CPU의 시간표 - 스케줄링
프로세스보다 적은 CPU로, 어떻게 여러 프로세스를 공평하게 수행할 수 있을까?

이런 역할을 하는 게 OS이고, 그 역할을 `스케줄링Scheduling`이라고 한다. 

스케줄링은 잘 수행되고 있는 프로세스를 계속 실행시키지 않고, 각 프로세스의 수행을 멈추고 다른 프로세스를 수행하는 방법이다. 이를 `문맥 전환Context Switching`이라고 하는데, OS의 가장 큰 책임 중 하나는 프로세스가 문맥 전환을 당할 때 눈속임해주는 것이다. 유일한 방법이, 현재 수행 중인 프로세스 관련 정보를 어딘가에 저장해두고 다음에 수행을 재개할 때 원래 상태대로 복구해주는 것이다.

노트북의 최대 절전 모드를 예시로 들면, 이 모드를 켜면 모든 메모리의 내용과 CPU 레지스터 값 등을 모조리 하드디스크에 백업하고 전원을 끈다. 다시 켜면 윈도우즈가 부팅하다가 백업 데이터를 발견하고는 메모리와 CPU에 백업 데이터들을 옮겨버리고 아무 일도 없었다는 듯이 돌아간다.

OS가 프로세스의 문맥 전환을 할 때에도, **프로세스(스레드도 묶어서 생각)의 가장 기본이 되는 정보는 CPU의 현재 수행 상태**이다. 이는 현재 메모리의 어떤 주소를 패치해서 인스트럭션을 수행했고, 이전 인스트럭션들의 수행 결과 레지스터의 값이 어떻게 되었는가 하는 정보이다. 즉, **레지스터의 값 = 그 시점에서의 CPU의 수행 상태**이다.

따라서 **문맥 전환에서 가장 중요한 건 모든 레지스터의 값을 백업받는 것**이다. 백업은 일반적으로 프로세스마다 할당되는 `PCB Process Control Block`이라는 구조체에 하게 된다. 윈도우즈에서는 `TCB Thread Control Block`에 레지스터를 백업한다. 한 프로세스가 여러 스레드를 가질 수 있어서..

이외에도 메모리 정보도 중요하다. 현재 수행 중이던 코드와 데이터가 저장되어 있는 메모리가 필수적으로, 이를 위한 해결책이 `요구 페이징 Demand Paging` 같은 기법이었다. 각 프로세스마다 페이지 테이블을 유지하고, CPU가 수행하면서 논리 주소가 생성될 때마다 페이지 테이블을 참조해서 프로세스의 코드나 데이터를 메모리로 옮겨오는 방식이었다. 그래서 **프로세스가 문맥 전환이 될 때마다 메모리와 관련해서 저장해야 할 가장 중요한 정보는 페이지 테이블**이다.

그 밖에도 프로세스마다의 핸들 값, 프로세스 이름 등의 정보가 PCB에 저장된다.

하지만 CPU 입장에서는 프로세스나 OS를 알 수 없고 기계적인 규칙에 따라 PC 레지스터가 가리키는 인스트럭션을 패치해서 수행하는 것이다. 즉, 인스트럭션 단위를 작업하지만 그게 어떤 프로세스에 의한 작업인지는 인지하지 못한다. 

그러면 OS는 언제, 어떻게 수행 중인 프로세스를 멈추고 다른 프로세스로 문맥 전환을 하는 것일까?

윈도우즈 95 같은 비선점형 OS에서의 문맥 전환 타이밍은 프로세스에서 호출하는 `시스템 콜`이었다. 
사실, 프로세스가 CPU에 의해 실행되기 시작하면 OS라도 중간에 끼어들 틈이 없다.(인터럽트는 제외) 그래서 OS 코드가 수행될 기회는 OS가 제공하는 API 함수를 프로세스가 자발적으로 부르는 경우 뿐이었다. 여기서 **호출된 API 함수는 함수 수행 후 곧바로 호출한 프로세스의 코드로 리턴하는 대신, 문맥 전환하려는 OS 내부 함수를 호출한다.** 현재 대기 중인 다른 프로세스의 정보를 다시 복구해서, CPU가 새로운 프로세스의 코드를 수행하도록 한다. 
그러면 API를 호출했던 프로세스는 다시 OS가 API 함수 호출 기회가 생겨 자신의 정보를 복구해서 수행시키기 전까지는 자신이 멈춰 있다는 것을 모른다.

하지만 `비선점형 OS`의 치명적인 단점이 있는데, 독불장군 프로세스에 의한 `기아Starvation` 상태이다. 어떤 프로세스가 `시스템 콜`을 호출하지 않는다면, 다른 프로세스들은 모두 정지 상태로 있어야 한다. 실제로 이것 때문에 윈도우 95를 재부팅해야 하는 경우가 많았다.

이를 개선한 게 `선점형Preemptive` 스케줄링을 지원하는 윈도우 98이었다. **응용 프로그램들이 API 함수를 제 때 호출하지 않더라도, 인터럽트를 통해 주기적으로 문맥 전환을 해주는 것**을 말한다. 여기서도 여전히 시스템 콜이 문맥 전환의 기회로 활용됐지만, `타이머 인터럽트`라는 게 더해져서 API 함수의 호출 여부에 관계 없이 주기적으로 OS의 코드가 수행되도록 한다.

**`인터럽트`란, I/O에서도 배웠지만 외부 신호에 의해 CPU가 하던 일을 멈추고 정해진 루틴으로 점프하는 것을 의미**한다. 인터럽트가 걸리면 CPU는 현재 수행 중인 인스트럭션까지 수행하고 인터럽트 종류에 따라 정해진 주소로 점프한다. 그 곳에서는 해당 인터럽트 처리 코드`인터럽트 핸들러`가 존재해서, 이를 수행하고 원래 지점으로 돌아가 수행하던 걸 계속한다.

`인터럽트 핸들러`는 인터럽트 종류에 따라 하는 일이 다르다. 키보드 입력에 발생하는 핸들러는 키보드 버퍼의 데이터를 읽어와 OS가 처리하게 한다든가, 랜 카드의 패킷 도착 인터럽트 핸들러는 패킷을 네트워크 처리를 담당하는 상위 레벨 프로토콜로 전달한다든가.

대표적인 인터럽트로, `타이머 인터럽트`가 있다. 정해진 시간이 경과하면 시그널을 발생시키는 외부의 타이머 레지스터에 의해 발생한다. 시스템에는 여러 타이머 인터럽트 소스들이 있는데, 이 중 하나가 OS의 스케줄링에 활용된다. 선점형 OS에서는 타이머를 설정해서 주기적으로 인터럽트가 걸리도록 하고, 이 인터럽트의 핸들러로 스케줄링 코드 = 문맥 전환 코드를 준비해둔다. 

# 실시간 운영체제

OS는 사실 대학교에서도 한 학기 이상에 걸쳐 들어야 하는 방대한 분량이다. 실제로 이 책의 독자가 직접 OS 커널을 제작하고 알고리즘에 모두 파악해서 실무에 활용할 일은 드물겠지만, OS를 이해해서 그 위에서 돌아가는 응용 프로그램을 개발할 때 더 견실하게 작성하기 위한 용도로 작성되고 있다.

여기서는 일반 개발자에게 중요한 몇 가지 개념을 설명하고, 실시간 운영 체제에 대해 살펴보고 마친다.

`RTOS Real Time Operating System`이라고 불리는 `실시간 운영체제`가 있다. 

`실시간 시스템`에 대한 정의가 있다.
- 프로세스가 수행한 작업 결과의 내용 뿐 아니라, 이 작업 결과가 도출되는 시점이 중요한 목표가 되는 시스템
- 외부에서 임의로 발생하는 데이터를 항상 예측 가능한 시간 안에 처리할 수 있도록 준비된 시스템
- 시간적 제약이 있는 작업을 다루는 시스템

더 와닿게끔 예시로 들어보자.

> 멀티미디어 재생 프로그램이 일반 이미지 뷰어와 어떻게 다를까?
> - 이미지 뷰어는 `JPEG` 파일을 읽어 이를 디코딩해서 화면에 그리기까지 몇 초가 걸리든 큰 문제가 되지 않지만, 초당 30프레임의 `mpeg2`로 인코딩된 dvd 영상을 재생하는 프로그램의 프레임 당 디코딩 시간이 1초를 넘으면 문제가 된다. 
> - 실시간 시스템은 이런 느낌의 제약이 있다.

`Hard Real Time System` : 실시간 처리가 실패했을 때 그 결과가 재앙일 경우(심장 보조 장치, 핵미사일 등)
`Soft Real Time System` : 위의 dvd 플레이어 같은 예시.

`실시간성`이 어떻게 구현될까?

**실시간성은 반응 속도를 원하는 범위 안에 들게 하는 것**인데, 평균 반응 속도가 빠른 것보다는 **느리더라도 일정하거나 최대 반응 시간 내에 무조건 실행되는 것이다. 즉, `예측 가능성`을 중요하게 보는데,** 반응 시간을 예측할 수 있다면 모자라는 부분은 하드웨어 향상 / 더 나은 알고리즘 사용 등으로 보완할 수 있기 때문이다.

이 시스템의 전형적인 처리 과정을 살펴보면 `폴링Polling`과 `인터럽트Interrupt`가 있다.

- 폴링
	- 프로그램이 무한 루프를 돌면서 입력 시스템의 버퍼를 확인
	- 버퍼에 값이 들어오면 값을 읽어 출력한다
- 인터럽트
	- 프로그램은 아무 것도 하지 않은 채 무한 루프를 돈다
	- 키보드가 눌리면 인터럽트가 발생, 프로그램은 자동적으로 즉시 미리 지정된 인터럽트 루틴으로 점프
	- 인터럽트 처리 루틴에서 글자를 출력

2가지 방식의 차이는 기다리는 동안 CPU가 다른 일을 할 수 있냐 없냐이다. `폴링`은 직관적으로 만들 수 있지만 CPU가 항상 인풋을 주기적으로 체크해야 하므로 다른 일을 하기 힘들다. `인터럽트`는 실제 I/O 이벤트가 발생하기 전까지는 다른 일을 할 수 있다는 장점이 있다.

**그래서 대부분 인터럽트를 사용한다.** 

위의 예제는 키보드 입력에 대해 했는데, 이번에는 키보드 입력에 마우스 입력까지 대기하도록 시스템을 개조했다고 해보자. 이 경우, 키보드 입력 외에도 마우스 입력에 대한 인터럽트 라인이 있어야 할 것이다. 

지금도 실시간 시스템일까?

일반적인 인터럽트 처리 과정을 살펴보자. 인터럽트가 발생하면 CPU는 `인터럽트 벡터`라는 걸 검토하게 된다. 메모리의 데이터 값이자 미리 지정된 주소값이다. CPU는 인터럽트 소스에 따라 해당 인터럽트 벡터의 값을 메모리에서 읽어 그 주소로 점프하게 된다. 

그 주소에는 인터럽트 처리 코드가 있다.

위에서 작성한 시스템은 눌린 키보드 값을 읽어 화면에 출력하는 루틴이 있었는데, 문제는 인터럽트는 아무 때라도 발생할 수 있다는 것이다. 즉, `CPU`가 어떤 코드를 처리하고 있는지 모르는 시점에 인터럽트가 발생할 수 있다는 것인데, 따라서 **인터럽트 처리 루틴은 항상 이 부분에 대해 처리할 수 있도록 작성**되어야 한다. 가장 대표적이고 기본적인 방법이 **인터럽트 처리 루틴 안에서 사용하는 모든 레지스터의 값을 백업**하는 것이다.

그러나 **백업할 수 없는 게 하나 있는데, PC 레지스터의 값**이다. 현재 수행중인 코드의 주소이기 때문에, 인터럽트 처리 루틴이 실행 중이라는 말은 PC 레지스터의 값이 원래 수행 중이던 코드 주소가 아니라 인터럽트 처리 루틴을 가리킨다는 의미가 된다. **따라서 이 부분에 대한 책임은 CPU가 지는데,** **인터럽트가 걸리면 하드웨어적으로 그 시점의 PC 레지스터 값을 백업하게 된다.** 인터럽트 처리 루틴에서는 할 일이 다 끝나고 백업해둔 PC 주소 값으로 다시 점프해서 원래 수행 중이던 코드를 수행하게 한다. 이 때 중요한 게 원래 수행 중이던 코드가 멀쩡히 돌아가도록 레지스터 값들을 다시 원상복귀시키는 것이다.

그런데 인터럽트 처리 루틴 중에 다른 인터럽트가 발생한다면? - **사실 인터럽트가 걸린 중에는 다른 인터럽트가 발생할 수 없다.** 

인터럽트 발생 시 기존에 수행 중이던 코드로 복귀하기 위한 PC 레지스터를 백업해야 하는데, 이 작업이 하드웨어 선에서 처리되기 때문이다. 소프트웨어 단위의 작업이라면 스택으로 쌓으면 그만이지만, 하드웨어적으로는 처리가 힘들다.

따라서 인터럽트가 걸리면 제일 먼저 할 일은 **PC 레지스터에 대한 백업**과 **다른 인터럽트가 걸리지 못하게 하는 것**이다. 이는 자동으로 이뤄진다.

그래도 이런 경우도 `실시간 시스템`이라고 얘기할 수 있다. 사용자에게 경고를 할 수도 있고, 하드웨어를 개선해도 되니까.

하지만 **입력 소스가 다원화되는 경우, 최소 시간 간격이라는 개념 자체가 불가능**해진다. 키보드를 치면서 마우스를 움직일 수도 있으니까. 그러면 "마우스가 움직여서 인터럽트가 걸림 -> 키보드를 누르면 키보드가 작동하지 않음" 이라는 이슈가 발생할 수 있겠다.

이런 경우 수행 시간에 대한 보장을 할 수 없어 실시간 시스템으로 부를 수 없게 된다.

PC의 경우 IRQ라고 해서 미리 정해져 있지 않은 인터럽트 라인으로 슬롯 등을 통해 어떤 장치가 연결되는가에 따라 할당되는 IRQ 번호가 달라진다. 따라서 장치의 용도에 따른 제약을 둬서 해결하는 건 불가능하다.

---
**OS가 이런 문제를 맡는데, 실시간 처리를 지원할 수 있는 OS를 RTOS라고 부른다.**

RTOS의 특징 중 하나는 `인터럽트 처리`이다. RTOS 는 언제라도 발생할 수 있는 수많은 인터럽트에 대해 일정 시간 안에 처리를 끝낼 수 있게 해줌으로써 다른 인터럽트가 걸리지 못하는 상황을 최대한 줄인다.

위에서 말한 문제는 복귀 시간이 길어지는 경우였는데, 처리 시간이 늘어지는 것보다도 그 동안에 다른 인터럽트를 처리하지 못하는 게 문제였다. 

RTOS의 인터럽트 처리 루틴은 실질적으로 해당 인터럽트에 대한 처리를 하지 않는다. **대신, 해야 할 일에 대한 목록을 작성하고 필요하다면 해당 목록의 버퍼에 데이터를 저장해 뒤로 미룬다.** 그래서 인터럽트 처리 루틴에서는 **곧바로 리턴**하고, 미룬 처리 루틴은 시스템에 여유가 생길 때 실행시킨다.

RTOS가 아니더라도 많은 OS에서 이런 방식으로 인터럽트에 대한 처리를 다원화한다. 

---
그런데 RTOS는 다단계 인터럽트 처리 외에도, **우선순위가 있는 처리**를 해야 한다.

여러 프로세스 사이에서도 우선순위가 있는데, 예를 들면 작업 관리자는 컴퓨터가 버벅거리는 상황에서도 빠르게 나타난다. 프로세스의 우선순위가 높게 설정되어 있기 때문이다.

인터럽트 처리 루틴을 미루는 건 말은 쉬워보이지만 실제로 간단하진 않다. `뒤로 미룬다`를 구현하려면 우선 순위가 높은 작업을 여러 가지로 분리할 수 있는 매커니즘인 프로세스의 개념 + `여유가 있을 때 수행한다`를 구현하려면 프로세스 간의 경쟁 상태를 나타내는 `우선순위`라는 갠며이 있어야 한다. 

우선순위 개념이 도입되고 나면, RTOS는 반드시 `선점성Preemptiveness`을 지원해야 한다. 비선점성이라면 낮은 우선순위의 프로세스가 CPU를 차지하고 놓지 않으면 다른 우선순위가 높은 프로세스가 수행될 수 없으니까.

**즉, RTOS는 아래의 특징을 갖고, 조건을 만족해야 한다.**
- **선점형 방식**
- **우선순위 스케줄링 지원**
- **인터럽트 지연 - 인터럽트가 걸리지 못하는 시간이 일정해야 함**

추가로, `스케줄링 지연 시간Scheduling Latency`이 일정해야 한다.

스케줄러가 우선순위 스케줄링을 지원한다면, 모든 프로세스를 검색해서 우선 순위가 가장 높은 걸 선택해야 할 것이다. 하지만, 검색 과정은 프로세스 수에 따라 시간이 증가한다. 단순 루프만 해도 `O(n)`임. 이게 문제가 되는 이유는, **RTOS의 필수 요소는 예측가능성**이었기 때문이다. 빈번하게 일어나는 작업이 데이터의 수에 따라 시간이 들쭉날쭉해지면 RTOS의 기본 요건을 만족하지 못하는 것이다.

**RTOS는 빠른 게 아니라, 안정성을 챙기는 OS이다**. 일정한 인터럽트 지연 + 스케줄링 지연을 구현하기 위해 평균 속도적인 면에선 다른 OS보다 떨어진다.

하지만 RTOS가 필요한 이유는 임베디드 시스템 같은 제어를 목적으로 하는 시스템의 경우 **외부 입력으로부터의 반응과 데이터 처리 시간이 항상 예측 가능한 범위 내에 있어야 설계 시점부터 이에 맞춰 하드웨어를 구성하고 실제 동작에 있어서도 원하는 결과**를 얻을 수 있기 때문이다. 예를 들어 오토파일럿이 10초 버벅이면 엄청 위험하겠지?

리눅스나 윈도우즈는 RTOS는 아니다. 선점성과 우선순위 스케줄링을 지원하고, 인터럽트 스레드나 다단계 인터럽트 처리도 구현하지만, **OS의 시스템 함수(커널 코드)가 선점성을 지원하지 못한다.** 자신보다 높은 우선순위의 프로세스가 대기 중이라면 해당 프로세스에 의한 선점이 일어나지만, 낮은 우선순위의 프로세스가 OS의 시스템 함수를 호출한다면 운영 체제의 코`커널모드`드로 선점성을 지원하지 않으므로 해당 함수가 리턴하기 전까지는 다른 높은 우선순위의 프로세스가 발생해도 실행되지 않는다. 이렇듯 `완벽한 선점성을 지원하지 못하기 때문에` 리눅스나 윈도우즈는 RTOS가 아니다.

아래 얘기가 이해가 안 됨. 제미나이한테 물어봤다.
> 1. 우선순위가 낮은 프로세스 A가 실행 중
> 2. A가 시스템 함수를 호출`ReadFile` 
> 3. CPU는 커널 모드로 전환, OS는 프로세스 A를 위해 `ReadFile` 관련 커널 코드 실행
> 4. 커널 코드의 실행 중, 높은 우선순위의 프로세스 B가 실행될 준비를 마침
> 5. **(RTOS 기준 문제 발생)** **CPU가 비선점형 커널 코드를 실행 중**이다. `ReadFile` 작업이 완전히 끝나고 커널 모드를 빠져나올 때까지, 우선 순위가 매우 높은 프로세스라도 CPU를 넘겨주지 못한다.
> 6. 프로세스 A의 `ReadFile`이 완료되고 커널 모드를 빠져나온다
> 7. OS 스케줄러가 프로세스 B가 대기 중임을 확인하고 CPU를 할당한다

>- 여기서 `커널`은 OS에서 가장 핵심적인 부분을 의미한다.
	- OS의 심장부이자 하드웨어 / 소프트웨어 사이의 다리 역할을 하고, 시스템의 모든 걸 총괄한다.
	- 매우 중요한 역할을 하기 때문에, **일반 프로그램과 분리된 특별한 권한**을 갖는다.
	- 위에서 **`비선점형 커널 코드`를 실행 중이라는 말은, 스스로 작업을 마치거나 CPU를 양보하지 않는 이상 다른 누구도 실행을 중단시킬 수 없으셈** 이라는 뜻이다.
		- 커널이 비선점형으로 실행되는 이유도, 가장 중요한 역할을 맡기 때문에 중간에 다른 간섭이 발생하면 데이터가 꼬일 우려가 있기 때문임.

물론 리눅스는 오픈 소스라서 여러 버전이 나왔다. `RTLinux`라는 `RTOS` 버전의 리눅스가 있음.

---

## 번외) (Gemini) 세그먼테이션 vs 페이징
세그먼테이션(Segmentation)과 페이징(Paging)은 운영체제에서 메모리를 관리하는 두 가지 중요한 기법입니다. 둘 다 가상 메모리(프로세스가 실제 물리 메모리보다 더 큰 메모리 공간을 사용하는 것처럼 보이게 하는 기술)를 구현하는 데 사용될 수 있으며, 주 목적은 제한된 물리 메모리를 여러 프로세스가 효율적으로 공유하고 사용하는 것입니다.

하지만 두 기법은 메모리를 바라보는 관점과 나누는 방식에서 근본적인 차이가 있습니다.

### 1. 세그먼테이션 (Segmentation)

*   **관점:** 프로그래머(또는 컴파일러/링커)의 **논리적 관점**을 반영합니다. 프로그램을 의미 있는 단위(블록)로 나눕니다.
*   **메모리 분할:** 프로세스의 주소 공간을 **서로 다른 크기**를 가질 수 있는 **논리적인 단위**인 **세그먼트(Segment)**로 나눕니다. 예를 들어, 코드 세그먼트, 데이터 세그먼트, 스택 세그먼트 등으로 나눌 수 있습니다.
*   **주소 지정:** 논리 주소는 `<세그먼트 번호, 오프셋>`으로 구성됩니다.
    *   `세그먼트 번호`: 어떤 논리적 단위(예: 코드, 데이터)에 속하는지를 나타냅니다.
    *   `오프셋`: 해당 세그먼트 내에서의 상대적인 위치(변위)를 나타냅니다.
*   **매핑:** **세그먼트 테이블(Segment Table)**을 사용합니다. 각 세그먼트마다 테이블 엔트리가 있으며, 여기에는 주로 다음 정보가 포함됩니다.
    *   **기준(Base):** 해당 세그먼트가 물리 메모리에서 시작하는 주소.
    *   **한계(Limit):** 해당 세그먼트의 크기 (오프셋이 이 크기를 넘어서면 안 됨).
    *   보호 비트 (읽기/쓰기/실행 권한 등).
    *   물리 주소 계산: `물리 주소 = 세그먼트 테이블[세그먼트 번호].기준 + 오프셋` (단, `오프셋 < 세그먼트 테이블[세그먼트 번호].한계` 여야 함)
*   **장점:**
    *   **논리적 분할:** 프로그램의 구조(코드, 데이터, 스택)를 반영하므로 이해하기 쉽고 관리가 용이합니다.
    *   **보호와 공유:** 세그먼트 단위로 읽기/쓰기/실행 권한을 다르게 설정하여 보호하기 쉽습니다. 코드 세그먼트처럼 공유가 필요한 부분을 쉽게 공유할 수 있습니다.
*   **단점:**
    *   **외부 단편화(External Fragmentation):** 세그먼트의 크기가 다양하므로, 메모리 할당과 해제가 반복되면 물리 메모리 중간중간에 사용하기 어려운 작은 빈 공간(조각)들이 많이 생깁니다. 전체 빈 공간은 충분해도 연속된 큰 공간이 없어 새로운 세그먼트를 할당하지 못할 수 있습니다.
    *   **복잡한 메모리 관리:** 가변 크기 할당은 고정 크기 할당보다 복잡합니다.

### 2. 페이징 (Paging)

*   **관점:** 물리 메모리 관리의 **편의성**에 초점을 둡니다. 프로그램의 논리적 구조와는 상관없이 주소 공간을 나눕니다.
*   **메모리 분할:**
    *   프로세스의 **논리 주소 공간**을 **고정된 동일한 크기**의 블록인 **페이지(Page)**로 나눕니다.
    *   **물리 메모리**도 페이지와 **동일한 크기**의 블록인 **프레임(Frame)**으로 나눕니다.
*   **주소 지정:** 논리 주소는 `<페이지 번호, 오프셋>`으로 구성됩니다.
    *   `페이지 번호`: 논리 주소 공간 내에서 몇 번째 페이지인지를 나타냅니다.
    *   `오프셋`: 해당 페이지 내에서의 상대적인 위치(변위)를 나타냅니다. (오프셋 비트 수는 페이지 크기에 따라 결정됨)
*   **매핑:** **페이지 테이블(Page Table)**을 사용합니다. 각 페이지마다 테이블 엔트리가 있으며, 여기에는 주로 다음 정보가 포함됩니다.
    *   **프레임 번호:** 해당 페이지가 물리 메모리의 어떤 프레임에 저장되어 있는지.
    *   보호 비트, 유효 비트(현재 메모리에 있는지 여부) 등.
    *   물리 주소 계산: `물리 주소 = (페이지 테이블[페이지 번호].프레임 번호 * 페이지 크기) + 오프셋` (또는 프레임의 시작 주소 + 오프셋)
*   **장점:**
    *   **외부 단편화 해결:** 모든 페이지와 프레임의 크기가 같으므로, 어떤 빈 프레임이든 필요한 페이지를 할당할 수 있습니다. 외부 단편화가 발생하지 않습니다.
    *   **간단한 메모리 관리:** 고정 크기 할당은 매우 간단합니다.
    *   **효율적인 스와핑:** 페이지 단위로 메모리와 디스크 간의 이동(스와핑)이 용이합니다.
*   **단점:**
    *   **내부 단편화(Internal Fragmentation):** 프로세스의 크기가 페이지 크기의 배수가 아닐 경우, 마지막 페이지에는 일부 사용되지 않는 공간이 남을 수 있습니다. 이 공간은 다른 프로세스가 사용할 수 없습니다.
    *   **페이지 테이블 오버헤드:** 프로세스마다 페이지 테이블이 필요하며, 주소 공간이 크면 페이지 테이블 자체의 크기도 매우 커질 수 있습니다 (메모리 차지). 이를 해결하기 위해 다단계 페이징 등의 기법이 사용됩니다.
    *   **논리적 공유/보호의 어려움:** 페이지는 논리적 단위가 아니므로, 코드나 데이터 같은 의미 단위로 공유하거나 보호 권한을 설정하기가 세그먼테이션보다 직관적이지 않습니다.

### 비교 요약

| 특징             | 세그먼테이션 (Segmentation)                   | 페이징 (Paging)                             |
| :--------------- | :---------------------------------------------- | :------------------------------------------ |
| **분할 단위**    | 논리적 단위 (코드, 데이터 등) / **가변 크기** | 고정 크기 페이지 / **고정 크기**            |
| **주소 구성**    | `<세그먼트 번호, 오프셋>`                       | `<페이지 번호, 오프셋>`                     |
| **매핑 테이블**  | 세그먼트 테이블                                 | 페이지 테이블                               |
| **프로그래머 관점** | 보임 (논리적 구조 반영)                       | 안 보임 (선형 주소 공간으로 보임)           |
| **단편화**       | 외부 단편화 발생                              | 내부 단편화 발생 (외부 단편화 없음)         |
| **메모리 관리**  | 복잡 (가변 크기 할당)                         | 단순 (고정 크기 할당)                       |
| **공유/보호**    | 세그먼트 단위로 용이                            | 페이지 단위 (논리적 의미와 다를 수 있음)    |

### 현대 시스템

현대의 많은 시스템(예: x86 아키텍처)은 **세그먼테이션과 페이징을 함께 사용**합니다. 보통 세그먼테이션을 이용해 기본적인 보호(커널/사용자 분리 등)와 주소 공간의 큰 틀을 잡고, 그 안에서 페이징을 통해 실제 물리 메모리를 효율적으로 관리하고 외부 단편화를 해결하는 방식을 사용합니다. (예: 논리 주소 -> 세그먼테이션 -> 선형 주소 -> 페이징 -> 물리 주소)

궁금한 점이 있다면 다시 질문해주세요.