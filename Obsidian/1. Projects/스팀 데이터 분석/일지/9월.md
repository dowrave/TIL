## 현재 이슈

- 텐서플로우 2.x 버전에서 작업 중
- `ValueError: Target data is missing. Your model was compiled with loss=<keras.src.losses.SparseCategoricalCrossentropy object at 0x7a8ec3d5e500>, and therefore expects target data to be provided in `fit()`.` 
## 일자별 진행상황

### 230921
- `create_optimizer` 이슈 : `tf.GradientTape`와 `KerasTensor` 관련 이슈
	- `AttributeError: 'KerasTensor' object has no attribute '_id'`
- `create_model` 내에 손실함수를 정의하는 부분도 같이 들어가 있는데, 2.x 버전에서 손실함수는 따로 정의하는 게 일반적이므로 그렇게 작업을 진행하겠음.
- 아예 전부 keras 처럼 바꿔서 작업, fit까지 작성 완료.
### 230920

- `create_model`까지 생성 완료
	1. `tf.linalg.matmul`에서 계산이 정상적으로 되지 않는 문제 수정
	2. `tf.nn.bias_add` 도 계산이 안되는 문제가 있음
		- 위 문제들 모두 수정
		```python
		# tf v1에서 작성된 코드
		output_weights = tf.compat.v1.get_variable(
		  "output_weights", [num_labels, hidden_size],
		  initializer=tf.compat.v1.truncated_normal_initializer(stddev=0.02))
		
		output_bias = tf.compat.v1.get_variable(
		  "output_bias", [num_labels], initializer=tf.compat.v1.zeros_initializer())
		
		# 수정 코드
		output_weights = tf.Variable(
		  initial_value = tf.keras.initializers.TruncatedNormal(stddev = 0.02)(shape = (num_labels, hidden_size)),
		  trainable = True,
		  name = 'output_weights'
		)
		
		output_bias = tf.Variable(
		  initial_value = tf.keras.initializers.Zeros()(shape = (num_labels,)),
		  trainable = True,
		  name = 'output_bias'
		)
		```
		- 기존에 `tf.keras.layers.Dense()`로 2개의 변수를 수정했는데, 더 직접적인 방법으로 `tf.Variable`을 사용하는 것 같다.

- 새로운 이슈
```
loss = tf.reduce_mean(tf.Variable(per_example_loss, trainable = False))

You are passing KerasTensor(type_spec=TensorSpec(shape=(2,), dtype=tf.float32, name=None), name='tf.math.negative_2/Neg:0', description="created by layer 'tf.math.negative_2'"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`
```

- 해결
```python
  # loss = tf.constant(loss) 
  loss = tf.keras.layers.Lambda(lambda x : x)(loss)
```
- loss 자체가 `KerasTensor`로 정의되어 있기 때문에, `tf.constant`로 직접 바꾸는 게 어려울 수 있으며, 이 경우 `tf.keras.layers`를 이용해 간접적으로 변환하는 방법이 있음.
### 230919
- `Loss` 정의하기 - 완료
- `create_model`을 텐서플로우 1 -> 2버전으로 바꾸는 과정에서 구조가 맞지 않는 것 같다. 어디가 문제인지 계속 확인해 봐야 함


### 230918
- 데이터 가공 작업 중 - 일단 krBERT에 있는 것들을 이용해서 가공을 다시 진행해보고, 막히는 곳이 있다면 그걸 수정해나가는 방식으로 작업을 진행하겠음.
- `tf.dataset` 전처리 과정 작업함 - 텐서플로우 버전 2에 맞게 코드 수정
### 230914
- 이슈에 있는 세부사항 - 학습률 값이 텐서에 들어가지 않는 현상 수정 시작
```
- `eval_results.txt`에서는 약 78% 정도의 정확도를 보이는데, 기대한 것보다 많이 낮은 느낌임. 
- 사실 텐서플로우 2.x 버전에서는 `model`을 쓰는 방법이 훨씬 좋아 보이는데, `krBERT`는 `estimator`를 이용하여 작성되어 있음. 이걸 다르게 가져갈 방법이 없을까 고민 중.

- 어떻게 해결했는지는 [[이슈 수정해나가기]]에 기록해두었다.
	1. 학습률`5e-5`을 적용했음에도 정상적으로 텐서에 들어가지 않는 현상
	2. `warmup_step`이 각 에포크마다 반복되지 않고, 특정 스텝 동안만 적용되게끔 함
```

### 230913
- 원본 코드는 `전체 에포크 * 한 에포크 당 훈련 스텝`을 `estimator`에 넣어서 계산하는데, 이를 에포크 수로 나눠서 넣어서 훈련함
	- 여기서 **`warmup_step` 관련 이슈가 있는데, 에포크 별로 반복할 때 `warmup_step`이 반복되는지 아닌지도 체크 필요함** (에포크 별로 반복되지 않아야 맞음)
- 학습에 따른 결과 수치화 결과 ) 에포크마다 Loss 값이 개선되지 않음

### 230912

- 하고 싶은 것 
1. 학습에 따른 결과를 시각화하고 싶음
2. 하이퍼파라미터(배치 크기, 최대 토큰 갯수)를 만지면서 미세조정을 만져보고 싶음


### 230911
- 세부사항 수정 시작
- 일단 `tf.compat.v1`으로 되어 있지 않은 부분들 수정하고, 다시 실행해서 확인함
	- 텐서플로우 자체에 `tf_upgrade_v2 --intree . --outtree ./krbert_v2 --copyotherfiles False` 라는 기능이 있다. 텐서플로우 1로 만든 코드를 2로 자동으로 업데이트하는 코드임. 직접 볼 곳이 있다면 `report.txt`에 자동으로 저장해준다.
### 230908

- **학습 시작했다!! (일단 파이프라인 자체는 완성한 셈)**
	- 훈련 데이터 학습은 1시간 조금 넘게 걸림
- 코드는 돌아가는 듯 한데, 결과를 시각화하는 방법을 찾아봐야 할 것 같다.
#### 이슈
- 같은 이슈 진행중 (GCS 버킷 접근 권한 설정 : `storage.buckets.list` 권한 부여하기)
	- [요 링크](https://colab.research.google.com/drive/1lYBYtaXqt9S733OXdXvrvC09ysKFN30W#scrollTo=aLjsqWr5upAz)의 가장 아랫쪽에서 TPU 에러 발생시 해당 버킷에 모든 유저 R/W 권한 부여가 필요하다고 하고 있다. 
	- GCS 콘솔에서 해당 버킷의 `공개 액세스 방지` 를 취소시킴
		- 이걸 눌러도 `공개 액세스`가 `공개 아님`으로 표시되는 건 동일한데, `allUsers`로부터의 접근 제한이 없어지는 차이점이 있는 듯. 이대로 실험해봄. 

- 아래 명령어로 해결한 듯? 오류 메시지가 달라짐 :
```
!gcloud storage buckets add-iam-policy-binding gs://steam-project-bucket --member=allUsers --role=roles/storage.objectViewer
```

- 다음 에러도 `storage.buckets.create` 관련 에러가 떴다.
- 관련 정보를 찾던 중, [클라우드 스토리지에 대한 IAM 역할](https://cloud.google.com/storage/docs/access-control/iam-roles?hl=ko)이 무슨 의미인가 궁금했는데 이제 이해를 좀 할 것 같음
	- `역할` 내에 `권한`이 포함되는 거임.
		- `역할`은 `objectViewer`, `objectCreator`, `objectUser` 등이 있는 거고
		- `권한`은 `storage.buckets.list`, `storage.object.get` 등이 들어감
	- 따라서, 위에서 `objectViewer`를 `allUsers`에게 권한을 줬는데, 다른 권한도 포함해줘야 하므로 `storage.objectUser`권한을 주고 테스트하겠음


### 230907
- 코랩에서 TPU로 학습하려면 GCS 관련 설정도 필요한 듯 하다. 그거 진행 중..
- GCS 버킷 접근 권한 설정 : `storage.buckets.list` 권한 부여하기
	- `[service-495559152420@cloud-tpu.iam.gserviceaccount.com](mailto:service-495559152420@cloud-tpu.iam.gserviceaccount.com) does not have storage.objects.list access to the Google Cloud Storage bucket.` 인걸로 봐서는 TPU에서 버킷에 접근할 권한을 부여해야 하는 것 같다.

### 230906
#### 새로운 이슈
- `UNIMPLEMENTED: File system scheme '[local]' not implemented (file: './models/char_ranked/model.ckpt-2000000')` 에러
	- GCS Bucket을 써라 + TPU가 해당 GCS Bucket에 접근할 수 있어야 한다
		- GCS 체험판(3달간 300$ 무료)을 사용해봄
	- 혹은, 캐글의 TPU를 사용하는 방법도 있다.
	- GCS 버킷 세팅 & 파일 업로드 완료, 코랩 파일에도 연동 완료.

### 230904 
- 이슈 해결 : 상속받는 optimzer를 `keras`가 아니라 `tf.compat.v1`에서 받게끔 변경


### 230901
- 멀고도 험하다. `krBERT`를 `Tensorflow 2.X` 버전에서 실행하기..

#### 이슈
1. `learning_rate`를 `optimization.create_optimizer`에서 인식하지 못하는 이슈

- 이해가 안 가는 상황이다.
```python
# main.py
import tensorflow as tf

lr = 5e-5
print(lr) # 5e-05

tensor = tf.compat.v1.constant(value = lr, shape = [], dtype = tf.compat.v1.float32)
print(tensor) # tf.Tensor(5e-05, shape=(), dtype=float32)
```

- 위 상황에서, lr 값을 `optimization.py`에 전달한 다음 아래 함수에 전달하는 상황임.
```python
# optimization.py
import tensorflow.compat.v1 as tf
import tensorflow
from tensorflow import keras

def create_optimizer(loss, init_lr, num_train_steps, num_warmup_steps, use_tpu):
  """Creates an optimizer training op."""
  global_step = tf.train.get_or_create_global_step()

  print("init_lr : ", init_lr)
  learning_rate = tf.constant(value=init_lr, shape=[], dtype=tf.float32)

  print("tensor : ", learning_rate)

  # Implements linear decay of the learning rate.
  learning_rate = tf.train.polynomial_decay(
      learning_rate,
      global_step,
      num_train_steps,
      end_learning_rate=0.0,
      power=1.0,
      cycle=False)
    
  print("polynomial_decay : ", learning_rate)

# ....
```

- 근데 여기서 `main.py`에서 `init_lr` 값을 `5e-5`로 전달했을 때,
```python
  print("init_lr : ", init_lr) # 5e-05
  print("tensor : ", learning_rate) # Tensor("Const:0", shape=(), dtype=float32)
  print("polynomial_decay : ", learning_rate) # Tensor("PolynomialDecay:0", shape=(), dtype=float32)

```
- 왜 이렇게 나오는지 모르겠음.

