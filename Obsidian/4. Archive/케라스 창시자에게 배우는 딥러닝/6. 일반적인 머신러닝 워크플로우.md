1. [[#작업 정의|작업 정의]]
	1. [[#작업 정의#문제 정의|문제 정의]]
	2. [[#작업 정의#데이터 수집|데이터 수집]]
		1. [[#데이터 수집#애너테이션 인프라에 투자하기|애너테이션 인프라에 투자하기]]
		2. [[#데이터 수집#대표성 없는 데이터에 주의하기|대표성 없는 데이터에 주의하기]]
	3. [[#작업 정의#데이터 이해|데이터 이해]]
	4. [[#작업 정의#성공 지표 선택|성공 지표 선택]]
2. [[#2. 모델 개발|2. 모델 개발]]
	1. [[#2. 모델 개발#데이터 준비|데이터 준비]]
		1. [[#데이터 준비#벡터화|벡터화]]
		2. [[#데이터 준비#값 정규화|값 정규화]]
		3. [[#데이터 준비#누락값 처리|누락값 처리]]
	2. [[#2. 모델 개발#평가 방법 선택|평가 방법 선택]]
	3. [[#2. 모델 개발#기준 모델 뛰어넘기|기준 모델 뛰어넘기]]
	4. [[#2. 모델 개발#모델 용량 키우기 : 과대적합 모델 만들기|모델 용량 키우기 : 과대적합 모델 만들기]]
	5. [[#2. 모델 개발#모델 규제와 하이퍼파라미터 튜닝|모델 규제와 하이퍼파라미터 튜닝]]
3. [[#모델 배포|모델 배포]]
	1. [[#모델 배포#고객에게 작업 설명 및 기대치 설정|고객에게 작업 설명 및 기대치 설정]]
	2. [[#모델 배포#추론 모델 배치하기|추론 모델 배치하기]]
		1. [[#추론 모델 배치하기#REST API로 모델 배포하기|REST API로 모델 배포하기]]
		2. [[#추론 모델 배치하기#장치로 모델 배포하기|장치로 모델 배포하기]]
		3. [[#추론 모델 배치하기#브라우저에 모델 배포하기|브라우저에 모델 배포하기]]
		4. [[#추론 모델 배치하기#추론 모델 최적화|추론 모델 최적화]]
	3. [[#모델 배포#작동 중 모니터링하기|작동 중 모니터링하기]]
	4. [[#모델 배포#모델 유지관리하기|모델 유지관리하기]]




- 실전은 데이터셋에서 시작하지 않고 **문제에서 출발**한다.
	- 개인화 사전 검색 엔진 
	- 게시물 중 스팸이나 공격적인 텍스트 표시
	- 음악 추천 시스템
	- 부정 거래 감지
	- 디스플레이 광고 클릭률 예측
	- 불량품 확인
	- 알려지지 않은 유적지 위치 예측

- 일반적인 머신러닝의 워크플로우

> 1. **작업 정의** : 문제 영역과 고객 요청에 있는 비즈니스 로직 이해. 데이터 수집, 내용 이해, 작업 성공 측정 방법을 선택한다.  
> 2. **모델 개발** : 머신 러닝 모델로 처리할 수 있는 데이터 준비, 모델 평가와 간단한 기준점 선택, 일반화 성능을 가지며 과대적합할 수 있는 1번째 모델 훈련, 최대 일반화 성능을 위한 규제 추가 및 튜닝  
> 3. **모델 배포** : 작업 결과를 고객에게 제시. 모델을 웹 서버, 앱, 웹 페이지, 임베디드 장치 등에 배포하고 실전에서 모델 성능을 모니터링. 차세대 모델 구축을 위한 데이터 수집.


## 작업 정의

### 문제 정의
- 우선 순위가 높은 질문은 이런 것들이 있다
	- 입력 데이터가 무엇인가? 어떤 것을 예측하려고 하는가?
	- 당면한 문제가 어떤 종류인가?
		- 이진 분류, 다중 분류, 스칼라 회귀, 벡터 회귀, 다중 레이블 다중 분류, 이미지 분할, 랭킹, 군집, 생성, 강화 학습
		- 머신러닝이 아니라 통계분석을 해야 할 수도 있다.
	- 기존 솔루션에는 무엇이 있는가?
		- 기존 처리 방법은 아마 수동으로 만든 알고리즘일 것이다. 현재 사용하고 있는 솔루션을 이해해야 한다.
	- 고려할 제약이 있는가?
		- 작업이 충족시켜야 할 조건을 이해해야 한다.

- 위 사항을 마치고 나면, 입력과 타깃 및 어떤 머신 러닝 작업이 문제에 맞는지 알게 된다.
- 위 과정에서 이러한 가설이 생긴다.
	- **주어진 입력으로 타깃을 예측할 수 있다고 가정**한다.
	- **가용한 데이터가 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다**고 가정한다.
- 가설은 가설일 뿐이며 검증될지 아닐지는 지켜봐야 한다. **모든 문제를 ML로 해결할 수 없다.**
	- 주식 시장의 최근 가격 변동으로 예측하면 실패할 가능성이 높다 : 예측에 활용할 정보가 많지 않기 때문이다.

### 데이터 수집
- 대부분의 머신러닝 프로젝트에서 가장 힘들고, 시간이 많이 걸리고, 비용이 많이 드는 단계이다.
	- 나만 해도 스팀 리뷰 데이터 수집에 리얼타임으로 1주일 씀

- 사진 검색 엔진 : 분류하려는 레이블을 선택, 레이블 집합을 이용해 사용자가 업로드한 이미지에 수동으로 태깅해야 함
- 스팸 감지 : 대화가 암호화되므로 모델 훈련에 쓸 수 없다. 필터링되지 않은 소셜 미디어 게시물로 구성된 별도의 데이터셋이 필요하고, 레이블을 달아야 한다.
- 음악 추천 엔진 : 좋아요 기록을 사용할 수 있다. 클릭률 예측 프로젝트도 과거의 클릭률 데이터가 있다.
- 불량 쿠키 감지 모델 : 이미지에 수동으로 레이블을 달아야 한다. 

- **모델의 일반화 능력은 훈련되는 데이터의 속성에서 오므로, 프로젝트에서 쓸 수 있는 시간 중 가장 우선적으로 투자해야 하는 곳은 데이터 수집이다.**
	- 2009년 구글 논문 `The Unreasonable Effectivness of Data`이 있다. 알고리즘보다 데이터가 더 중요하다는 논문임.
- 지도 학습의 경우 `애너태이션annotation`을 만들어야 한다. 대부분의 경우 수동으로 레이블을 달아야 하며, 이는 매우 노동집약적인 작업이다.

#### 애너테이션 인프라에 투자하기
어떤 방법을 쓸 수 있는지 고려해야 한다.
- 직접 애너테이션을 수행하는가?
- 레이블을 모으기 위해 외부 플랫폼이나 서비스를 써야 하는가? `Mechanical Turk` 같은 크라우드 소싱이나, 전문적인 레이블링 회사가 있을 수 있다.

또한, 현재 작업의 제약 조건도 고려해야 한다.
- 레이블을 할당하는 데 전문적인 지식이 필요한가?
	- 필요하다면, 이를 위해 사람을 훈련시킬 수 있는가? 아니면 전문가를 구할 수 있는가?
- 전문가의 애너테이션 작업을 당신이 이해하고 있는가?
	- 그렇지 않다면 데이터셋 = 블랙박스가 돼서 특성 공학을 수동으로 수행할 수 없다.
- 관련 소프트웨어를 개발하거나 사용할 수도 있다. 비용 절약에 도움이 될 수 있으므로 투자할 가치가 있다.

#### 대표성 없는 데이터에 주의하기
- 가능한 **모델이 사용될 환경에서 데이터를 수집**해야 한다.
	- 사진 -> 음식 분류 앱에서 전문가가 찍은 사진만을 이용한다면, 실환경에선 가치가 떨어질 확률이 높다.
	- 불가능하다면, 훈련 데이터와 실전 데이터의 차이점을 이해하고 이를 좁히기 위해 적극적으로 노력해야 한다.

- `개념 이동Concept Shift` 
	- **제품 환경에서 데이터의 속성이 시간에 따라 변하는 경우, 모델의 정확도가 서서히 감소한다.**
		- 2011년 IMDB 모델은 2012년 리뷰보다 2020년 리뷰에 대한 성능이 좋지 않다. 어휘, 표현, 영화 장르가 시간에 따라 변하기 때문이다.
	- 이에 대처하려면 **지속적인 데이터 수집, 애너테이션, 모델 재훈련**이 필요하다.
	- 머신러닝은 훈련 데이터에 있는 패턴만을 기억한다. 
		- 미래 예측의 경우, 과거의 패턴이 미래에도 있을 것이라는 가설 하에 세워진 경우가 많은데, 실제로는 그렇지 않은 경우도 종종 있다.

- `샘플링 편향(Sampling Bias)`
	- 데이터 수집 과정이 예측 대상과 상호작용해서 편향된 측정 결과를 만들 때 사용함
	- 많이 나오는 예시 : 시카고 트리뷴의 설문 조사
		- 이 신문을 보는 사람들이 미국 시민 전체를 대표할 수 없었기 때문에 예측에 실패한 경우.

### 데이터 이해
모델 훈련 전, 데이터를 탐색하고 시각화하여 예측 능력을 가진 특성에 대한 통찰을 얻어야 한다.

- 이미지나 자연어 텍스트를 포함한 경우, 몇 개의 샘플과 레이블을 확인하라
- 수치 특성을 포함한다면 히스토그램을 그려서 범위나 빈도를 파악하라
- 위치 정보를 포함한다면 지도를 그려라. 패턴이 드러나는가?
- 일부 샘플이 누락된 값이 있다면, 처리해야 한다.
- 분류 문제라면 각 클래스의 샘플 갯수가 비슷한지 살펴봐야 하며, 아닌 경우 불균형을 고려해야 한다.
- 타깃 누출(Target Leaking)을 확인하라. 데이터에 타깃에 관한 정보를 제공하는 특성이 있는지 확인해야 한다.
	- 암 치료 예측을 위한 훈련 데이터에 "암 진단을 받은 적 있음"이라고 한다면, 타깃이 누출되고 있는 것이다.

### 성공 지표 선택
- 성공에 대한 정의가 필요하다.
	- 정확도 vs 정밀도 vs 재현율 vs 재방문율 등등
	- 이 정의는 고객의 비즈니스 성공 같이 고수준의 목표와 직접 연결되어 있어야 한다.

- 지표 예시
	- 클래스 분포가 균일한 분류 : 정확도, ROC AUC(ROC 곡선 아래 면적)
	- 불균일 클래스 분포, 랭킹, 다중 레이블 : (정밀도, 재현율) or (정확도와 ROC AUC의 가중평균)

- 새로 지표를 정의하는 경우도 드물지 않다. 캐글에서 관련 사례들을 볼 수 있다.

## 2. 모델 개발
- **정말 어려운 단계는 위의 문제 정의, 데이터 수집, 애너테이션, 정제**이다. 
- 위 과정이 끝났다면 모델 개발 단계임.

### 데이터 준비
- **데이터 전처리** : 원본 데이터를 신경망에 적용하기 쉽게 만듦
- 많은 전처리는 도메인에 특화되었다. 즉, 텍스트 데이터에만 쓰이거나, 이미지 데이터에만 쓰이거나.
- 아래 예시는 모든 데이터 분야에 쓰이는 기본적인 사항들이다.

#### 벡터화
- 모든 입력과 타깃은 부동 소수점 데이터거나, 특정 경우 정수나 문자열로 이뤄진 텐서이다.
- **사운드, 이미지, 텍스트 어떤 것이든 먼저 텐서로 변환해야 하는데, 이를 `벡터화Vectorization`** 라고 한다.

#### 값 정규화
- 이미지의 경우 0~255를 0~1로 정규화했음. 집 가격 예측도 정규화를 거쳤음.
- 네트워크를 쉽게 학습시키려면 아래 조건을 만족해야 한다.
	- **작은 값** : 0 ~ 1 사이
	- **균일** : 비슷한 범위를 모든 특성이 가져야 함
- 정규화가 도움이 될 수 있지만, 항상 필요하지는 않다.

#### 누락값 처리
- 삭제 가능
- **누락값이라는 새로운 범주를 만드는 게 안전하다** 
	- 모델이 타깃에 대해 의미하는 바를 자동으로 학습한다.
- 수치형 특성이라면 `0` 같은 임의의 값을 넣는 건 위험할 수 있다.
	- 특성의 잠재 공간에 불연속성이 생겨서 모델의 일반화를 어렵게 할 수 있다.
	- 평균값이나 중간값으로 대체하는 것을 고려할 수 있는데, 그 값을 기록해둬야 한다.

- 일반적으로 어떤 방법이 문제에 적합한지는 알기 어려우며, 교차검증으로 모두 확인해보는 것이 좋다.

### 평가 방법 선택
- 앞에서 3가지 평가 방법을 다뤘음
	- 홀드아웃 : 데이터가 풍부할 때 가능
	- K-fold CV : 홀드아웃을 쓰기에 샘플 개수가 너무 적을 떄
	- 반복 K-fold CV : 데이터가 적을 때만 사용 가능
- 대부분의 경우 `홀드아웃`만으로 충분하다

### 기준 모델 뛰어넘기
- 초기 목표는 `통계적 검정력Statistical Power`을 달성하면 된다.

- 중점 3가지
	- **특성 공학** : 유용하지 않은 특성을 제외하고, 새 특성을 개발
	- **구조에 대한 올바른 가정** : 어떤 종류의 모델 구조? (Dense, CNN, RNN, Transfomer) 등
	- **좋은 훈련 옵션** : 손실 함수 선택, 배치 크기, 학습률

- 자주 쓰이는 마지막 층의 활성화함수와 손실 함수

| 문제 유형             | 마지막 층 활성화 함수 | 손실함수                 |
| --------------------- | --------------------- | ------------------------ |
| 이진 분류             | sigmoid               | binary_crossentropy      |
| 단일 레이블 다중 분류 | softmax               | categorical_crossentropy |
| 다중 레이블 다중 분류 | sigmoid               | binary_crossentropy                         |


- 대부분의 프로젝트에서 활용할 수 있는 기존 템플릿이 있다.
	- 여러분이 처음 도전하는 사람은 아니다.

- 통계적 검정력을 달성하는 게 항상 가능한 건 아니며, 간단한 기준점을 넘지 못한다면 아래 가설을 만족하고 있는지 확인하자.
	- 주어진 입력으로 타깃을 예측할 수 있다는 가정
	- 가용한 데이터에 입력 - 출력 관계 학습에 충분한 정보가 있다는 가정

### 모델 용량 키우기 : 과대적합 모델 만들기
- 층 추가
- 층 크기(유닛 수) 증가
- 더 많은 에포크에서 훈련
- 검증 데이터에서 모델 성능 감소가 시작됐을 때 과대적합이 시작된 것이다

### 모델 규제와 하이퍼파라미터 튜닝
- 통계적 검정력 + 과대적합 을 달성했다면, 일반화 성능을 최대화하는 게 남은 목적이다.
- 이 단계가 대부분의 시간을 차지한다.  모델 수정과 훈련, 평가를 반복하기 때문이다.
	- 검증 데이터를 이용하며, **테스트 데이터는 이용하지 않는다.**
- 시도할 것들
	- 다른 구조 시도 : 층 추가 및 제거
	- 드롭아웃 추가
	- 작은 모델인 경우 L1, L2 규제 추가
	- 하이퍼파라미터 바꿔서 시도 : 층의 유닛 개수, Optimizer의 학습률
	- 데이터 큐레이션이나 특성 공학 시도
		- 데이터 수집, 애너테이션 만들기, 더 나은 특성 개발, 유용하지 않을 것 같은 특성 제거
- 위 작업 중 많은 부분을 `keras-tuner`를 이용해서 자동화할 수 있다.

> 주의 : 검증 데이터를 사용하여 튜닝하고 있기 때문에 모델을 튜닝할 때마다 더 많은 정보가 누설되는 것이다. 반복 수가 많을수록 검증 데이터에 대해 과대적합된다.  
> **만족할 만한 성능이 나왔다면 훈련 + 검증 데이터를 사용해서 최종 모델을 훈련시킨 뒤, 테스트 세트에서 딱 1번만 평가**한다. 테스트 세트에서 성능이 많이 부족하다면 검증 데이터에 과대적합된 것이므로, 이 경우 더 신뢰할 만한 평가 방법을 쓰는 게 좋다.


## 모델 배포

### 고객에게 작업 설명 및 기대치 설정
AI 시스템에 대한 사람들의 기대는 현실적이지 않은 경우도 있다. 시스템이 작업을 이해하고 사람과 같은 상식을 보여준다고 생각할 수도 있음. 모델이 실패하는 경우를 고객에게 보여줄 수 있다.  
특히 사람 수준의 성능을 기대하는 경우도 있는데, 대부분 사람이 만든 레이블을 근사하기 위해 불완전하게 훈련되므로 대부분 그 수준에 도달하지 못한다.

- 정확도 보다는 `거짓 음성 비율`이나 `거짓 양성 비율`에 대해 얘기하는 것이 좋을 때도 있다.
	- 거짓 음성 비율 : 실제로 양성인데 음성으로 잘못 분류된 비율
	- 거짓 양성 비율 : 실제로 음성인데 양성으로 잘못 분류된 비율

- 핵심적인 파라미터도 고객과 논의해야 한다. 
	- ex) 스팸이나 부정 거래로 인식하는 확률 임계값 : `Confusion Matrix`의 각 값에 영향을 주기 때문

### 추론 모델 배치하기

1. 파이썬 외의 방식으로 모델을 저장할 수 있다.
	- 제품 환경이 파이썬을 지원하지 않고, 임베디드 시스템이나 모바일 앱 등일수 있다.
	- 애플리케이션이 파이썬으로 작성되지 않았을 수 있다.

2. 제품 모델은 훈련이 아니라 예측을 만들기 위해서만 사용된다.
	- 따라서 모델의 속도를 높이고 메모리 사용량을 줄일 수 있는 최적화도 수행될 수 있다.

#### REST API로 모델 배포하기
- 가장 보편적인 모델 -> 제품 배포 방식.
- **서버, 클라우드 인스턴스에 텐서플로우 설치 -> REST API로 모델 예측 요청**
- Flask나 파이썬 웹 개발 라이브러리를 이용해 직접 Serving 앱을 만들 수도 있다.
- 텐서플로 서빙을 쓸 경우 몇 분 만에 케라스 모델을 배포할 수 있다. 
- 조건
	- 모델 예측을 사용할 앱이 인터넷에 안정적으로 접속할 수 있어야 한다.
	- 응답 속도에 대한 요구 사항이 엄격하지 않다 : 일반적으로 요청 -> 추론 -> 응답에 `500ms`가 걸림
	- 추론을 위해 전달되는 입력 데이터가 민감하지 않다 : 서버는 암호화되지 않은 데이터를 사용할 수 있어야 한다(HTTP 요청 & 응답을 위한 SSL 암호화는 필요함)

- 예시 : 이미지 검색 엔진, 음악 추천, 신용 카드 부정 거래 감지, 위성 이미지

- 중요한건 직접 서비스를 구성할지 아니면 관리형 서드파티 클라우드 서비스를 쓸 지 결정하는 것이다.
	- 구글 `Cloud AI Platform`은 텐서플로우를 `Google Cloud Storage`에 업로드하기만 하면 추론 요청을 보낼 수 있는 API 엔드포인트를 제공한다.
		- 배치 예측, 로드밸런싱, 확장 등 처리해줌


#### 장치로 모델 배포하기
- 이런 방식을 사용해야 함
	- 모델의 응답 속도 제약이 엄격하거나, 인터넷 연결이 불안정
		- 몰입형 증강 현실 앱을 만든다면, 원격 서버 질의는 불가능
	- `텐서플로우 모델 최적화 도구(Tensorflow Model Optimization Toolkit)`를 사용하면 작게 만들 수 있다.
	- 최상의 정확도가 작업에서 크게 중요하지 않다 : 효율성과 정확도 사이의 절충점을 찾아서, 메모리와 전력 조건을 고려한 모델을 만들어야 함.
	- 입력 데이터가 매우 민감하며, 원격 서버에서 암호화가 해제되면 안된다.
- `Tensorflow Lite`가 스마트폰, 임베디드 장치를 위한 솔루션이다.

#### 브라우저에 모델 배포하기
- 브라우저나 데스크톱 기반의 JS 앱에서 쓰일 수도 있다.
	- 사용자 측에서 계산을 수행
	- 입력 데이터가 사용자의 컴퓨터나 핸드폰에 있어야 함
	- 앱의 응답 속도 제약이 엄격함
	- 모델을 받아 저장 후, 인터넷이 연결되지 않은 상태에서 작동할 수 있어야 함
- `Tensorflow.js`가 있음.

#### 추론 모델 최적화
- 스마트폰, 임베디드나 브라우저 애플리케이션 배포 시 특히 중요하다.
- `Tensorflow.js`를 쓰기 전에 최적화해야 함
	- `가중치 가지치기Weight Pruning` : 가중치 텐서 중 가장 큰 값만 남겨서 파라미터 개수를 크게 줄인다. 성능 저하가 있지만 메모리, 계산 자원을 줄인다. 가지 치는 정도를 조정할 수 있음.
	- `가중치 양자화Weight Quantization` : `float32`를 쓰는 모델을 `int8`로 압축해서 쓸 수 있다. `1/4`의 크기임에도 원본 모델의 정확도에 가까운 추론 모델을 얻을 수 있따.
- 

### 작동 중 모니터링하기
- 배포 후 동작을 모니터링해야 한다.
	- 가입이 늘었는가 줄었는가? 지표가 상승했는가? 
		- 랜덤한 A/B 테스트를 수행할 수 있다.
	- 제품 환경에서 모델 예측을 정기적으로 수동으로 조사하라. 
		- 데이터 애너테이션 인프라를 재사용할 수 있다. 수동으로 애너테이션과 모델 예측을 비교해본다.
	- 수동 조사가 불가능하다면, 사용자 설문 같은 평가 수단을 이용할 수 있다.

### 모델 유지관리하기
- `개념 이동` 같이, 시간이 지나면서 제품의 환경과 데이터 속성이 변하고 모델의 성능이 저하한다.
	- 음악 추천 시스템의 수명은 몇 주임
	- 신용 카드 부정 거래 시스템은 며칠임
	- 이미지 검색은 좋아야 몇 년임
- 지켜봐야 할 것
	- 제품 환경의 데이터 변화 감시하기 : 새로운 특성? 타깃 클래스 확장 or 수정 필요?
	- 계속 데이터 수집하고, 애너테이션을 수행하고, 파이프라인을 개선하라.
		- 특히 현재 모델이 분류하기 어려워 보이는 샘플을 수집하는 데 관심을 두라.

- 이 책의 대부분은 모델 개발에 맞춰져 있지만, 이는 워크플로우의 일부에 불과하다. 큰 그림을 보자.