[깃허브 정리 내용](https://github.com/dowrave/TIL/blob/main/FeatureEngineering/3_CreatingFeatures.ipynb)
- 새로운 특성을 만드는 팁들
	- 데이터에 대한 문서 읽기
	- 도메인 지식 얻기 : 위키피디아로 출발하는 게 좋고, 책이나 저널 기사 등의 정보가 제일 많다.
	- 이전 대회들의 작업물 보기
	- 시각화 활용하기

#### 수학적 변환
- 수학 공식으로 수치적 특징 사이의 관계를 설명할 수 있다. 도메인에 대한 지식이 있다면 좋겠죠?
- 시각화를 통해 변환을 할 필요를 느낄 수도 있다.
	- 예를 들어 분포가 너무 한 쪽으로 쏠려있다면(Skewness) `로그 변환`을 고려해볼 수 있다.
		- 공식도 간단함 : `df.feature.apply(np.log1p)`

### Count
- 어떤 값의 유무를 나타낼 때 쓸 수 있는 집계 연산(혹은 이를 통해 만드는 열)이 `Count`이다.
- 파이썬은 Bool도 이진값처럼 처리할 수 있음
- Bool 값을 만들어낼 수도 있다
```python
df[col].gt(0) # 값이 0을 초과하면 T, 아니면 F // greater than
```

#### 복잡한 특성 만들고 분해하기
- `str` : `string`에 적용할 수 있는 메서드들을 이용할 수 있다.
1. `str.split` :  `df[[new_col1, new_col2]] = df[col].str.split(' ', expand = True)` 요런 식으로 쓸 수 있음
2. 합치는 건 그냥 `df[col1] + '_' + df[col2]` 이런 식으로 구현할 수 있음

- 이외에도 날짜나 위도, 경도 값들을 파싱할 수 있다.

### Group Transform
- 흔히 써왔던` groupby()[].transform()` 개념이다.
	-  `()` 안에 쓸 수 있는 빌트인 메서드로 `mean, max, min, median, var, std, count` 등이 있음.
	- 저렇게 만든 `transform`은 바로 열이 되니까 저 결과에 바로 연산을 가할 수도 있다
		- `groupby()[].transform() / df.col.count()` 같은 게 된다는 소리
- 훈련 / 검증 테스트 분리를 이용한다면, 훈련 테스트에 대해서만 그룹 피쳐를 적용하고 이를 그대로 검증 세트에 쓰는 게 제일 좋다
```python
df_train = customer.sample(frac=0.5)
df_valid = customer.drop(df_train.index)

df_train["AverageClaim"] = df_train.groupby("Coverage")["ClaimAmount"].transform("mean")

df_valid = df_valid.merge(
    df_train[["Coverage", "AverageClaim"]].drop_duplicates(),
    on="Coverage",
    how="left",
)
```

#### 피쳐 만들기 가이드라인
- `선형 모델` : 합, 차를 학습하지만 그 이상 복잡한 건 학습할 수 없음
- `Ratio` : 자체로는 대부분의 모델에서 학습하기 어려운데, `Ratio Combination` 특성을 넣으면 쉽게 좋은 성능을 얻는 방법이 자주 되는 편이다.
- `선형 모델, Neural Network` : 정규화된 피쳐에서 잘 작동한다. 특히 신경망은 값이 0에서 너무 멀지 않을 필요가 있다.
- `트리 기반 모델` : 정규화의 필요성이 강하지 않음
	- 트리 모델은 피쳐들을 조합하는 경우의 수를 따져들어가기 때문에, **피쳐나 데이터가 적은 상황에서** 피쳐를 추가로 만드는 건 새로운 조합을 만드는 일이므로 매우 중요하다
	- `Count`는 트리 모델에 도움이 된다 : 모델 자체적으로 여러 피쳐를 집계하는 방법이 없기 때문.

