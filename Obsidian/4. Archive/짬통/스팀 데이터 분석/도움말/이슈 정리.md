#### 1. pd.merge()에서 키로 사용하는 값
프로젝트 진행중 `pk`로 사용할 값이 2개가 있는 상황. 하나는 `object`, 다른 하나는 `int`.
chatGPT에게 물어보니까 `int`를 키로 사용하는 것을 아래의 이유로 권장하고 있다.
> 1. `int`값 비교가 `object` 비교보다 빠름
> 2. 메모리 사용을 줄일 수 있음
> 3. 인덱스로 `int`를 쓸 경우 `object`보다 더 빠름

- 대충 더 빠르다는 뜻 
- 이외에도 검색해보면, **`key`와 `key `는 구분되기 때문에 `pk`로 쓰기 난감한 구석이 있다**는 말도 있다. 

- 근데 지금 내 경우를 생각해보자
- 4개의 테이블로 분리를 했고, `pk`는 `name`으로 지정한 상황임
- 왜냐하면 `merge, join`을 하지 않고 단독 테이블만 사용하는 상황을 고려했기 때문 -> 만약 `appid`만을 `pk`로 쓴다면, 시각화하는 상황에서 `name` column만을 가져오기 위해 `merge`를 하는 상황이 발생할 수 있기 때문이다
- 이러한 걸 chatGPT에게 물어보니 이런 대답이 옴
> 1. PK를 선택하는 기준
> - 유일성
> - 데이터를 합칠 수 있는 기준이 되는가
> - 쿼리 성능
> 2. 한편 `object`를 `pk`로 쓰는 것엔 이런 단점이 있다
> - 데이터 길이와 효율성 : `object`가 `int` 대비 공간을 더 먹는다는거
> - 안정성과 변화 : `object`는 미래에 바뀌거나 복제될 가능성이 있음 
> 3. 외부 데이터와 합치는 경우

#### 2. 데이터프레임 마지막 인덱싱
```python
df['col'][-1] # 안됨
df.loc[-1, 'col'] # 안됨

# -1을 쓰고 싶다면 iloc를 이용하자
df['col'].iloc[-1]
```

#### 3. 데이터 보관 방식
- 현재 1개의 데이터를 4개의 csv 파일로 나눠서 보관 중임 : 하나는 시간에 관계 없는 정보, 다른 하나는 시간에 관계 있는 정보, 나머지 2개는 원핫인코딩으로 사용해야 할 것 같아서 따로 분리해놓은 상태임
- 문제는 이렇게 해놓으면 원래에 비해 훨씬 많은 저장 공간을 먹는다는 것임

> 데이터를 나누는 것의 장점
> 1. 모듈화 : 데이터의 부분집합에 대한 작업을 더 손쉽게 만듦 -> 찾고자 하는 작업, 원하는 작업에 대한 접근을 더 손쉽게 할 수 있음
> 2. 성능 : 메모리에 로드하는 데이터를 줄임으로써 성능 향상 가능
> 3. Scalibility(용량을 늘였다 줄였다 하는 것의 자유로움; 용량탄력성?) : 병렬처리도 가능해짐

> 주의점
> - 꾸준히 같이 쓰이는 데이터를 쪼갤 필요는 없음 : 모든 column 단위로 데이터를 나누지는 않으니까

- 결국 정해진 좋은 방법은 없고 **용량, 데이터의 크기, 접근 빈도**에 따라 방법을 다르게 취하면 됨
- 사실 지금 걱정하는 이유도 데이터가 쌓이는 상황 때문이긴 한데.. 가상의 상황을 가정하고 어떻게 대응하면 좋은지 고민해보는 것도 좋다고 생각함


#### 4. Pymysql : With Connection() 문
- 원래 `pymysql.connect()`으로 만드는 `connection`객체는 `autocommit = False`로 설정, 그 내용이 자동으로 커밋되지 않는다. 그러나 **해당 객체를 `with`문과 함께 사용한다면, `with`문이 종료됨과 동시에 `commit`이 자동으로 된다.**
- 한편 **`with conn.cursor()`으로 닫힌 `cursor`문은 자동으로 커밋되지 않고, 자원을 안전하게 정리하는 역할을 한다.**

#### 5. pymysql : 데이터 조회
```python
conn = pymysql.connect()#이미 있다고 가정
q = "SELECT date FROM time_value ORDER BY 1 DESC LIMIT 1"

with conn.cursor() as cur:
	cur.execute(q)
	print(cur.fetchall()) 
```
- `execute`를 한 다음, 별다른 객체 지정 없이 `cursor.fetchall()`로 조회할 수 있당.

- 날짜 조회할 때 쿼리에 '날짜'로 들어가므로, 파이썬에서도 ''을 쳐줘야 함

#### 6. to_sql() 관련 이슈
- `to_sql(name, conn)`에서, `conn`에는 `pymysql.connect`, `sqlalchemy.create_engine.connect` 객체가 모두 쓰일 수 있다.
- 근데 `pymysql.connect`을 쓴 경우, 데이터가 정상적으로 저장되지 않는 문제가 있었음 -> `sqlalchemy`로 바꾸니까 해결O


#### 7. MySQL 포트 번호 확인하기
```sql
SHOW GLOBAL VARAIBLES LIKE 'PORT';
```

#### 8. MySQL 호스트 포트 번호 설정하기
```sh
-p a:b
```
- `a`는 (내 경우)윈도우 OS의 포트로, `3306`은 이미 MySQL에서 쓰고 있기 때문에 지정할 수 없다. `3307`도 나중에 MariaDB를 쓸 경우가 있을 수 있기 때문에 지정하지 않는 게 좋을 것 같다.
- 대신, 리눅스에서 이걸 입력해보면
```sh
sudo cat /proc/sys/net/ipv4/ip_local_port_range
# 32768 60999
```
- 위와 같이 뜨며, 명령어에 나온 것처럼 `로컬 포트 범위`라고 한다. 저 범위 내에서 호스트 포트 번호를 선택하면 되겠다.

#### 9. utc 시간 변환하기
```python
from datetime import datetime

datetime.utcfromtimestamp('utc시간')
```


#### 10. VARCHAR()에 들어가는 숫자는 '글자 수'이다.
[VARCHAR과 TEXT의 차이 참고](https://leezzangmin.tistory.com/49)
- VARCHAR은 '바이트의 개수'를 저장함. 
- UTF-8로 인코딩된 한글 단일 글자는 3바이트이고, 스팀의 글자수 제한은 8000자이다.
- 그러면 해당 데이터를 저장하려면 `VARCHAR(24000)`을 저장해야 하는가? 아니다.
- 영어 1글자이든 한글 1글자이든 '바이트의 개수'는 1개로 동일하다. 둘의 용량은 1바이트와 3바이트로 다르더라도 말이다.
- 스팀의 글자수 제한이 8000자라는 이슈가 있고, 실제로 도배성 리뷰를 조회했을 때도 8000자인 리뷰가 있는 걸 봐서는 `VARCHAR(8000)`으로 지정하면 맞을 것 같음.

#### 11. numpy에서 특이한 상황 발견
- 하긴 했는데.. 왜 같은 상황으로 실험하니까 또 잘 되지?

- 요는, numpy 배열에서 파이썬의 `iterable` 객체에 쓰는 `in` 같은 문법을 사용하고 싶다면, `np.any(arr == x)` 같은 걸 쓸 수 있다는 것임
- `in` 같은 경우, 자료형까지 맞춰줬는데도 올바르게 반환하지 않는 케이스가 있어서 기록해둠.