- **다수에 비해 매우 적은 소수의 클래스에 더 큰 관심이 있을 경우 클래스 균형이 필요**하다
- 즉 자주 나오는 얘기인 `Accuracy`와 `Precision`, `Recall`에 관한 이야기
-----------
## 1. Weight Balancing
- 특정 클래스의 데이터에 더 큰 loss값을 갖게 하는 방법
- 케라스로 쉽게 구현할 수 있다.
```python
import keras

class_weight = {"buy": 0.75,
                "don't buy": 0.25}

model.fit(X_train, Y_train, epochs=10, batch_size=32, class_weight=class_weight)
```

### Focal Loss
- 분류 성능이 높은 클래스의 가중치를 줄인다
- 이 때 사용되는 파라미터가 $\gamma$ 임. 
$$FL(p_t) = -(1-p_t)^r \times log(p_t)$$
- 케라스에는 [[BinaryFocalCrossentropy]], [[SigmoidFocalCrossEntropy]] 가 있음.
-----------
## 2. Over, Under Sampling
- `Undersampling` : 많은 레이블을 가진 데이터의 일부만을 선택함
- `Oversampling` : 적은 레이블을 가진 데이터에서 최대한 많은 양을 이용함