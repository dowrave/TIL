- 이전 : [[7-3. Connect & Connector]]

- 전체 다이어그램
![[Pasted image 20230104143415.png]]
- `Zookeeper` 
	- 브로커 서버의 상태 감지
- `Broker` 
	- `Source Connector`에서 데이터를 받아 `Topic`에 저장
	- `Sink Connector`로 데이터를 넘겨줌
	- 여기선 단일 브로커를 사용함
- `Schema Registry` 
	- 메시지의 `Schema`를 저장하는 서버
- `Connect`
	- `Connector`를 띄우는 서버


- 주키퍼, 브로커는 앞에서 사용한 코드와 동일함
```sh
cp naive-docker-compose.yaml kafka-docker-compose.yaml
```

### 스키마 레지스트리
```yaml
version: "3"  
  
services:  
  schema-registry:  
	image: confluentinc/cp-schema-registry:7.3.0  
	container_name: schema-registry  
	depends_on:  
	  - broker  
	ports:  
	  - 8081:8081  
	environment:  
	  SCHEMA_REGISTRY_HOST_NAME: schema-registry  
	  SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: broker:29092  
	  SCHEMA_REGISTRY_LISTENERS: http://schema-registry:8081
```
- 환경변수
> - `SCHEMA_REGISTRY_BOOTSTRAP_SERVERS` 
>> - `Bootstrap`으로 띄워진 서버 이름
>>- 일반적으로 `브로커 서비스 이름 : 브로커 서비스 내부 포트` 형식으로 작성됨
	- `SCHEMA_REGISTRY_LISTENERS`
>> -  외부에서 접속할 리스너 설정

### Connect
- 별도의 Dockerfile을 만들어야 함
- `connect.Dockerfile`
```dockerfile
FROM confluentinc/cp-kafka-connect:7.3.0  
  
ENV CONNECT_PLUGIN_PATH="/usr/share/java,/usr/share/confluent-hub-components"  
  
RUN confluent-hub install --no-prompt snowflakeinc/snowflake-kafka-connector:1.5.5 &&\  
confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.2.2 &&\  
confluent-hub install --no-prompt confluentinc/kafka-connect-json-schema-converter:7.3.0
```
> `ENV` :
>> - 플러그인의 PATH를 2개 설정함 : 경로는 `base`이미지로부터.
>>> 1. `/usr/share/java`
>>> 2. `/usr/share/confluent-hub-components`
> 위 둘은 `""` 속에서 `,`로 구분됨
> `RUN`:
>> - 사용할 커넥터는 `JDBC Connector`이며, `PostgreSQL DB`에 접근이 가능한 커넥터를 설치해야 한다.
>> - `value schema`의 컨버터는 `Json Schema Converter`

- 이를 `docker-compose` 파일에 반영한다.

- `kafka-docker-compose.yaml`
```yaml
version: "3"  
  
services:  
  connect:  
	build:  
	  context: .  
	  dockerfile: connect.Dockerfile  
	container_name: connect  
	depends_on:  
	  - broker  
	  - schema-registry  
	ports:  
	  - 8083:8083  
	environment:  
	  CONNECT_BOOTSTRAP_SERVERS: broker:29092  
	  CONNECT_REST_ADVERTISED_HOST_NAME: connect  
	  CONNECT_GROUP_ID: docker-connect-group  
	  CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs  
	  CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1  
	  CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets  
	  CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1  
	  CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status  
	  CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1  
	  CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter  
	  CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter  
	  CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
```
- `broker`, `schema registry` 실행 후 `connector`가 실행돼야 함
- 환경변수
> `CONNECT_BOOTSTRAP_SERVER` 
>> - 연결할 브로커 서버 : `브로커 이름 : 브로커 내부 포트`
>
> `CONNECT_REST_ADVERTISED_HOST_NAME`
>> - 커넥터는 `REST API 요청에 대한 처리` 및 `Connector의 등록, 설정, 시작, 종료 처리를 담당`하는 Worker가 존재함
>> - Worker 간의 연결이 가능하도록 호스트 이름을 지정함
>
>`CONNECT_GROUP_ID`
>> - Connect의 Worker 프로세스 그룹(or 클러스터)을 구성하는 데 사용하는 고유 ID
>> - `Consumer` 그룹 ID와 충돌하면 안됨
>
> 그 밑으로는
> `CONNECT_CONFIG_STORAGE`
> `CONNECT_OFFSET_STORAGE`
> `CONNECT_STATUS_STORAGE`
> 각각 환경 설정, offset, 상태 저장 브로커를 의미하며 각각에 대해 `TOPIC`과 `REPLICATION_FACTOR` 항목이 있다. 단어가 의미하는 그대로임.
> 
> `CONNECT_KEY_CONVERTER` 
>>  - `KEY`에 대한 컨버터로, 여기선 `String Converter`이 사용
>
>`CONNECT_VALUE_CONVERTER`
>> - `VALUE`에 대한 컨버터, `Json Converter`가 사용됨
>
>`CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL`
>> - `Value Converter`에 대한 `Schema Registry URL`
>> - `Schema Registry`의 서비스 이름 & 포트를 지정하면 된다.

### 실행
```sh
docker compose -p part7-kakfa -f kafka-docker-compose.yaml up -d
```

- 서비스 확인 : `docker ps`
	- `kafka-connect`, `schema-registry`, `kafka`, `zookeeper` 4개의 컨테이너가 뜨면 성공
> ??? :
>- `kafka-connect`의 상태가 `health: starting`이라고 뜨는 게 괜찮은건가 싶은데 가이드에도 일단 그렇게 나와 있어서 다음으로 넘어감

- 다음 : [[7-5. Source Connector]]