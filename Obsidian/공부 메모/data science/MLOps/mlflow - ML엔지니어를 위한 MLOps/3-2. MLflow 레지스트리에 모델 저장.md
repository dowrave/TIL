이전 : [[3-1. MLflow Backend Store 구축]]

- 패키지 설치
```sh
pip install boto3==1.26.8 mlflow==1.30.0 scikit-leaern
```

- 2장에서 했던 `db_train.py`의 모델을 저장하는 부분을 모델을 업로드하는 코드로 바꿈

> - 2번째 폴더 -> 3번째 폴더로 복붙
```sh
cp 2_model_development/db_train.py 3_model_registry/db_train.py
```

### 모델 로컬 저장 -> 서버 업로드로 바꾸기
- `db_train.py` 내용 바꾸기
- 학습한 모델을 MLFlow 서버를 통해 Artifact Store인 MiniO에 저장한다. 
	- MiniO에 대한 접근 권한이 필요하며, 
	- 이 정보는 앞의 `MLflow Setup`의 `docker-compose.yaml` 파일에서 설정한 `mlflow-artifact-store` 정보와 같다.
- 접근에 사용할 아이디, 비밀번호는 사전에 정의된 시스템 환경 변수에 설정해야 하며, `MLflow`와 `S3(MiniO)`의 URI도 마찬가지이다.

- `db_train.py`에 추가
```python
import os

os.environ['MLFLOW_S3_ENDPOINT_URL'] = "http://localhost:9000"
os.environ['MLFLOW_TRACKING_URI'] = "http://localhost:5001"
os.environ['AWS_ACCESS_KEY_ID'] = "minio"
os.environ['AWS_SECRET_ACCESS_KEY'] = 'miniostorage'
```
> `MLFLOW_S3_ENDPOINT_URL` : 모델 저장 스토리지 주소
> `MLFLOW_TRACKING_URI` : 정보 저장을 위해 연결되는 MLflow 서버의 주소
> `AWS_ACCESS_KEY_ID` : MiniO 접근을 위한 ID 
> `AWS_SECRET_ACCESS_KEY` : MiniO 접근 비번

### 서버에 모델 저장하기
- `MLflow`는 `experiment`와 `run`을 사용한다.
	- `experiment` 
		- 정보 관리를 위해 나누는 **디렉토리**이다.
		- 이름 설정 가능
		- 이름 설정 안할 시 `Default`라는 이름의 `experiment`에 저장됨
	- `run`
		- `experiment`에 저장되는 모델 실험 결과
		- 실제 정보가 저장되며, `experiment/run`의 구조로 저장된다.

> `experiment` : `new-exp`을 생성하고 여기에 `run`을 생성하는 방식으로 진행함

- 추가할 부분들
1. 모델 이름을 설정할 **외부 변수를 설정**함. `sk_model`로 지정함
```python
from argparser import ArgumentParser

parser = ArgumentParser()
parser.add_argument('--model-name', dest='model_name', type = str, default = 'sk_model')
args = parser.parse_args()

```

2. `experiment` 설정 
```python
import mlflow

mlflow.set_experiment("new-exp")
```
> `mlflow.set_experiment` 함수는 해당 이름의 `experiment`가 없다면 새로 생성됨

3. 잘못된 정보가 들어올 때 에러를 발생시키기 위해, 모델에 입력값 정보들을 설정함
```python
signature = mlflow.models.signature.infer_signature(model_input= X_train, model_output = train_pred)
input_sample = X_train.iloc[:10]

print(signature) # [컬럼이름:데이터타입]
print(input_sample)
```

4. `run`을 생성 & 정보 저장
```python
with mlflow.start_run():
	mlflow.log_metrics({"train_acc" : train_acc,
						"valid_acc" : valid_acc})
	mlflow.sklearn.log_model(
		sk_model = model_pipeline,
		artifact_path = args.model_name,
		signature = signautre,
		input_example = input_sample,
		)
```
- `mlflow.log_metrics` : 모델의 결과 `metrics`를 딕셔너리 형태로 입력해 `run`에 저장됨
- `mlflow.sklearn.log_model` 
	- 사이킷런의 모델은 `mlflow.sklearn`으로 간편하게 업로드가 가능함
	- `mlflow storage format`의 구조로 `run`에 저장된다.

- 전체 파일 : `3_model_registry/db_train.py`
```python
import os  
from argparse import ArgumentParser  
  
import mlflow  
import pandas as pd  
import psycopg2  
from sklearn.metrics import accuracy_score  
from sklearn.model_selection import train_test_split  
from sklearn.pipeline import Pipeline  
from sklearn.preprocessing import StandardScaler  
from sklearn.svm import SVC  
  
# 0. set mlflow environments  
os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://localhost:9000"  
os.environ["MLFLOW_TRACKING_URI"] = "http://localhost:5001"  
os.environ["AWS_ACCESS_KEY_ID"] = "minio"  
os.environ["AWS_SECRET_ACCESS_KEY"] = "miniostorage"  
  
# 1. get data  
db_connect = psycopg2.connect(  
	user="myuser",  
	password="mypassword",  
	host="localhost",  
	port=5432,  
	database="mydatabase",  
)  
df = pd.read_sql("SELECT * FROM iris_data ORDER BY id DESC LIMIT 100", db_connect)  
  
X = df.drop(["id", "timestamp", "target"], axis="columns")  
y = df["target"]  
X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=2022)  
  
# 2. model development and train  
model_pipeline = Pipeline([("scaler", StandardScaler()), ("svc", SVC())])  
model_pipeline.fit(X_train, y_train)  
  
train_pred = model_pipeline.predict(X_train)  
valid_pred = model_pipeline.predict(X_valid)  
  
train_acc = accuracy_score(y_true=y_train, y_pred=train_pred)  
valid_acc = accuracy_score(y_true=y_valid, y_pred=valid_pred)  
  
print("Train Accuracy :", train_acc)  
print("Valid Accuracy :", valid_acc)  
  
# 3. save model  
parser = ArgumentParser()  
parser.add_argument("--model-name", dest="model_name", type=str, default="sk_model")  
args = parser.parse_args()  
  
mlflow.set_experiment("new-exp")  
  
signature = mlflow.models.signature.infer_signature(model_input=X_train, model_output=train_pred)  
input_sample = X_train.iloc[:10]  
  
with mlflow.start_run():  
	mlflow.log_metrics({"train_acc": train_acc, "valid_acc": valid_acc})  
	mlflow.sklearn.log_model(  
						sk_model=model_pipeline,  
						artifact_path=args.model_name,  
						signature=signature,  
						input_example=input_sample,  
)  
  
# 4. save data  
df.to_csv("data.csv", index=False)
```

- 실행
```sh
python3 db_train.py --model-name "sk_model"
```

- 결과 확인
	-  [localhost:5001](http://localhost:5001/)에 뜨면 성공
![[Pasted image 20221230172742.png]]

다음 : [[3-3. MLflow 레지스트리에서 모델 불러오기]]