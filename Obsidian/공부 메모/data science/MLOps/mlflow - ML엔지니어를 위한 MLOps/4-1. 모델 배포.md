이전 : [[3-3. MLflow 레지스트리에서 모델 불러오기]]

학습이 완료된 모델을 다른 사람이 사용하게 하려면?

1. 저장된 모델 & 추론 코드를 사용자에게 전달
- 문제 : 사용자마다 디바이스 환경이 다르다.
	- 모델이 너무 크다거나
	- 패키지 버전이 맞지 않다거나

### Request - Response
그렇다면 **데이터만 모델을 돌릴 수 있는 환경으로 전송하고, 추론 결과만을 받는다**면?
- ML 외에도 많은 SW에서 쓰이는 방식으로, 이를 `Request-Response` 방식이라고 한다.
![[Pasted image 20221230180710.png]]
- 이 때 요청과 응답을 어떻게 할 것인지에 대해 정의하는 절차가 필요하다. 가장 대표적인 방법이 `REST API` 이다.
- 5장에서는 가장 대표적인 `REST API`를 구현하는 `FastAPI`를 학습함
- 6장에서는 `REST API`로 결과를 얻는 `API Serving`을 다룸

### Stream Serving
- 데이터가 계속해서 쌓임 + 실시간 이상 탐지 모델 서빙이 필요한 상황을 가정하자.  
- 기존의 `request-response` 방식에는 문제가 많음
	- 수집 센서가 요청을 보낼 수 없는 경우가 많음(아주 작은 업무만 할 수 있기 때문에)
	- 요청을 통해 결과를 받는 주체가 센서가 아닌 경우도 많음(요청한 대상과 응답받는 대상이 다른 경우)
- 따라서 **대신** `요청을 보내고 결과를 수집할 수 있는 주체`가 필요함

- 이러한 `실시간` 상황을 `Stream`이라고 한다.
- 7장에서는 `Kafka`를 다루며 
- 8장에서는 `Stream Serving` 및 이를 대쉬보드로 연결하여 시각화하는 `Grafana`를 학습한다.

- 다음 : [[5-1. FastAPI 튜토리얼]]