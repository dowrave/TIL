
## 목표
1. `steamspypi`에 있는 데이터를 지속적으로 수집 & 가공하는 파이프라인 만들기
	- 구현 가능하다면 자동화도 시도하기
2. 날짜에 따른 `ccu`, `positive`, `negative` 추적 및 분석해보기
3. 카테고리나 태그에 따른 분석하기(가능하다면)
4. 할인율에 따른 분석도 ㅇㅋ

---

## 일지

### 230518
- `get_details()`에 날짜 column 추가
	- 순위를 벗어난 데이터는 `get_details()`로만 정보를 얻기 때문에 여기에 대한 날짜를 추가로 넣음
- 일단 `tag.csv`, `info_genre.csv`는 `key, value` 형태를 그대로 유지함
	- 이걸 쓰게 된다면 원핫인코딩을 할 거 같은데, 모아놨다가 필요할 때 원핫인코딩을 하는 게 나을 거 같음 :  들어올 때마다 원핫인코딩으로 처리하면 데이터프레임의 스키마가 달라질 수 있기 때문(없는 태그에 대해서는 feature가 안생기는데, 기존 데이터프레임에는 있었다고 하면 좀 골치아파짐)
- 데이터 수집 & 가공 과정 파이프라인으로 정리 중

- 머리로 생각하려니까 헷갈린다..
> 어떤 날 수집한 데이터와 이미 있는 데이터를 비교해보자
> 데이터는 크게 3가지 종류로 나뉜다.
> 1. `info.csv`에 이미 있으면서 5000개를 수집했을 때 이미 있는 데이터  
>
> 2. `info.csv`에 이미 있지만, 5000개를 수집했을 때는 나타나지 않는 데이터(순위에서 벗어남)  
> 3. `info.csv`에 없지만 5000개를 수집했을 때 나타나는 데이터  
1. 바로 날짜와 수치 정보만 떼내서 날짜&수치 테이블에 저장함
2. `detail`에 관한 쿼리를 날려서 오늘의 정보를 얻은 뒤, 날짜와 수치 정보를 떼내서 날짜&수치 테이블에 저장함
3. `detail`에 관한 쿼리를 날려서 오늘의 정보를 얻고, 얻은 정보를 4개의 테이블에 나눠 저장함


### 230517
- 어떤 날의 `ccu`는 모든 데이터 수집할 때 얻을 수 있다
- `detail`에 관한 정보는 새로운 게임이 생겼을 때, 해당되는 게임들만 수집하면 되며 얘네들은 날짜에 따라 업데이트되는 데이터가 아님(태그를 제거하기 떄문에)
- 따라서 데이터 수집 과정은 이런 식으로 정리할 수 있음
```
데이터 수집 과정
# 최초 실행
1. 상위 5000개 게임 수집 및 중복값, 결측치 처리
2. 5000개 게임의 지원 언어와 장르, 태그를 얻기 위해 `appdetails`를 리퀘스트
3. 얻은 데이터를 테이블을 구분해서 저장함
	- 게임 정보 : `appid, name, developer, publisher, initialprice`
	- 날짜와 수치 정보 : `name, ccu, positive, negative, average,median 2weeks`
	- 세부 정보(1) : name, 언어, 장르
	- 세부 정보(2) : name, 태그
- 언어, 장르, 태그는 `,`로 구분된 정보들이므로 일단 원핫인코딩을 처리함
- 정보는 일단 다 남겨둔다
---
# 2회 실행 이후
1. 상위 5000개 데이터 수집
2. 기존 게임 정보 테이블과 `appid`를 비교, 새로 생긴 데이터와 `appdetails`를 받아옴. 이미 수집된 적 있는 데이터라면 역시 `appid`를 이용해 계속적으로 추적함
3. 새로운 데이터는 4개로 나눠 저장함. 날짜와 수치 정보 테이블에 해당 정보들을 갱신함

# 추가
- 특정 시간마다 자동 실행되면 좋을 듯 -> 아마 `py` 파일로 바꾼 다음에 윈도우 스케줄러를 이용해야 할 듯
- 아니면 무한 반복 & 컨테이너를 쓰는 방법도 있을 듯
```

#### 자동화 관련
- 도커 컨테이너를 하나 띄운다음에, 무한히 반복되지만 특정 시간에만 실행되는 스크립트를 짜면 되지 않을까? 
- 근데 그러면 컨테이너 밖으로 파일을 빼는 방법을 생각해봐야겠다. 

#### 앞으로 할 일
1. 새로 추가된 데이터 : 디테일을 얻은 다음, `info, lang_genre, tag`에 정보 저장
2. 5000위 내에 있는 데이터 : 새로 데이터를 얻은 날짜의 수치 데이터를 `time_value`에 저장
3. 5000위를 벗어난 데이터 : 디테일을 얻은 다음 `time_value`에 저장
4. 위 과정 함수화 & 자동화
	- 하나씩 ㄱㄱ


### 230516
- `steamspypi` 다시 멀쩡하게 작동함 : 기존 약 4800여개의 데이터로 진행하려던 내용 수정
- 중복값 처리 이슈
	- `ccu`가 더 큰 데이터를 살림 : `sort` 이후 `drop_duplicate` 이용
> 원래 스크래핑하려고 했는데 기존 코드도 손볼 게 많다 많아

#### 앞으로 할 일(1.Collect_Preprocesssing)
```
1. `details` 수집하기
2. `genre` 분리해서 별도의 `column`으로 만들기
3. 데이터프레임을 `info`, `time_value`, `category`로 나눠서 보관하고, `time_value`는 날마다 수집하기
4. (가능하면) 자동화하기

- 이후는 탐색
```



## 230515 
- `steamspypi`가 이상함 : `download_all_pages()`를 해도 `Dota 2`부터 받아지는 게 아니라 이상한 게임 이름이 맨 앞으로 옴
- 그래서 이미 있는 데이터로 징행함
