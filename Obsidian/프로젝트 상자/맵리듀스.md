### 윈도우 터미널 탭
1. `git clone https://github.com/CUKykkim/hadoop-docker`
2. `cd hadoop-docker`
3. `docker compose up`

### 우분투 탭
4. `docker ps`
5. `docker exec -it (NameNode 컨테이너 id) /bin/bash`
6. `vi input.txt`
	```
	Apple Apple Apple

	Banana Banana

	Melon
	```
	- hdfs에 올리기 (루트)
	`hdfs dfs -put input.txt /`
7. `map.py` 작성
```python
import sys

for line in sys.stdin:

    keys = line.strip().split()

    for key in keys:

        print("{0}\t{1}".format(key, 1))
```
- 파이썬 버전 3.5.3이라 그런가 f-string이 먹히지 않음
- `cat input.txt | python3 map.py`
	- 실행 결과
	```
	Apple 1 Apple 1 Apple 1 Banana 1 Banana 1 Melon 1
	```

8. `reduce.py` 작성
```python
import sys
last_key = None
running_total = 0
for input_line in sys.stdin:
  input_line = input_line.strip()
  this_key, value = input_line.split('\t', 1)
  value = int(value)
  # 기존 존재한다면 카운트 증가
  if last_key == this_key:
    running_total += value
  else: # 새로운 단어
    print("{0}\t{1}".format(last_key, running_total))
  running_total = value
  last_key = this_key
if last_key==this_key:
  print("{0}\t{1}".format(last_key, running_total))
```
- 따로 실행한 결과
```
Apple 3 Banana 2 Melon 1
```
9. 두 파일 HadoopStreaming으로 옮김
	- 경로 `/hadoop-data/HadoopWithPython/python/MapReduce/HadoopStreaming`

10. HadoopStreaming에서 맵리듀스 실행
`hadoop jar /opt/hadoop-3.2.1/share/hadoop/tools/lib/hadoop-streaming-3.2.1.jar -input /input.txt -output /220817_3 -mapper mapper.py -file mapper.py -reducer reducer.py -file reducer.py`
- hdfs 상의 `220817_3` 에서 성공(기존에 있는 `mapper.py`와 `reducer.py`를 쓸 때만 성공했음)
	- 결과 확인 : `hdfs dfs -cat /220817_3/part-00000`
		```
		Apple 3
		Banana 2
		Melon 1
		```
- 즉 내가 만든 `map.py`와 `reduce.py`는 `Streaming Command Failed!`라는 오류가 뜸
	- `map` - `reducer` / `mapper` - `reduce` 모두 같은 오류 발생

11. HDFS 상에서 컨테이너로 파일 가져오기 :  `hdfs dfs -get /220817_3/part-00000 .

12. 컨테이너에서 로컬로 파일 가져오기 - 별도의 터미널 탭을 `hadoop-docker` 폴더에서 실행
	- `docker cp namenode:/hadoop-data/HadoopWithPython/python/MapReduce/HadoopStreaming/part-00000 .`
		- `/bin/bash`는 쓰지 않아도 된다.

