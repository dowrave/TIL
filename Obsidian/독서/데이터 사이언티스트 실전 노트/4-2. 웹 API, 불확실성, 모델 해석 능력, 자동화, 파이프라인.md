## 1. 모델 수익화(Web API)
- `API(Application Programming Interface)` : 응용 프로그래밍 인터페이스

### 작동
- 사용자가 앱에 접속해 필요한 정보를 양식에 맞게 **요청(Request)**
- 앱은 요청받은 정보를 **응답(Response)**

- 앱은 다른 앱에 접속할 수 있다.
	- 요청은 HTTP을 통해 진행되고
	- 응답은 XML이나 JSON으로 이뤄진다.

- 대충 유료 API 서비스를 만들어서 필요한 정보를 제공한다는 얘기

#### Flask
#### 도커
- 기존엔 1개의 머신에서 1개의 앱 서비스만 제공할 수 있었다
	- 트래픽이 늘어나면 여러 컴퓨터를 구축해야 하는데, 그 자원에 드는 비용이 많앗음
	- VM(가상머신)이 낭비된 자원을 활용할 수 있었지만, 스케일 업/다운을 운영하는 데에는 한계가 있었음
- 컨테이너 두둥

#### AWS ECS
- 컨테이너를 관리하는 AWS ECS(Elastic Container Service), 호근 AWS EKS(Elastic K8s Service)
- 컨테이너가 많아지면서 컨테이너들을 관리할 프로그램이 또 필요해졌다~는 뜻

## 2. 불확실성 다루기
> 예시 ) 서울과 제주 지역 집값을 예측하는 모델을 만든다.  
> 오차 없는 예측 모델을 만드는 것은 불가능하다.  
> **오류를 최소화하기 위해 집값에 영향을 주는 핵심만을 파악해 이를 이용한 모델을 만들었다면, 오류가 있더라도 예측값이 잘못된 것이 아니다.**   
> 이 때 초기 모델 A를 만들었다면 이를 그대로 쓸지 더 보완할지를 어떤 기준으로 결정하면 좋을까?

- 모델을 그대로 쓸지 더 보완할지, 고려해야 할 사항들
	- 여러 데이터 중 올바른 / 필요한 데이터를 사용했는가?
	- 훈련 데이터 이외의 타깃에 대한 정보로 학습이 되진 않았는가?
	- 코딩 문제점은 없는가?
	- 예측 값을 얻을 때까지의 계산 시간이 오래 걸리는가?
	- 성능이 만족할 만 한가?

- **예측 모델 성능 + 불확실성**으로 압축할 수 있다.

### 1. 예측 모델 성능
>예시 )  
>MAE(평균절댓값오류)를 사용했고 서울은 8천만원, 제주는 3천만원의 MAE가 있었다  
> 이를 보완한 모델을 만들었더니 서울은 7천만원, 제주는 4천만원의 MAE가 나왔다.  

- 윗줄만의 상황으로 이 모델을 더 쓸까 보완할까?를 판단하는 것도 쉽지 않고
- 아랫줄까지의 상황으로 두 모델 중 어떤 모델을 쓸까?를 판단하는 것도 쉽지 않다.

> tip) MAE 대신 RMSE를 쓰기도 한다. 제곱을 안 쓰는 이유는 이상치의 영향이 커지니까. 혹은 Root Median Square Error를 쓰기도 한다.

- 따라서, **모델 성능은 꼭 확인해야 할 사항이지만 이것만으로 결정할 수는 없다.** 여기서 **불확실성**이 등장한다.

### 2. 불확실성

- 불확실성은 2가지 종류로 나뉜다.
1. **무작위 불확실성(Aleatoric Uncertainty): 데이터 수집 과정에서 발생하는 무작위성**
	- 많은 데이터를 수집하더라도 모델 성능이 악화되는 경우가 있다. 데이터가 많아지면 불확실성도 커지기 때문이다.
2. **인식론적 불확실성(Epistemic Uncertainty) : 지식의 부족으로 인한 불확실성**
	- 리서치, 시뮬레이션 등으로 줄일 수 있지만, 모수 자체를 알지 못하는 데서 나오는 불확실성도 여기서 나온다.

#### 실무에서의 불확실성

##### 왜 불확실성을 파악해야 하는가?
- 완벽한 예측 모델을 만드는 건 불가능하다.
- 그러나 **예측 모델을 이해하고 설명할 수 있어야 한다.**
- **불확실성의 유형을 파악**함으로써, **어떤 종류의 불확실성이 있는지 구체화하거나 정량화**할 수 있다.
	- 예측 모델을 재점검하거나 보완할 요소에 대한 우선순위를 정할 수 있고, 이를 사용할 클라이언트나 사용자의 의문점 또한 해소할 수 있다.

##### 불확실성을 다루는 4단계
1. 정리 : 예측 모델이 만들어지는 과정에서 발생하는 불확실성의 종류
2. 선택 :  많은 불확실성 중 다룰 것 선택
3. 구체화 : 어떤 식으로 이를 정량화할 것인가?
4. 적용 

#### 불확실성 정리

##### 1. 데이터
- 수집/추출 
	- 특정 지역에 치우친 데이터가 수집되었는가?
- 측정
	- 주어진 피처, 타깃 범위, 분포는 신뢰할 만한가?
	- 이상치, 결측치 정도
- 입력 과정에서의 오류
	- 정수로 표현되어야 할 변수에 소수점 데이터가 있는가?
	- 입력값에 오류가 있는가?

##### 2. 데이터 처리
- 입력 값 변경, 결측치 처리
	- 실수 -> 정수 변환과정(방 갯수가 2.5인 걸 2로 할까 3으로 할까)
	- 많은 유일값을 줄이기 위해 특정 범위/기준에 따라 범주화
- 피처 엔지니어링 / 선택
	- 피처를 추가로 만들거나, 모델에 필요한 피처 선택

##### 3. 모델링
- 훈련 / 시험 데이터 구분
	- 무작위로 잘 구분되었는가?
	- 훈련과 시험 데이터의 피쳐 / 타깃 분포가 비슷한가?
- 매개변수 불확실성
	- 예측 모델 식이 올바른가?
	- 올바른 알고리즘을 썼는가? 알고리즘이 가정하는 조건이 있다면 이를 데이터가 만족하는가?


#### 불확실성 선택 및 구체화
- 모든 데이터는 측정 상의 오류나 값을 잘못 입력하는 등 어떤 식으로든 불확실성이 있다 : 이를 어떻게 구체화해서 정량화할 수 있을까?
- **시각화로는 이상치를 볼 수는 있지만, 이상치 = 오류라고 단정할 수는 없다.**

- 이를 해결하는 방법 중 하나로는, **다른 피쳐에서 비슷한 데이터들을 묶은 다음 수치를 비교하는 방식**이 있다.
> 집값을 따지려면 집의 평수나 방 갯수 등이 비슷한 상황에서 고려해야 그 값이 특이값인지 오류인지를 알 수 있다는 뜻

- 특이값이 많다면 해당 피쳐의 불확실성이 높다고 할 수 있고, 이런 데이터로 예측 모델을 만든다면 모델 성능이 떨어질 수 있다.
- 분석 결과는 우리가 알고자 하는 모든 불확실성을 나타내지는 않는다. 
- 예시의 전제도 `비슷한 집은 비슷한 집값을 갖는다`라는, 맞는지 틀린지 모를 불확실성이 있기 때문이다.

##### 적용
- 불확실성을 구체화하고 정량화했다면 불확실성의 원인을 찾거나 이를 줄일 수 있는 방법을 찾아 적용하는 게 최종 목표가 될 수 있다.

## 3. 모델 해석 능력(Interpretability)
- 예측 모델 하나를 만드는 데 드는 비용은 상당하다.
- 사용자가 전문 지식 없이 모델을 사용한다면, 잘못 사용하거나 제대로 못 쓸수 있으며 이는 잘못된 의사결정으로 이어질 수 있다.
- 따라서, 데이터 사이언티스트는 **예측 모델을 사용자가 올바르게 이해할 수 있도록 전달해야 한다.** 이를 **해석력(Interpretability)** 이라고 한다.

> 예시 : 집값 예측 모델을 사용자가 쓰고 나온 질문들
> 1. 예측된 집값이 생각보다 높게/낮게 계산된 이유
> 2. 집값에 가장 많은 영향을 주는 요인
> 3. 방 개수 1개가 늘어나면 집값은 어떻게 달라지는가
> 4. 집 연식에 따라 집값은 어떻게 달라지는가
> 5. 입주 물량이 집값에 얼마나 영향을 미치는가
> 6. 역세권, 집 주변 상권이 얼마나 영향을 미치는가
> 7. 금리, 실업률이 집값에 얼마나 영향을 미치는가
> 8. 새로 나온 부동산 정책이 집값에 얼마나 영향을 미치는가

- 최종 사용자가 모델 성능에 만족한다면 어떤 요인이 타깃과 연관 있는지에 더 관심이 많다.
- 질문은 주로 **피쳐(인풋 데이터)** 중심이며, **데싸는 분석과 예측 모델을 통해 사용자가 이해할 수 있도록 설명**해야 한다.

### 1. 질문 분류하기

#### 1. 왜 이런 예측값을 얻었는가?
- 주어진 예측값이 어떤 피처와 연관이 있는지, 어떤 피처가 중요한지에 대한 이해가 필요함

#### 2. 피쳐가 바뀌면 예측값이 어떻게 바뀌는가?
- 특정 피쳐가 타깃과 얼마나 상관이 있는가?

### 2. 피쳐 분류하기
- 입력값이 피쳐는 아니다. 
- 데이터 추가 / 가공 / 피쳐 엔지니어링을 통해 최종 피쳐가 결정된다.
- 예제의 경우
	- 집 특징 : 방 개수, 집 크기, 연식 등
	- 주변 환경 : 상권 / 역까지의 거리에 관한 피쳐, 입주 물량 등 비슷한 지역의 피쳐
	- 외부 환경 : 실업률, 금리, 주담대 이자율 등 전체 집값에 영향을 주는 피쳐
	- 그 외 : **집값에 영향을 미치지만 데이터화하기 힘든 것들(갑자기 발표된 부동산 정책, 뉴스, 심리 등) -> 궁금할 수 있으나, 불확실성에 해당함**.

### 3. 설명 방법 생각하기

#### 1. 왜 이런 예측값을 얻었는가?
- 피쳐의 상태부터 살핀다.
	- 몇 개의 결측치가 있는가, 중요한 피쳐에 결측치가 있는가, 값이 잘못되진 않았는가, 이상치가 있었는가 등등
	- 예측 모델의 알고리즘보다는 **사용된 데이터의 이상, 계산 과정이 올바른지 등 데이터를 분석해 답변**할 수 있음

#### 2. 예측 값이 어떻게 달라지는가?
- 모수적 모델을 썼다면 X -> y에 대한 설명이 되지만, **비모수적 모델이나 앙상블을 썼다면 피쳐-타깃 관계를 설명하기 쉽지 않다.**

- 대신 **부분의존성플롯(Partial Dependence Plot)** 을 그려볼 수 있다.

##### 부분의존성플롯(Partial Dependence Plot)
- 다른 모든 피쳐를 고정하고, 1개의 피쳐를 변경하면 그래프를 그릴 수 있음
- 단, **피쳐가 다른 여러 피쳐와 연관이 있다면 그래프를 제대로 분석할 수 없음**
- **XAI(eXplainable AI)이라는 인공지능 설명 기법의 예시**이다.
	- 또다른 기법으로 `라임(LIME : Local Interpretable Model-agnostic Explanations) 기법`이 있다. 피쳐 값의 작은 변동으로 타깃 값의 큰 변동이 있다면 중요한 피쳐로 판단한다.

- 이외에도 **주요 피쳐 - 타깃 간의 관계만 이해하고 싶은 고객이라면 회귀 모델이나 DT 등 해석 가능한 모델**을 만들어서 설명할 수 있다.
- 중요한 것은, 1가지 방법만으로 예측 모델을 완전히 이해할 수 없고, 피쳐-타깃 간의 상관성이 인과성을 의미하지는 않는다는 것이다.


## 4. 업무 효율성 : 자동화 ML, 파이프라인
> 예제  
> 비즈니스 문제 A, B, C를 해결하기 위한 모델 각각 구축
> 주기적으로 데이터 수집 후 DB에 저장
> 기존 ML 모델 X를 이용해 주기적으로 예측값 제공
> 기존 ML 모델 Y를 이용해 코드 검토 및 보완
> 비즈니스 문제 해결 관련 데이터 분석

- 효율성 : 결과물 / 투입된 시간, 비용
- 투입되는 시간, 비용을 줄이는 방법

#### 1. 프로젝트 투입 시간 줄이기 : AutoML
- 반복되는 업무를 파악하고, 이 부분에 대한 사람의 개입을 최소화함
- 예시) 3개의 프로젝트 각각은 `데이터 수집 -> 분석 -> 가공 -> 피쳐 엔지니어링 -> 피쳐 선택 -> 모델 선택 -> 하이퍼파라미터 튜닝 -> 결과 분석 -> 검토`의 과정을 거친다.
- 이들 중 반복적인 업무를 파악하고 자동화할 수 있을 것.
- 특히 `피쳐 엔지니어링 + 모델 알고리즘 선택 + 하이퍼 파라미터 튜닝` 과정을 자동화할 수 있는데, 이외에도 데이터 취합, 가공, 피쳐엔지니어링, 모델 성능 분석까지도 자동화되고 있다.

- 자동화 플랫폼
- `AWS SageMaker` : 모델 알고리즘 선택, 하이퍼파라미터 튜닝, 데이터 준비 및 피쳐 정리
- `Microsoft Azure AutoML` : 코드 없이 예측 모델 구축 및 해석력 제공
- `Google AutoML`
	- `AutoML Vision` : 자동 이미지 분류
	- `AutoML Natural Language` : 텍스트 구조 의미 파악 

- 자동화 플랫폼 도입 시 고려 사항
	- 회사 전체 프로젝트 중 자동화 플랫폼을 이용할 만한 서비스는 무엇이 있는가
	- 자동화가 필요한 프로젝트 부분?
	- 어떤 이유로 플랫폼이 필요한가
	- 기업 환경에 적합한 건 무엇인가
	- 플랫폼 서비스를 쓰면 비용 대비 효율성이 얼마나 올라가는가
	- 플랫폼 서비스가 제공하는 분석, 알고리즘 종류는 무엇이며 제한점은 무엇인가
	- **플랫폼 서비스를 쓰지 않는 경우 효율성을 높일 대안이 있는가**

- 특히 마지막의 경우, 이미 데이터사이언티스트가 회사에 있다면 자동화 과정을 오픈소스로 직접 개발하거나, ML 과정 중 반복 작업 일부만 자동화 플랫폼을 쓰는 방법이 있다.

- 오픈 소스
	- `AutoML-Zero` : 구글 ML연구진이 스스로 진화하는 ML 알고리즘 공개
	- `Auto-Sklearn2.0` : `scikit-learn`을 기반으로 알고리즘 & HPO 자동화
	- `H20 AutoML` : 오픈소스 ML 플랫폼사, 알고리즘, HPO 자동화
	- `TPOP` : 유전 알고리즘으로 ML 파이프라인 최적화

- 클라우드의 ML 플랫폼을 사용할 경우, 기능과 서비스가 추가될수록 비용이 올라가는 문제가 있다. 

#### 파이프라인
- 스크래핑이나 주기적으로 예측 값을 제공하는 업무 등 같은 작업이 필요하다면 파이프라인을 구축할 수 있다.

- 파이프라인을 **구축했다고 해서 이후에 볼 필요가 없는 건 아니다.**
	- 메모리 이슈
	- 스크래핑 대상 웹 사이트 구조의 변경
	- 데이터 변환에 문제 등

- 따라서, 파이프라인에 **문제가 생겼을 때 데이터 사이언티스트는 이를 빨리 감지할 수 있어야 하며, 디버깅 작업이 수월하도록 문제 원인을 쉽게 파악할 수 있어야 한다.**
	- 예를 들면 문제가 생길 것 같은 구간에 `print()`를 넣는다든가,
	- `try/except`로 파이프라인을 멈추지 않고 다음 단계나 대안 코드를 실행하게 하든가.

- 파이프라인이 멀쩡하더라도 **들어오는 데이터에 차이가 생기는지도 관찰해야 한다.**
	- 기존 모델의 훈련 데이터와 **다른 범위의 데이터가 들어오면, 예측값의 신뢰도가 떨어지므로 새로운 훈련 데이터로 모델을 다시 만들어야 한다.**
	- 그러나 **오류가 발생하고 있지 않은 상황이므로 인식하기 쉽지 않다.**

