
## 1. 왜 포폴인가?
- 서류에서 계속 떨어진다면 
	- 이력서에 있는 뭔가가 잘못되었다
	- 맞지 않는 직무에 지원했다

- 취업은 **실력과 운 모두가 중요하다**
	- 서류와 과제(코테)를 통과해 추려진 사람들을 비교하기 때문에, 이들의 실력에 따라 내 취업도 결정될 수 있다는 것이다. 그리고 운의 영역임.

- 실력을 어떻게 드러낼 수 있을까?
	- 면접 직전까지 갔다는 건 학교 성적, 영어 시험 점수 등에 이상이 없다
	- 따라서 **실력은 면접관 질문에 대한 본인의 답변**으로 판단된다.

### 면접 질문은 크게 2종류

#### 1. 업무 관련 전공 지식 질문
- 지원자가 준비해야 하는 범위가 넓음

#### 2. 이력서를 보고 궁금한 점에 대한 질문
- 이력서를 어떻게 구성하느냐에 따라 **실력**을 드러낼 수 있으며, 이 내용이 **포트폴리오**가 된다.


## 2. 함정에 파뜨릴 포트폴리오
- 최종 합격이 목표라면, "면접관이 이 포트폴리오로 내 실력을 판단할 수 있을까?"라는 생각을 할 필요가 있다.
- 포트폴리오가 오히려 내 실력을 깎아내릴 수 있는 요인이 될 수도 있기 때문에, 주의해야 할 3가지가 있다.

### 1. 누구나 아는 데이터
- 면접관은 지원자가 어떤 데이터로 어떤 프로젝트를 했는지 그 내용 자체에 관심이 없다.
- **어떤 문제를 어떤 방식으로 해결했는가에 관심이 있다.**
- `타이타닉, Iris, MNIST` 모두 마찬가지.

### 2. 복붙 포폴
- 다른 사람의 것을 복사 - 붙여넣기 한 포트폴리오를 제출하는 경우도 종종 있는데, 면접관도 같은 내용을 봤을 거라는 걸 간과한 행동이다.
- 블로그나 TIL을 하더라도, **성실성**의 척도일 뿐 그게 당락을 결정하진 않는다.
	- 예를 들면 블로그나 TIL에 논문 내용을 정리했다면, "정리를 했다"를 어필하는 것보다는 **"정리한 내용으로 프로젝트를 해서 포트폴리오를 만들었다"가 더 어필이 된다**는 것이다.

### 3. 양Quantity을 선택한 포트폴리오
- 개인 블로그, 웹사이트, 깃허브에 여러 주제나 많은 코딩을 올리는 건 괜찮다.
- 그러나 **이력서, 이력서 첨부 파일로 포트폴리오를 낼 경우 많은 양은 좋지 않다.**

1. **면접관은 이력서에 할애할 수 있는 시간이 길지 않으며, 포트폴리오 내용까지 확인하는 것도 쉽지 않다.**
	- 포트폴리오가 길거나 코드가 너무 복잡하고 지저분하다면 읽지 않을 확률이 높다.

2. 너무 많은 내용은 **지원자 본인도 프로젝트 내용을 기억하기 힘들다.**
	- 본인이 제출한 포트폴리오만큼은 어떤 질문에 대해서도 정확한 답변을 해야 한다.

- **포트폴리오는 실력을 잘 드러낼 수 있도록 정리**해야 한다.
	- 웹, 블로그는 양으로 정리해도 상관이 없지만 말이다.

## 3. 포트폴리오 예시

- 프로젝트 구성 요소
	1. 주제 선택, 문제점 제시
	2. 데이터 선택
	3. 해결 과정
	4. 결과
	5. 플랫폼 선택, 문서화
	6. 재검토

### 1. 주제 선택, 문제점 제시
- **지원하고자 하는 회사가 하고 있을 만한 프로젝트 주제**를 찾아보자.
	- 예를 들어 `유통`에 관심이 있다면 캐글 데이터셋에서 `retail`을 검색해볼 수 있다.
	- 프로젝트를 하지 않더라도 **다양한 데이터를 접해보는 것이 중요**하다 : **데이터를 이해하면 산업을 이해할 수 있고, 산업을 이해하면 프로젝트 주제나 문제점을 찾는 데 도움**이 되기 때문이다.

> 예시 : '특정 제품 가격 예측' 회귀 유형으로 주제를 정한다
> - 근데 모수적 모델과 비모수적 모델이 얼마나 다른지를 분석하는 주제를 고를 수도 있다.
> 두 모델의 성능 차이, 모델마다 중요한 피쳐 등을 비교할 수 있다.


- 현재 상황을 반영해 **관심 있는 업계에서 어떤 프로젝트를 진행하면 좋을지 생각**해볼 수도 있다.
	- ex) 코로나 시기에 증가한 온라인 구매 -> 추천 시스템 주제
		- 컨텐츠 기반 필터링
			- 아이템이 가진 피쳐들의 유사성으로 다른 제품 추천
		- 협업 필터링
			- 따봉을 박은 사용자들의 유사성으로 다른 제품 추천
			- 행렬 분해를 이용하는데 데이터가 커지면 계산도 오래 걸린다
		- 이를 개선하는 뉴럴 네트워크 필터링도 있더라~
	- 라는 식으로 여러 추천 시스템을 비교하는 주제로 프로젝트를 진행할 수 있음

- 프로젝트 주제가 **꼭 지도 / 비지도 학습을 이용해 예측 값을 계산하는 것일 필요는 없다.**
- **데이터 분석 / 처리** 또한 훌륭한 주제다.
	- ex) 고객의 구매 데이터
		- 비슷한 특징을 가진 고객이 어떤 제품을 구매했더라
		- 특정 제품을 기준으로 어떤 고객층이 구매했더라
		- 특정 고객과 특정 제품의 유사성 계산
		- 시간 / 시기별로 구매 특징 파악 

- 이외에도 **관심 산업에서 ML, DL과 관련된 최신 논문은 무엇이 있는가**를 보는 것도 좋다.
	- 어떤 주제가 있는가
	- 기존 알고리즘의 문제점과, 보완해야 할 점은 무엇인가

- **주제를 정한 뒤 맞는 데이터를 선택할 수도 있고, 데이터를 정한 뒤 주제를 정할 수도 있다.**

### 2. 데이터
- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)
- [공공데이터포털](https://www.data.go.kr)
- [국가공간정보포털](https://www.nsdi.go.kr)
- [국가통계포털](https://kosis.kr)
- [서울열린데이터광장](https://data.seoul.go.kr/)
- [미국 정부](https://www.data.gov)
- [영국 정부](https://data.gov.uk)

등등

- 공공 데이터는 많다. **관심 있는 분야의 단어 + Open Data**를 함께 입력해서 찾을 수 있다.
- **데이터 사용 시 출처는 꼭 기록**해두자.

### 3. 해결 과정

#### 종류에 따른 과정 수립 
1. 예측 값 계산
- 어느 피쳐를 위주로 어떻게 분석할까
- 피쳐 엔지니어링이 필요한가
- 훈련 데이터와 시험 데이터를 어떻게 나눌까
- 알고리즘은 어떻게 사용할까 
등 **큰 틀을 생각한뒤 항목별로 세부 내용을 기록**한다.

2. 실험 과정
- 가설 검정
- 확률에 기반한 의사결정이 필요하다면 `몬테 카를로 시뮬레이션`
	- 무작위 입력값을 모델에 대입해 결과값을 얻는 과정을 충분히 반복, 입력 값이 불확실하더라도 모델의 분포를 연구할 수 있음
	- 입력 데이터가 분포를 가질 경우, 이 분포로 Y에 대한 값을 확률 분포로 얻을 수 있따.
	- 입력값이 불확실하더라도 확률 값을 계산할 수 있기 때문에 `금융 시나리오 분석`, `사업 리스크 분석`, `품질관리 분석`에서 사용된다.

---
 
- 제안한 과정에 문제점이 없는가
- 실험 설계가 올바른가
- 비교 대상이 정확한가
- 해결 과정을 수식으로 표현할 수 있는가

등을 생각해볼 수 있다. 이게 어렵다면 **비슷한 주제의 논문을 찾아 논문이 사용한 방법을 참고**할 수 있다.

#### 구현 - 가독성
- 프로그래밍 언어를 이용하는데, **가독성이 중요함**
- **필요한 부분을 함수로 만들고 사용**하는 것을 권장하는데, 같은 파일에 두는 게 아니라 **다른 파일(모듈)로 빼놓고 이를 import해서 사용**하자. 
	- 왜냐면 한 코드에 스크립트가 다 박혀있으면 지저분하기 때문임.
- 이외에도, **일관성 있는 코드 작성**이 있다.
	- **`PEP8` 가이드라인**이 있다.
		- ex) 1줄의 최대 문자 길이는 79자로 권장함
			- 많은 문자가 필요하다면 \를 이용해 줄바꿈
			- 이 79자를 표시하는 기능이 주피터 노트북에 있다고 함

### 4. 결과
- 회귀, 분류 문제는 예측 모델을 평가하는 지표를 사용할 수 있다.
- 가설 검정을 했다면 검정 통계량과 임계치를 비교해 결론을 내린다.
- 시뮬레이션을 했다면 함수값 Y의 분포로 시각화한다

#### 회귀 - 분류 문제의 모델 평가 지표

#### 회귀
- 수식은 생략함~
##### 1. MAE(평균 절대 오차)
- 예측 변수의 단위와 같음


##### 2. MSE(평균 제곱 오차)
- 제곱이므로 이상치에 민감함
- 예측 변수의 단위와 다름

##### 3. RMSE
- 예측 변수의 단위와 같음

##### 4. MAPE : MAE를 비율로 계산
- 이상치에 민감하지 않음
- 비율이므로 여러 예측 모델끼리 성능 비교가 가능함
- y=0이면 에러가 발생하므로, 0이 포함되어 있다면 양과 음의 구간으로 나눠야 함

##### 5. RMSLE
- RMSE인데 각 값에 1을 더한 다음 log를 취함 : 실제/예측값이 0이면 로그는 음의 무한으로 가기 때문
- 로그의 특성 상, 예측 -실제 값의 상대적인 오차를 측정할 수 있다.
- **RMSE는 절대오차라면, RMSLE는 상대오차다(로그의 특성)**
- RMSE는 오차가 양수로 바뀌었기 때문에 과대평가인지 과소평가인지 알 수 없는 반면, RMSLE는 실제/예측 비율을 계산하므로 과대/과소평가에 쓰일 수 있다.

#### 분류 : Confusion Matrix
|        | 실제 P | 실제 N |
| ------ | ------ | ------ |
| 예측 P | TP     | FP     |
| 예측 N | FN     | TN       |
- 여기서 **`P`는 다른 그룹에 비해 개수가 적은 경우를, `N`은 많은 경우**를 지칭한다.
- 지표

1. **정확도(Accuracy)** 
- 전체 중 예측 모델이 맞게 분류한 비율
$$
Accuracy = \frac{TP + TN}{TP +FP + FN + TN}
$$

2. **정밀도(Precision)**
- 예측 P중 실제 P인 것의 비율
$$
Precision = \frac{TP}{TP + FP}
$$

3. **재현율(Recall, TPR)**
- 실제 P중 예측 P인 것의 비율
$$
Recall = \frac{TP}{TP + FN}
$$

4. **F1 Score**
- 정밀도와 재현율의 조화평균
$$
F1 \ score = \frac{2 \times Precision\times Recall}{Precision + Recall}
$$


5. **ROC Curve / AUC**
- **FPR(False Positive Ratio)**
$$
FPR = \frac{FP}{FP + TN} 
$$

![[Pasted image 20230511183145.png]]
- 분류에서 **어떤 기준(Threshold) 이상으로 Positive로 분류할 것인지에 따라 오차행렬과 지표값들이 달라진다.** **임계치의 변화에 따라 바뀌는 점들을 모아놓은 것이 ROC Curve.**
- `y=x` 에 가까워진다는 것은 무작위로 분류했다는 의미로 본다.

- **ROC(Receiver Operating Characteristic)**
	- 모든 임계값에서 모델 분류 성능을 측정한 그래프로, 여러 모델을 비교할 때 좌측 상단에 붙을수록 좋은 모델이다.
- X축은 FPR, Y축은 TPR로 둘 모두 예측 모델이 True로 분류했는데 잘못 분류한 것과 맞게 분류한 것을 의미한다.
- **AUC(Area Under the Curve)** : 1에 가까울수록 모델 성능이 좋다

##### 정밀도(Positive 예측 중 True Positive)와 재현률(실제 Positive 중 True Positive) 비교하기
- 상황에 따라 다름

1. 스팸 이메일 분류를 보자. 
	- FN : 스팸 이메일이 아니라고 예측했는데 스팸 이메일인 경우
	- FP : 스팸 이메일이라고 예측했는데 스팸 이메일이 아닌 경우
- 업무 이메일이 스팸 이메일로 분류되는 상황 같은 걸 생각해보면, **FP가 더 치명적**이다. (업무 이메일을 스팸 통에 넣는게 되니까)
- 따라서 **FP를 고려하는 정밀도**를 봐야 한다.

2. 암 분류
	- FN : 암이 아니라고 예측했는데 암인 경우
	- FP : 암이라고 예측했는데 암이 아닌 경우
- **FN이 훨씬 치명적**인 걸 알 수 있다. 치료 타이밍을 놓치게 되는 거니까.
- 따라서 **FN을 고려하는 재현률**을 봐야 한다.

##### 데이터 불균형 문제
- **데이터 불균형이 심한 경우,** `Positive`에 해당하는 관측치를 제대로 학습하지 못하는 문제가 발생한다. 
- 이 경우 `예측 Positive` 자체가 굉장히 드물어지게 되면서, 정밀도나 재현율 값이 1이나 0으로 나오는 문제가 발생한다.
- 따라서 Positive 케이스가 양쪽에 잘 들어갈 수 있도록 **샘플링 테크닉**을 이용하기도 한다.
	- **오버샘플링** : Positive 케이스를 복사해서 늘리는 방법
	- **언더샘플링** : Negative 케이스 중 일부만 써서 줄이는 방법
	- **SMOTE** : Positive 케이스의 k-NN을 이용, 원본 데이터의 피쳐값만 살짝 바꿔서 P 케이스를 만듦

##### F1 Score vs Accuracy

| TP = 1 | FP = 1 |
| ------ | ------ |
| FN = 4 | TN = 994       |
- Accuracy : 0.995
- Precision : 1/2 = 0.5
- Recall : 1 / 4 = 0.25
- F1 score = `2*0.25*0.5 / 0.25 + 0.5` = `0.33`
- 정확도가 0.995지만, 이것만으로 모델 성능을 평가할 수 없다.
- **불균형 데이터의 경우 정밀도와 재현율을 고려해야 하며, 더 작은 값으로 평균을 매기는 F1 Score을 살펴야 한다.**

##### 산술평균, 기하평균, 조화평균
- 산술평균 : 이상치가 있다면 영향 받음

- 기하평균 : n개를 모두 곱한 값의 제곱근
	- 극단적인 수가 있더라도 특정 값에 가중치가 생기지 않음

- 조화평균 : n개 양수의 역수를 산술평균한 것의 역수
	- 즉 1/$n_i$을 다 더한다 -> 평균을 낸다 -> 역수를 취한다
	- 데이터 측정 기간이 다르거나, 수마다 다른 가중치를 부여할 경우 역수의 개념이 필요할 때 사용되며, 역수로 인해 평균은 작은 값에 가까워짐

### 5. 플랫폼 선택, 문서화
- 프로젝트 과정도 중요하지만, 이를 잘 기록하거나 포장하는 것도 중요하다.
- 개인 웹, 블로그를 통해 게재하거나 포폴로 제출할 수 있도록 문서화할 필요도 있다.

- 블로그 : `github.io`, `Velog`, `Medium` 등
- 고려할 사항
	- **프로그래밍 코드**, 수학 수식어 입력 환경
	- 구글 검색 노출 여부
	- 초기 세팅 시간 및 글 작성 편의
	- 커마 가능 여부
	- 광고 수입 발생 가능 여부
	- 블로그 통계 기능
	- 퍼스널 브랜딩 성장 가능성
	- 디자인

- 특히 프로그래밍 코드의 경우 `Gist`나 `Color Scripter` 등 외부 사이트를 이용해 블로그에 코드를 적용할 수도 있다.

- **제출용으로 작성**
	- 이걸 보는 건 면접관이다.
	- 따라서, **<프로젝트 소개 - 주제 / 문제점 - 데이터 - 해결 과정 - 결론> 과정**을 최대한 간결하게 써야 한다.
	- **그래프**를 넣고 싶다면, **그 그래프가 가장 중요한 항목을 명확하게 표현할 수 있는지**를 고려해야 한다.

### 6. 재검토
- 포폴을 만들었다면 재검토하는 시간이 필요하며, 아래 질문에 대답할 수 있도록 한다.

- 왜 이 주제를 선택했는가?
- 뭘 알고 싶어서 프로젝트를 시작했는가?
- 데이터 출처?
- 데이터는 언제, 어떻게 표집되었는가?
- 데이터 크기와 주요 변수?
- 데이터에 대한 특이점이 있었는가?
- 어떤 분석 방법을 썼는가?
- 어떤 예측 알고리즘을 썼는가?
- 예측 값을 얻기까지 걸리는 시간은?
- 예측 모델의 성능은? 얻은 성과가 있었는가?
- 이 프로젝트로 배운 점?
- 데이터 사이언티스트가 아닌 사람에게 어떻게 설명할 수 있을까?
- 어느 부분이 제일 힘들었고, 어떻게 해결했는가?
- 프로젝트에 대한 개선점?
- 완성까지 투자한 시간은?

- 프로젝트는 한번에 완벽하게 마치기 쉽지 않다. 재검토하는 과정에서 보완하면서 완성도를 높이자.