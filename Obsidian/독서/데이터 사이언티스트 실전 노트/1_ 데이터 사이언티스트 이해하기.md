## 1. 데이터 직무 알아보기
- **이용자 로그가 중요**해짐 : 사용자의 행동 정보(`User Behavior`)가 들어있기 때문

#### 데이터 엔지니어 
- 로그를 정보로 바꾸기 위해 `추출 - 변환 - 저장`하는 일이 있다. 이게 데이터 엔지니어의 업무이다.
	- 추출 : 정리되지 않은 로그 파일에서 중요한 정보(데이터) 추출
	- 변환 : 사람이 이해하기 쉽게 바꿈
	- 저장 : 데이터를 한 곳에 모음

- 데이터에 대한 분석과 이해 : 데이터 분석가, 데이터 사이언티스트

#### 데이터 사이언티스트
- 분석을 바탕으로 데이터를 이해한 뒤, **특정 행동이나 사건을 예측**하는 것에 집중
	- 방문자가 첫 페이지의 제품을 살까?에 대한 예측

#### 데이터 분석가
- **비즈니스 의사결정에 유용한 정보를 찾는 것**에 집중함.
	- 웹 사이트에 배치할 제품을 결정할 때, 시간&요일 별 방문자 특징이나 웹 사이트의 제품 배치 대비 판매량 비교 등

### 공통적으로 갖춰야할 능력 : 데이터에 대한 이해와 지식 & SQL
- SQL은 뒤에서 다룸
- 데이터 엔지니어 
	- 데이터 파이프라인 구축 & 자동화
	- 깃
	- 프로그래밍 언어와 플랫폼에 관한 지식과 경험
- 데이터 분석가
	- 파이썬, R
		- 엑셀과 비교 : 출처가 다양한 대용량의 데이터를 다루고, 통계 분석을 적용할 수 있음
	- 전공자 / 비전공자를 떠나 **분석 능력이 비슷하다면, 산업에 대한 이해와 관심이 높은 사람이 선호**됨 : **어떤 분석을 해야할 지에 대한 방향성**을 알기 때문.
		- 따라서 "내 관심 산업 분야"와 "데이터 분석력 향상 방법"을 고민해야 함.
- 데이터 사이언티스트
	- **예측 모델**을 만드는 작업은 생각보다 비중이 크지 않음
	- **데이터를 가공**하는 시간이 오래 걸림. 
	- **데이터에 문제점이 없는지, 더 유용한 데이터가 있는지를 조사**하는 업무도 상당함.


## 2. 왜 데이터 사이언티스트라고 할까
- 데이터 + 사이언티스트로 구분해서 설명함

### 데이터
- 데이터가 속한 **산업에 대한 이해**
- 데이터 자체를 다룰 수 있는 지식

#### 데이터 과학의 정의
> 데이터 마이닝과 같이, 정형 비정형 형태를 포함한 다양한 데이터로부터 지식과 인사이트를 추출하는데 과학적 방법론, 프로세스, 알고리즘 ,시스템을 동원하는 융합분야

#### 회사에서 데이터 사이언티스트에게 바라는 점
- 예제 1) 예측 모델 : 산업 이해, 데이터 분석, 필요한 경우 데이터 추가
- 예제 2) 예측 모델 구성 시 예측 모델에 필요한 데이터만 취합해 다른 DB에 저장.

- 회사는 환경을 개선하는 데서 끝나지 않고, 그 **다음에는 무엇을 할 것인가?를 제안할 수 있는 사람**을 찾는다. 

##### 업무의 흐름
**프로젝트 -> 의사결정 -> 실행 -> 문제 발견 ->** 프로젝트 -> ...
- 프로젝트 = 데이터 분석, 예측 모델 구축, 데이터 문제점 해결 등..
- 의사결정자는 프로젝트 실행 시 회사에 어떻게 도움이 되고 얼만큼의 이익이 발생하며 잠재적인 위험이나 문제점이 해소될 수 있는지를 파악한다.

#### 데이터 사이언티스트가 갖춰야 하는 역량
- **다음 프로젝트를 제안**하는 능력
	- `제안` : 팀, 회사에 도움이 되는 방향, 문제점을 해결해 잠재적인 위험을 감소시키는 것.

- 제안을 위해 필요한 역량 : **통찰력, 기술/개발 능력, 소통 능력**

##### 1. 통찰력
- 데이터를 가공 & 분석 및 예측 모델링을 거쳐 수익화하기 까지, **모든 단계에서의 결정이 수학적, 통계적, 과학적으로 합리적인지를 들여다보는 것**이다.
	- 단순히 모델 A, B를 비교하는 게 아니라 다른 데이터를 이용할 수 있는지, 불필요한 데이터는 없는지, 데이터 크기나 포맷은 적당한지 등이 있다.
- 통찰력을 갖추기 위해서는 **수학, 통계 지식을 바탕으로 의심하고 질문하고 실험을 계속해서 반복**해야 한다.

##### 2. 기술력(1) : 데이터베이스 이해
> 예제 ) 3개의 팀에서 데이터를 따로 가졌다고 하자. 분석에 필요한 데이터를 각 팀에 요청하고 받는 과정에서 발생할 수 있는 문제점은 무엇일까?
- 각 팀에서 이해하는 바가 다르고, 데이터를 취합해 전달하더라도 그 형태나 방식이 다 다를 수 있다. 데이터 사이언티스트는 이들을 받아 재취합하는 시간이 필요하게 된다.
- 만약 **모든 데이터를 한 곳에서 관리하고 작업**한다면, 위의 문제가 해결됨 : 이를 **데이터 레이크(Data Lake)** 라고 한다.
- 미가공 데이터가 클라우드의 데이터 저장 공간에 들어가면 사전에 만들어 둔 데이터 가공을 거쳐 DB에 저장된다. 데이터 사이언티스트는 이렇게 가공된 DB에 접근하는 방식.

##### 3. 기술력(2) : 클라우드 서비스
- 개인 컴퓨터로 데이터 분석을 한다면, 데이터 저장 & 메모리 문제 & 메모리 누수 & 협업 과정에서의 문제 & 보안 문제 등이 발생할 수 있음.
- **로컬 작업은 업무의 비효율성을 초래**한다. 그래서 클라우드 서비스를 많이 이용한다.
- 클라우드 서비스 
	- 쓴 만큼 비용 지불
	- 프로젝트 코드와 데이터가 완전히 격리될 수 있음
	- 개발 환경과 운영 환경, 스테이징 환경(운영 직전에 보안, 성능 검증) 등에서 보안 레벨을 다르게 설정할 수 있다. 

- 데이터 사이언티스트가 클라우드에서 자주 사용하는 서비스는 **가상 서버(컴퓨팅), DB, 스토리지, 분석툴, 서비스/애플리케이션 통합, ML/AI 정도**이다.

##### 4. 기술력(3) : 프로그래밍 능력
- 우선, 프로그래밍 언어는 업무 도구일 뿐이며 이를 어떻게 활용할 지에 대한 생각이 더 중요함.

- **코드의 효율성**을 높이는 게 중요하다

---

> 예제1 ) 데이터 포맷 : 데이터 프레임 파일로 저장 시, csv : pickle : feather 성능
- **직렬화**  :  파이썬의 객체를 일련의 바이트 스트림으로 변환함 (역과정 = 역직렬화)
	- `Pickle, JSON` 등 포맷 변환으로 이뤄짐
	- `Feather` 또한 직렬화  포맷이지만 아파치 애로우 테이블 저장 형식이고, 파이썬과 R 모두에서 사용할 수 있다.

> 책의 예제의 경우, 300만개 row와 5개의 col 저장 / 읽기 시간을 비교해봄

|          | 저장   | 읽기  |
| -------- | ------ | ----- |
| csv      | 23.202 | 2.352 |
| csv.gzip | 57.582 | 3.734 |
| pickle   | **0.159**  | **0.135** |
| feather  | **0.14**   | **0.108**      |
- `csv.gzip`은 csv를 압축한 파일임
- 직렬화된 파일의 저장 & 읽기 속도가 압도적임을 알 수 있으며, 데이터가 크면 더 차이가 많이 날 거임

---
> 예제 2) 최소한으로 코드 수정하기
> 상황 : 모델의 입력으로 들어가는 특성의 이름이 바뀌었다. 그러면 관련된 모든 코드에서 피쳐의 이름을 수작업으로 수정해야 할까?

- 이걸 관리하는 파이썬 코드 파일을 별도로 작성하면 됨
	- 각 코드에서 모델에 들어가는 `feature`를 계속 명시하지 않고, 마스터 파일에서 `dict` 형태를 지정한 후 `pickle` 형태로 저장함
```python
# master_dict.py
import pickle

master_dict = {}
master_dict['feature_cat'] = ['feature1, feature2']
master_dict['feature_num'] = ['feature3']
```
- 이후는 각 코드 파일에서 저장된 `pickle` 파일을 불러오는 형식을 이용하면 된다

---

##### 5. 커뮤니케이션 능력
- 상대방에 따라 다르게 전달해야 함

> ex1) 데이터 사이언티스트와 커뮤니케이션
- 전문적인 **기술**을 바탕으로 **정확하고 간결하게 말하는 것**이 필요함
- 문제를 해결하지 못해 상사에게 보고하는 상황
	- 상황 설명 + 시도한 것 + 여전히 있는 문제점 보고
	- 새로운 데이터 설명 & 분류 모델의 성능평가 지표(RMSE, 오차 행렬, ROC 커브 등) 등을 정리해서 보고할 수 있음

> ex2) 데이터 사이언티스트가 아닌 경우
- 고려해야 할 2가지.
1. 어떤 도움이 필요하고 어떤 일을 해줄 수 있는가
2. 진행 순서를 파악하고 소요 시간을 계산


## 3. 데이터 사이언티스트가 되고 싶다면 이것부터 살펴라
- 석박사를 우대하는 이유 : 문제 해결 능력

#### 문제 해결 능력을 이루는 3가지
1. 문제 관련 지식 및 기술
	- 부족하다면 리서치를 통해 부족한 지식을 채워야 함
	- 데이터 이해, 수학/통계/알고리즘, 업무 기술
2. 경력
	- 경력 = 문제를 마주하고 해결해 온 경험
3. 끈기와 집중

- 제한된 시간과 예산 안에서 새로운 시도가 많기 때문에 스스로 문제에 접근하고 해결할 수 있는 사람을 선호함

- 전공 석박사 학위가 있지만 회사 경력이 없다면, 이들은 경력자로 분류한다. 문제를 직간접적으로 해결해본 경험이 있기 때문임.
	- 논문 : 기존에 없던 새로운 문제를 해결하기 위해 실험하고 증명하는 과정. 
	- 논문을 읽고 이해한다 = 간접적으로 문제 해결을 지켜보는 것과 같다
	- 박사는 자기 실험으로 인정받고 학위를 받는 거니까 더더욱.

- 비전공 석박사는 면접관마다 케바케. 

- 비전공 학사는? : "지원해도 될까?" 가 아니라 **"무엇을 준비해야 할까?"이다.** 

