- 정규분포에는 확률 변수가 여러 개 올 수 있으며, 일변량, 이변량, 다변량 정규분포로 나뉜다.
- 여기선 변수 2개를 먼저 살펴봄

- 두 확률 변수는 정규 분포를 따름
$$
X_1 -> N(\mu_1, \sigma^2_1), X_2 -> N(\mu_2, \sigma^2_2)
$$
> 원래는 ~인데 LaTeX에서 ~가 안들어감;

- 확률 벡터는
$$
X = \left(\begin{matrix} X_1 \\ X_2\end{matrix} \right) 
$$

### 분산-공분산 행렬

- 모집단 **분산-공분산 행렬($\Sigma$)** 은 확률 변수가 2개이므로 2X2 행렬이다. 
	- 주대각성분은 $X_1, X_2$의 분산이다. (모분산) 
	- 이를 제외한 성분들은 두 확률벡터 사이의 **공분산(Covariance)** 으로, 두 변수 $X_1, X_2$가 동시에 변하는 정도를 뜻한다.

$$
\Sigma = \left(\begin{matrix}\sigma_1^2 & \sigma_{12} \\
\sigma_{21} & \sigma_2^2\end{matrix}\right)
$$

### 공분산
- 모집단 **공분산** $\sigma_{12}$ = $cov(X_1, X_2) = \frac{\Sigma(X_{1i} - X_1)(X_{2i} - X_2)}{n}$
- 모집단 **상관계수** $\rho = corr(X_1, X_2) = \frac{cov(X_1, X_2)}{\sqrt{var(X_1)var(X_2)}}$

### 결합확률밀도함수
$$
\begin{matrix}
f(x_1, x_2)= \frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}exp\left[
\frac{1}{2(1-\rho^2)}\left\{
\left(
\frac{x_1 - \mu_1}{\sigma_1}
\right)^2 - 
2\rho 
\left( \frac{x_1 - \mu_1}{\sigma_1}\right)
\left( \frac{x_2 - \mu_2}{\sigma_2}\right) +
\left( \frac{x_2 - \mu_2}{\sigma_2}\right) ^2
\right\}
\right]\\
-\infty < x_1, x_2  < + \infty \\
-\infty <  \mu_1, \mu_2 < + \infty \\
-1 < \rho < 1
\end{matrix}
$$
- 확률 변수가 2개이므로 확률밀도함수를 결합확률밀도함수라고 한다. 
	- 변수 각각이 정규 분포를 띄므로 2개의 정규분포확률밀도를 곱한 다음, 상관계수$\rho$가 반영된 식이다. 

> 예를 들면 정규분포를 띄는 키와 몸무게의 상관계수를 알면 170cm 이상의 키를 갖고 70kg 이상의 몸무게를 가질 확률을 계산할 수 있다.


### 이변량 정규 분포(BVN)
- 위 분포를 기호로 분포 표현하면 아래와 같다
$$

{X_1 \choose X_2} = BVN(\mu_1, \mu_2, \sigma^2_1, \sigma^2_2, \rho)

$$
- BVN : BiVariate Normal Distribution(이변량 정규분포)


#### 예제 
##### 1. 평균 (0, 0), 공분산행렬 `[2, 0] , [0, 2]`
![[Pasted image 20230510235138.png]]
- 두 변수가 관계 없을 경우 상관계수가 0이므로 공분산도 0이 된다.

##### 2. 분산이 다른 경우 : 공분산행렬 `[4, 0], [0, 1]`과 `[1, 0], [0, 4]`
![[Pasted image 20230510235331.png]]
![[Pasted image 20230510235346.png]]

- **분산이 더 큰 방향으로 값이 퍼지는 것을 알 수 있다.** 
- 공분산이 없기 때문에 $X_1, X_2$ 중 한 방향의 축으로 퍼진다.

##### 3. 두 변수의 분산이 같고 공분산이 다를 경우
`[4, 3.5] [3.5, 4]`와 `[4, -3.5] [-3.5, 4]`

![[Pasted image 20230510235709.png]]
![[Pasted image 20230510235717.png]]
- 분산이 같기 떄문에 평균을 기준으로 X, Y 축으로 퍼진 정도는 같으나, **데이터가 퍼지는 방향은 두 축 사이의 어딘가일 것이다**

---
## **실무**에서의 관계 파악
- **상관계수나 산포도**를 통해 관계를 파악한다.
- 관측치가 많다면 모든 관측치로 산포도를 그리지 않고 **표집을 한 다음 산포도**를 그린다.

### 상관계수
- **공분산을 각 변수의 표준편차로 나눈 값**
- `[-1, 1]`의 범위를 갖는다. 0에 가까울수록 상관성이 없다.
![[Pasted image 20230511000657.png]]
- 평균과 표준편차가 0, 2로 동일한 상황에서 **상관계수만 0.95(High), 0.7(Low)로 +, -을 따로 준 산점도**이다.
- **상관계수가 높으면 분포가 좁게 나타나고, 낮으면 넓게** 나타남
- **양의 상관계수는 우상향, 음의 상관계수는 우하향**하는 모양을 나타냄

#### 파이썬에서 상관계수는 `.corr()`함수로 쉽게 구할 수 있다. 산포도를 꼭 그려야 할까?
- 분석에서 제일 중요한 건 필요한 가정 조건을 만족했는지 여부이다.
- 연관성 분석을 할 때 **상관계수에만 의존하면 안되며, 산포도로 가정 조건이 충족되는지도 확인이 필요**하다.

#### 상관 연구의 기본 가정

1. 상관 연구의 기본 가정은 두 변수가 **선형성**을 가져야 한다
	- 증가하다가 감소 : 비선형(2차함수)
	- 이 떄는 구간을 나눠서 구간별로 상관분석을 하는 방법이 있음

2. 상관 연구의 다른 가정으로는 **등분산성**이 있다 
- 등분산성이란, 직선을 따라 분포된 데이터들이 **흩어진 정도가 같아야 한다**는 것이다(값이 커질수록 넓게 퍼지면 안된다는 뜻)
	- 값의 크기에 따라 분산이 달라지는 것을 이분산성(Heteroscedasticity)이라고 한다.
	- **등분산성은 선형회귀모델, ANOVA, 시계열 등에서도 확인**한다.
	- 등분산성을 확인하는 방법에는 산포도 이외에도 Bartlett's test, Levene's test 등이 있다.
	- 이분산성을 **해결하는 방법으로는 로그 변환이나 거듭곱 변환(파워 변환)** 이 있는데, 이상치에 의해 이분산성이 발생할 수 있기 떄문에 변환 전후에 생길 장단점을 잘 비교해야 한다.

3. 두 변수에 **이상치가 없어야 한다.**
- 통계치만으로 이상치를 확인할 수 없기 때문에 산포도를 먼저 그려볼 필요가 있다.

- 상관분석에서 다루는 변수는 **독립변수 간, 독립변수 - 종속변수** 모두를 포함한다.
- 그렇다면 독립변수 끼리의 연관성이 높은 상황은 어떨까?

## 공선성, 다중공선성
- **공선성(Collinearity)** : 하나의 독립 변수가 다른 독립변수와 높은 연관성이 있는 경우
- **다중공선성(MultiCollinearity)** 
	- 한 독립변수가 다른 여러 개의 독립변수로부터 예측할 수 있는 경우
	- 여러 개의 독립변수끼리 상관성을 가진 경우

> 실제로는 2개를 뚜렷한 구분 없이 비슷한 의미로 사용함

--- 
#### 다중공선성 발생상황

> 1. 1개의 정보가 여러 단위로 측정되어 다른 변수로 저장된 경우 : 섭씨와 화씨, 평수와  제곱미터 등 // 열 이름이 명확하지 않거나, 너무 많다면 어떻게 해야 할까?

> 2. 미가공된 데이터를 취합하는 과정에서 상관성이 높은 데이터가 포함된다.
> 예를 들면 집 데이터에서 집 크기, 방 개수, 화장실 개수 등이 있다고 할 때, 집 크기와 방들의 개수는 상관성이 있다. 근데 이러한 상관성이 높은 변수를 모두 쓰고 싶을 수도 있다.

> 3. 피쳐 엔지니어링 사용 시 자주 쓰는 방법 중 하나는 k-NN이다. k를 이용해 생긴 이웃들에 대해 평균, 중앙값 등 여러 통계치로 여러 피쳐를 만들 수 있다. 피쳐 끼리 상관성이 높아지는데, 여러 피쳐를 만들어도 괜찮을까?

---
- 다중공선성은 **VIF(분산팽창계수 : Variation Inflation Factor)와 산점도로 파악**한다.

#### VIF : 분산팽창계수
- 다중 회귀 모델에서 독립변수끼리 상관관계가 있는지 측정하는 정도를 말한다.
$$
\begin{matrix}
VIF = \frac{1}{1-R^2}  \\
R^2 = \frac{\Sigma(\hat{Y_i} - \bar{Y})^2}{\Sigma(Y_i - \bar{Y})^2}
\end{matrix}
$$
- 설명된 편차: $\hat{Y_i} - \bar{Y}$ 
- 총 편차 : $Y_i - \bar{Y}$
- **결정 계수 $R^2$**  `Coefficient of Determination`
- 회귀선을 통해 **종속변수와 설명할 수 있는 부분의 오차**와 **설명되지 않은 편차**로 나눌 수 있다. 이 둘을 합친 게 **총 편차**이다.
- **결정계수는 총 편차 대비 설명된 편차의 비율**을 말하며 상관관계가 높을수록 1에 가까워진다.

- 다중공선성을 가지면 이 변수들로 회귀모델을 만들었을 때 높은 $R^2$값을 얻을 수 있다. 
- 일반적으로 **$VIF$의 값이 5보다 큰 경우 다중공선성이 있다**고 해석한다.

![[Pasted image 20230511003200.png]]
- 각 표본의 평균은 10이며, 표준편차는 `[1, 2, 3, 4]`이다.  `0.85`의 상관계수를 이용해 공분산 값들을 얻었다.
- 상관계수 행렬로, `col5`는 `col1*3 + 10`으로 얻은 뒤 `df.corr()`을 가한 식이다.
	- 즉 1번 열과 5번 열은 상관관계가 높을 수밖에 없음

- 위 식에서 VIF를 구하면 아래와 같이 나타난다. 파이썬의 `statsmodels.stats.outliers_influence.variance_inflation_factor`에 있음.
![[Pasted image 20230511003726.png]]
- `col5`는 `col1`로 얻었으니 VIF값이 높다.
- 이 상태에서 `col1`을 지우면 다중공선성을 해결할 수 있을까?
![[Pasted image 20230511003959.png]]
- 데이터를 높은 상관계수로 만들었기 때문에, VIF 값이 전체적으로 올라간 것을 볼 수 있다.

#### 다중공선성 문제 상황
- 특히 **회귀모델**에서 문제가 되는 이유는, **독립변수끼리 독립이어야 한다는 가정이 망가지기 떄문**이다. 이 상황에서 얻은 회귀 모델은 계수를 신뢰할 수도 없고 모델을 잘못 해석하게 되기도 한다.
- 이 상황에서는 **트리 기반 알고리즘**을 사용하면 상관성이 높은 피쳐를 쓰더라도 예측 성능에 영향을 주지 않기 때문에 상관성이 높은 피쳐를 여러 개 사용하기도 한다.

- 그렇다면 회귀 모델을 쓰지 않을 때는 다중공선성이나 상관관계를 확인해야 할까? 다중공선성을 해결하는 방법은 무엇이 있을까? VIF가 낮아질 떄까지 변수를 지워야 할까?

## 차원의 저주 