1. [[#일반화 : 머신러닝의 목표|일반화 : 머신러닝의 목표]]
	1. [[#일반화 : 머신러닝의 목표#과소적합과 과대적합|과소적합과 과대적합]]
		1. [[#과소적합과 과대적합#(개인적으로 겁나 매우 중요)|(개인적으로 겁나 매우 중요)]]
	2. [[#일반화 : 머신러닝의 목표#딥러닝에서 일반화의 본질|딥러닝에서 일반화의 본질]]
		1. [[#딥러닝에서 일반화의 본질#매니폴드 가설|매니폴드 가설]]
		2. [[#딥러닝에서 일반화의 본질#일반화의 원천 :  보간|일반화의 원천 :  보간]]
		3. [[#딥러닝에서 일반화의 본질#딥러닝 작동 이유|딥러닝 작동 이유]]
		4. [[#딥러닝에서 일반화의 본질#훈련 데이터|훈련 데이터]]
2. [[#모델 평가|모델 평가]]
	1. [[#모델 평가#훈련, 검증, 테스트 세트|훈련, 검증, 테스트 세트]]
		1. [[#훈련, 검증, 테스트 세트#홀드아웃|홀드아웃]]
		2. [[#훈련, 검증, 테스트 세트#k-fold cv|k-fold cv]]
		3. [[#훈련, 검증, 테스트 세트#셔플링 k-fold|셔플링 k-fold]]
	2. [[#모델 평가#상식 수준의 기준점 넘기|상식 수준의 기준점 넘기]]
	3. [[#모델 평가#모델 평가 시 유념할 점|모델 평가 시 유념할 점]]
3. [[#훈련 성능 향상하기|훈련 성능 향상하기]]
	1. [[#훈련 성능 향상하기#핵심 파라미터 튜닝|핵심 파라미터 튜닝]]
	2. [[#훈련 성능 향상하기#구조에 대한 더 나은 가정|구조에 대한 더 나은 가정]]
	3. [[#훈련 성능 향상하기#모델 용량 늘리기|모델 용량 늘리기]]
4. [[#일반화 성능 향상하기|일반화 성능 향상하기]]
	1. [[#일반화 성능 향상하기#데이터셋 큐레이션|데이터셋 큐레이션]]
	2. [[#일반화 성능 향상하기#특성 공학|특성 공학]]
	3. [[#일반화 성능 향상하기#조기 종료|조기 종료]]
	4. [[#일반화 성능 향상하기#규제|규제]]
		1. [[#규제#가중치 규제 추가|가중치 규제 추가]]
		2. [[#규제#드롭아웃 추가|드롭아웃 추가]]


## 일반화 : 머신러닝의 목표

- 과대적합은 모든 머신러닝 문제에서 발생한다.
	- 최적화 : 주어진 데이터에서 최고의 성능을 얻으려 모델을 조정함
	- **일반화 : 이전에 본 적 없는 데이터에서 잘 수행**되는 정도

### 과소적합과 과대적합
- 훈련 초기, 최적화와 일반화는 비슷한 방향으로 이뤄진다.
	- 이 때 훈련을 중단하면 `최소적합`의 가능성이 있음 
	- 최소적합은 모델의 발전 가능성이 있는 상태이다.
- 그러다가 훈련을 특정 횟수 이상 반복하면 일반화 성능이 더 이상 높아지지 않고 낮아지기 시작한다.
	- 이런 상태를 `과대적합`이라고 한다
	- 훈련 데이터에만 맞는 패턴을 학습하기 시작한 상황이다.

> 과대적합이 문제일 수 있는 상황
> 1. 데이터 잡음 : 훈련 데이터에 에러가 있을 가능성이 있는데 이를 학습한다면?  
> 2. 불확실한 특성 : `바나나가 익었는가?`를 판단하는 건 사람마다 다를 수 있다. 그런데 이런 상황에도 과대적합된다면?
>> 비슷한 문제로 무작위성도 포함되어 있다. 측정값이 같아도 다른 결과가 나올 수도 있다. 날씨 등.
>3. 가짜 상관관계 : 평생 2마리의 사교성이 없는 얼룩무늬 고양이를 보고 `모든 얼룩무늬 고양이는 사교성이 없다` 고 말하게 되는 게 과대적합임

> 시각화 힌트 : plot에 범례에 표시되는 명칭 지정할 수 있음(`plt.plot(label = )`)

- [실습 코드 : 여기의 5장](https://github.com/dowrave/TIL/tree/main/NotObsidian/%EC%BC%80%EB%9D%BC%EC%8A%A4%20%EC%B0%BD%EC%8B%9C%EC%9E%90%EC%97%90%EA%B2%8C%20%EB%B0%B0%EC%9A%B0%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D)
![[Pasted image 20230721171152.png]]
- 둘 다 MNIST label을 주되 파란색은 노이즈, 빨간색은 그냥 백색 이미지를 절반씩 섞음. 원본 MNIST 데이터는 1개도 들어가지 않음.

- `np.random.random`이 섞인 데이터는 `np.zeros`보다 성능이 낮은데, 가짜 상관관계의 영향이다.
- 잡음은 필연적으로 과대적합을 유발시킨다. 따라서 사전에 특성을 줄이는 `특성 선택feature selection`을 수행해야 한다.
	- IMDB에서 1만개 단어만 쓰는 방식은 세련되진 않음

#### (개인적으로 겁나 매우 중요)
- **특성 선택의 일반적인 방법은 가용한 특성에 대해 유용성 점수를 계산**하는 것이다.
	- **특성 - 레이블 사이의 상호 의존 정보`mutual information`** 처럼 작업에 특성이 얼마나 유익한지 측정하고, 임계 값을 넘긴 특성만 사용하는 방식이다.

### 딥러닝에서 일반화의 본질
- 이미지 크기만 맞으면 어떤 걸 던져줘도 얘는 그 특성에 맞게 학습한다. 실제로 세상에 유용한지 여부는 둘째치고.
- 딥러닝에서 일반화의 본질은, 모델과는 거의 관련이 없고 실제 세상의 정보 구조와 관련이 있다.

#### 매니폴드 가설
- MNIST 모델의 인풋은 28 * 28 의 정수 배열, 각각은 0~255의 값을 가지므로 가능한 경우의 수는 $784^{256}$이다. 
- 그러나 **실제 손글씨는 그 중 아주 작은 부분 공간만 차지하며 랜덤이 아니라 매우 구조적**이다.

> 1. 손글씨 부분 공간은 연속적이다.  이 중 일부를 조금 수정해도 같은 숫자로 인식할 수 있다.  
> 2. 유효한 부분 공간에 있는 모든 샘플은, 부분 공간을 가로지르는 경로로 연결되어 있다.

> **매니폴드 가설** : **이 세상의 모든 데이터는 고차원 공간 안에 있는 저차원 매니폴드에 놓여 있다
> 고 가정한다.**  경험상 사실이며, 딥러닝이 작동하는 이유이다.
> - 머신러닝 모델은 가능한 입력 공간 안에서 간단하고 저차원이며 매우 구조적인 부분 공간만 학습하면 된다.
> - 매니폴드 중 하나 안에서 두 입력 사이를 `보간interpolation`하는 것이 항상 가능하다. 

#### 일반화의 원천 :  보간
- 예시) 숫자 2와 0의 중간 이미지를 생각해보면, 어떤 숫자도 안될 것이다. (`선형 보간`)
- 그러나 `매니폴드 보간`은 숫자 2에서 0으로 서서히 바꿔나가는 것을 생각하면 된다.
	- 보간이 전부는 아니다. 보간은 이전에 본 것과 매우 가까운 것을 이해하는 데 도움을 줄 뿐이다 `지역 일반화`
	- 그러나 사람은 새로운 것을 마주쳐도, 미리 훈련하지 않고도 잘 처리할 수 있다. 인지 매커니즘의`궁극 일반화`

#### 딥러닝 작동 이유
- 구겨진 공을 종이로 펼치는 예제에서, 
	- 종이는 3D 공간 내의 2D 매니폴드
	- 종이 공을 펼치는 도구가 딥러닝 모델이다. 잠재 매니폴드를 푸는 도구이다.

- 딥러닝 모델은 매우 고차원의 곡선으로, 매끄럽고 연속적이다. 
	- 모델 구조의 가정으로 인한 곡선 형태의 제약은 있다.
- 경사 하강법으로 이 곡선을 데이터 포인트에 맞춘다. 본질적으로 크고 복잡한 곡선`매니폴드`을 선택하여 훈련 데이터 포인트에 맞을 때까지 파라미터를 조정한다.
- 이 곡선은 어떤 것에도 맞출 수 있는 충분한 파라미터가 있다.
- 학습 데이터는 입력 공간 내에서 고도로 구조적인, 저차원의 매니폴드를 형성한다. `매니폴드 가설`

#### 훈련 데이터
- 일반화 능력은 모델의 속성보다는 데이터의 자연적인 구조로 인한 결과이다.
- **데이터가 보간할 수 있는 매니폴드를 형성하는 경우에만 일반화**할 수 있다.
	- 유익한 특성
	- 적은 잡음
	- 일수록 더 잘 일반화할 수 있음.
	- 데이터 큐레이션과 특성 공학은 일반화에 필수적이다.
- 또한 **입력 공간을 조밀하게 샘플링하여 훈련**해야 한다.
	- 결정 경계 근처에서는 특히 그러한데, 이걸 수행하면 상식, 요약 추론, 외부 지식 없이 훈련 입력 사이를 보간하여 새로운 입력을 이해할 수 있다.
- 조밀한 샘플링이 중요하기 때문에, **딥러닝 모델을 향상시키는 가장 좋은 방법은 더 좋고 더 많은 데이터에서 훈련하는 것이다.**
	-  딥러닝 모델에게 훈련 샘플 사이를 보간하는 것 이상을 수행하는 것을 기대할 수 없다.
	- "무엇을 모델에 넣었는가"가 중요해는데, `모델 구조에 인코딩된 가정`과 `데이터`에 따라 모델이 달라진다.

- 추가적인 데이터 수집이 불가능해지면, 모델의 `정보량을 조정`하거나 모델 곡선의 매끄러운 정도에 `제약`을 추가할 수 있다.
	- 적은 패턴만 기억할 수 있다면 최적화 과정은 가장 일반화 가능성이 높은 패턴에만 초점을 맞추기 때문이다.
	- 이러한 과정을 **규제Regularization**라고 한다.

## 모델 평가

### 훈련, 검증, 테스트 세트
- `하이퍼파라미터` : 사용자가 직접 설정해야 하는 수치. 유닛 수, 모델 층 수 등등
	- 검증 세트를 기반으로 성능을 측정하면 검증 세트에 과대적합될 수 있음
- `정보 누설Info leak` : 검증 세트를 기반으로 모델 설정 튜닝 시, 검증이나 테스트 데이터의 정보가 모델로 새는 현상.
	- **어떻게 훈련을 하든, 테스트 데이터가 모델 튜닝(하이퍼파라미터)에 이용돼서는 안된다!**
	- 이를 반복하면 검증 데이터에 맞춰서 과대적합된다.

#### 홀드아웃
- 데이터의 일부만 테스트로 분리, 나머지 데이터로 훈련하고 테스트로 평가한다.
- 단점 : 데이터가 적을 때는 검증 - 테스트의 샘플이 너무 적어서 통계적으로 대표하지 못한다.

#### k-fold cv
- 데이터를 k분할한 뒤, 각 분할 i에 대해 k-1개의 분할로 모델을 훈련하고 i로 모델을 평가하는 방식.
	- 즉 i번째 분할은 `검증`데이터가 된다. **테스트 데이터는 이거 전에 이미 분할되어 있어야 함.**
- 최종 점수는 이렇게 얻은 성능들을 평균낸다.
- 모델의 성능이 분할에 따른 편차가 클 때 이용하며, 튜닝은 별개의 검증 세트를 사용하게 된다.

#### 셔플링 k-fold
- k-fold 이전에 데이터를 1번 섞고 시작한다. 섞는 횟수를 P라고 하면, P *  K 개의 모델을 훈련하고 평가하는 방식.
- 비용이 많이 든다.

### 상식 수준의 기준점 넘기
- 모델 훈련은 평행세계의 로켓 발사 버튼을 누르는 것과 비슷하다. 
	- 볼 수도, 들을 수도, 학습 과정을 관찰할 수도, 시각화해도 해석할수도 없다.
	- 유일한 피드백은 `검증 지표` 뿐이다.
- 따라서, 작업 시작전에 **넘어야 할 기준점을 설정**하는 것이 필요하다.
	- 일반적으로 기준점은 **무작위로 골랐을 때의 값(MNIST라면 0.1, 이진분류면 0.5) 정도**로 잡힌다.

### 모델 평가 시 유념할 점
1. 대표성 있는 데이터
	- ex) 10개의 LABEL이 있는데 훈련에 0~7만 들어가고 테스트에 8~9가 들어가면?
	- `계층별Stratified 분할` : 클래스의 비율을 전체 데이터에 있는 비율과 동일하게 훈련-테스트로 넣는 분할.
2. 시간의 방향
	- 과거 -> 미래 예측 시 데이터 분할할 때 무작위로 섞으면 안된다. 미래의 정보가 과거로 누설되기 때문이다.
	- 이럴 때는 **테스트의 모든 데이터는 훈련의 모든 데이터보다 미래**에 있어야 한다.
3. 데이터 중복
	- 검증 세트에 훈련 세트와 중복된 데이터가 없는지 체크하자. 위에서 `정보 누설`을 다뤘다.

## 훈련 성능 향상하기
- **최적 적합 모델을 찾으려면 일단 과대적합까지 돌려본 다음 일반화 성능을 개선한다.**
- 즉, 과대적합까지 가봐야 하는게 우선이다.

> **발생할 수 있는 문제들**  
> 1. 훈련이 되지 않음
> 2. 훈련은 되지만 의미 있는 일반화가 안 됨 : `기준점`을 넘지 못함
> 3. 훈련은 되지만 과소적합 상태가 유지됨

### 핵심 파라미터 튜닝
- 훈련이 시작되지 않거나 너무 일찍 중단되는 경우
- 경사 하강법 설정 문제가 있을 수 있다
	- 옵티마이저 선택
	- 가중치 초기값 분포
	- 학습률
		- 너무 낮으면 훈련이 멈춘 것처럼 보이고, 너무 높으면 최적 적합으로 못들어감
	- 배치 크기
		- 배치 크기를 늘리면 유익하고 잡음이 적은 그래디언트가 생김
- 이러한 파라미터들은 **하나만 바꾸고 나머지는 고정하는 식으로** 테스트하며 수정할 수 있다.

### 구조에 대한 더 나은 가정
- 검증 지표가 나아지지 않는 경우이며, 랜덤 분류기보다 못한 경우

1. 입력 데이터에 타깃 예측을 위한 정보가 불충분한 경우
2. 모델의 종류가 문제에 적합하지 않은 경우
	- ex) 시계열 예측은 `Fully Dense Connected`로는 부적합하며, `RNN`이 더 적합하다.
	- **해결하려는 작업의 종류에 적절한 구조에 관한 모범 사례를 찾아봐야 한다.** 당신이 처음일 가능성은 높지 않다.

### 모델 용량 늘리기
- `MNIST`에서, 유닛 수가 10개인 `Dense` 층 1개만 있다고 할 때, 검증 손실이 더 이상 감소되지 않거나 정체된 상태에 머무를 수 있다.
- **항상 과대적합이 가능하다**
	- 손실이 더 이상 감소하지 않는다면, 모델의 `표현 능력Representational Power`이 부족한 것이다.
- 그래서 위 예제는 `Dense, Unit = 96`인 층 2개를 앞에 추가했을 때, 검증 손실이 다시 상승하는 과대적합의 결과를 얻을 수 있었다.

## 일반화 성능 향상하기

### 데이터셋 큐레이션
- 데이터 수집에 노력과 비용을 투자하는 것이, 동일한 노력과 비용을 모델 개발에 투자하는 것보다 거의 항상 더 나은 결과를 가져다 준다.

> 1. 데이터가 충분한지 확인한다 : 조밀한 샘플링이 중요하기 때문  
> 2. 레이블 할당 에러를 최소화한다. 입력을 시각화해서 이상치를 보고, 레이블을 교정한다.  
> 3. 데이터를 정제하고 누락값을 처리한다.  
> 4. 특성 선택 : 어떤 것이 유용한지 확실하지 않은 경우 사용한다.   


### 특성 공학
- ex) 시계 이미지를 입력으로 받고 하루 시간을 출력하는 모델을 개발한다고 가정하자.

1. 이미지 자체를 입력으로 쓴다면, CNN과 많은 컴퓨팅 자원을 써야 한다.
2. 이미지 내에 있는 시계 바늘의 좌표를 (`x, y`)로 출력하는 스크립트를 만든 뒤, 간단한 머신러닝 알고리즘을 사용할 수 있다.
3. `2.`에서 좌표를 극좌표로 바꾸게 되면, 머신러닝조차 필요하지 않게 된다.

- **특성 공학의 핵심은, 특성을 더 간단한 방식으로 표현하여 문제를 쉽게 만드는 것**이다.
	- 현재 매니폴드를 더 매끄럽고 간단하고 구조적으로 만든다.
	- 이를 위해서는 **문제를 잘 이해**하고 있어야 한다.

- 딥러닝 이전에는 특성공학이 머신러닝 워크플로우에서 가장 중요했다. 
	- `얕은 방법`의 알고리즘은 가설 공간이 충분히 넓지 않았다. 
	- `MNIST` 같은 경우도 이전까지는 하드코딩된 특성을 사용했다.
		- 숫자 이미지의 동심원 수, 이미지에 있는 숫자의 높이, 픽셀 값의 히스토그램

- **딥러닝은 대부분 특성 공학이 필요하지 않지만, 아예 신경쓰지 않으면 안된다.**
	1. 좋은 특성은 자원을 적게 소비시킬 수 있다.
	2. 좋은 특성은 더 적은 데이터로 문제를 풀 수 있다.

### 조기 종료
- 케라스의 콜백 함수에는 `EarlyStopping`이 있다. 여러 번 써봣으니 알거임
- 각 에포크에서 모델을 저장하고, 검증 지표가 더 이상 향상되지 않을 때 바로 중지하고 해당 에포크로 모델을 되돌릴 수 있다.

### 규제
- `Regularization` : 훈련 데이터에 **완벽**하게 맞추려는 모델의 능력을 **방해**하는 사례이다.
	- 검증 점수의 향상이 목적임.
	- 모델을 더 부드럽고 일반적으로 만드는 성향을 가진다.

- 규제를 적용하는 가장 간단한 방법은 **모델 크기(층, 유닛 수)를 줄이는 것**이다.
	- 예제는 모델을 3개 층으로 구성된 유닛 수 (16, 16, 1)과, (4, 4, 1), (512, 512, 1)을 비교했다.
	1. 기본 모델 vs 작은 모델
		- **작은 모델의 과대적합이 더 나중에 시작되며, 성능의 감소폭도 더 작다.**(=손실의 증가폭)
	2. 기본 모델 vs 큰 모델
		- **큰 모델의 과대적합이 거의 바로 시작되며, 손실 곡선이 고르지 않고 분산이 크다.**
		- 검증 지표가 고르지 않다 = 검증 과정을 신뢰할 수 없는 경우일 수 있다. 검증 세트가 너무 작은 경우를 예로 들 수 있다.
		- 용량이 큰 모델은 **훈련 데이터 모델링 속도가 빠르지만, 과대적합에 훨씬 민감**해진다.

#### 가중치 규제 추가
- **오컴의 면도날**  : 같은 걸 설명하는 2가지 이론이 있을 때, 가정이 적은 게 옳은 이론이다.
- **간단한 모델이 복잡한 모델보다 덜 과대적합될 가능성이 높다.**

- 과대적합을 완화하기 위한 일반적인 방법 : **복잡도에 제한**을 둬서 가중치의 값을 작게 강제하는 것이다. 그러면 **가중치 값의 분포가 더 균일하게 됨.**
	- `L1 규제` : 가중치의 절댓값에 비례하는 비용 추가
	- `L2 규제` : 가중치의 제곱에 비례하는 비용
		- 신경망에서 `가중치 감쇠Weight Decay`라고도 부른다. 같은 뜻임.

- 케라스에서 가중치 규제 추가하기
```python
model = keras.Sequential([
						  layers.Dense(16,
									kernel_regularizaer = regularizers.l2(0.002),
									activation= 'relu'),
						  layers.Dense(16,
									kernel_regularizaer = regularizers.l2(0.002),
									activation= 'relu'),
						layers.Dense(1, activation = 'sigmoid')						
])
```
- `l2` : 가중치 행렬의 모든 원소를 제곱하고, `0.002`를 곱해 모델의 전체 손실에 더해진다.
	- **훈련할 때만 추가된다. 모델의 손실은 테스트보다 훈련에서 높다.**

- 가중치 규제에는 이런 것들이 있음
```python
from tensorflow.keras import regularizers

regularizers.l1(0.001)
regularizers.l1_l2(l1 = 0.001, l2 = 0.001)
regularizers.l2(0.001)
```

- **가중치 규제는 작은 딥러닝 모델에서 쓰인다.**
- 대규모 딥러닝 모델은 그렇게 효과가 크지 않은 경우가 많은데, 이 때는 `드롭아웃`을 쓴다.

#### 드롭아웃 추가
- 훈련 중 무작위로 층의 출력 특성을 0으로 만든다.
- `드롭아웃 비율` : 0이 되는 특성의 비율로, `0.2 ~ 0.5`로 지정된다.
- 테스트 단계에서는 드롭아웃되지 않는 대신 층의 출력을 드롭아웃 비율에 비례하여 줄여준다.
	- 예를 들어 `0.5`라면 
		- 훈련 시에는 유닛 출력 중 50%를 버린다
		- 테스트 시에는 출력의 스케일을 0.5배한다.

```python
# 크기 (batch_size, features)인 층의 출력을 담은 `layer_output`이 있다면

# 훈련 시 유닛 출력 중 50%를 버린다
layer_output *= np.random.randint(0, high = 2, size = layer_output.shape)

# 테스트 시 출력을 낮춘다
layer_output *= 0.5 

# 훈련 단계에 위 연산들을 포함시켜서 테스트 단계에서 출력을 유지시킬 수도 있다.
layer_output *= np.random.randint(0, high = 2, size = layer_output.shape)
layer_output /= 0.5 
```

> 드롭 아웃이 왜 도움이 되는가?  
> 은행의 직원이 자주 바뀌는 이유는 직원 간의 유대를 유지시키지 않게 하기 위함이다.  
> 각 샘플에서 뉴런의 일부를 무작위하게 제거하면 과대 적합을 감소시킬 수 있다.

- 드롭아웃 적용
```python
layers.Dense(16, activation = 'relu'),
layers.Dropout(0.5)
```
- 이런 식으로 층 뒤에 `Dropout` 층을 붙이는 식임.

- 일반화 성능을 높이고, 과대적합을 방지하는 일반적인 방법은
	- 훈련 데이터를 더 모은다. 더 나은 데이터를 모은다.
	- 더 나은 특성을 개발한다.
	- 네트워크의 용량을 감소시킨다.
	- 가중치 규제를 추가한다.
	- 드롭아웃을 추가한다.

