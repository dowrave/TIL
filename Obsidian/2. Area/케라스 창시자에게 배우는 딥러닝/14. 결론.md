
1. [[#핵심 개념 리뷰|핵심 개념 리뷰]]
	1. [[#핵심 개념 리뷰#AI를 위한 여러 방법|AI를 위한 여러 방법]]
	2. [[#핵심 개념 리뷰#딥러닝이 특별한 이유|딥러닝이 특별한 이유]]
	3. [[#핵심 개념 리뷰#딥러닝에 대해|딥러닝에 대해]]
	4. [[#핵심 개념 리뷰#핵심 기술|핵심 기술]]
	5. [[#핵심 개념 리뷰#일반적인 머신러닝 워크플로우|일반적인 머신러닝 워크플로우]]
	6. [[#핵심 개념 리뷰#주요 네트워크 구조|주요 네트워크 구조]]
		1. [[#주요 네트워크 구조#밀집 연결 네트워크|밀집 연결 네트워크]]
			2. [[#밀집 연결 네트워크#이진 분류|이진 분류]]
			3. [[#밀집 연결 네트워크#단일 레이블 다중 분류|단일 레이블 다중 분류]]
			4. [[#밀집 연결 네트워크#다중 레이블 다중 분류|다중 레이블 다중 분류]]
			5. [[#밀집 연결 네트워크#회귀|회귀]]
		2. [[#주요 네트워크 구조#컨브넷|컨브넷]]
		3. [[#주요 네트워크 구조#RNN|RNN]]
			1. [[#RNN#단일 RNN 층|단일 RNN 층]]
			2. [[#RNN#벡터 시퀀스 이진 분류 RNN 모델|벡터 시퀀스 이진 분류 RNN 모델]]
		4. [[#주요 네트워크 구조#트랜스포머|트랜스포머]]
			1. [[#트랜스포머#seq2seq 트랜스포머|seq2seq 트랜스포머]]
			2. [[#트랜스포머#정수 시퀀스 이진 분류 : TransformerEncoder|정수 시퀀스 이진 분류 : TransformerEncoder]]
	7. [[#핵심 개념 리뷰#딥러닝의 가능성|딥러닝의 가능성]]
2. [[#딥러닝의 한계|딥러닝의 한계]]
	1. [[#딥러닝의 한계#ML 모델의 의인화 위험|ML 모델의 의인화 위험]]
	2. [[#딥러닝의 한계#자동 기계 vs 지능 에이전트|자동 기계 vs 지능 에이전트]]
	3. [[#딥러닝의 한계#지역 일반화 vs 궁극 일반화|지역 일반화 vs 궁극 일반화]]
		1. [[#지역 일반화 vs 궁극 일반화#지능의 목적|지능의 목적]]
		2. [[#지역 일반화 vs 궁극 일반화#일반화의 스펙트럼|일반화의 스펙트럼]]
3. [[#AI에서 일반화를 높이는 방법|AI에서 일반화를 높이는 방법]]
	1. [[#AI에서 일반화를 높이는 방법#올바른 목표 설정의 중요성 : 지름길 규칙|올바른 목표 설정의 중요성 : 지름길 규칙]]
	2. [[#AI에서 일반화를 높이는 방법#새로운 목표|새로운 목표]]
4. [[#지능 구현 : 누락된 구성 요소|지능 구현 : 누락된 구성 요소]]
	1. [[#지능 구현 : 누락된 구성 요소#추상적 비유에 뛰어난 지능|추상적 비유에 뛰어난 지능]]
	2. [[#지능 구현 : 누락된 구성 요소#두 종류의 추상화|두 종류의 추상화]]
		1. [[#두 종류의 추상화#가치 중심 비유|가치 중심 비유]]
		2. [[#두 종류의 추상화#프로그램 중심 비유|프로그램 중심 비유]]
		3. [[#두 종류의 추상화#두 추상화를 조합한 인지|두 추상화를 조합한 인지]]
		4. [[#두 종류의 추상화#누락된 절반의 그림|누락된 절반의 그림]]
5. [[#딥러닝의 미래|딥러닝의 미래]]
	1. [[#딥러닝의 미래#프로그램 같은 모델|프로그램 같은 모델]]
	2. [[#딥러닝의 미래#딥러닝과 프로그램 합성 혼합하기|딥러닝과 프로그램 합성 혼합하기]]
		1. [[#딥러닝과 프로그램 합성 혼합하기#딥러닝 + 알고리즘 모듈 통합하기|딥러닝 + 알고리즘 모듈 통합하기]]
		2. [[#딥러닝과 프로그램 합성 혼합하기#프로그램 탐색을 위한 딥러닝 사용|프로그램 탐색을 위한 딥러닝 사용]]
		3. [[#딥러닝과 프로그램 합성 혼합하기#영구 학습과 모듈화된 서브루틴 재사용|영구 학습과 모듈화된 서브루틴 재사용]]
	3. [[#딥러닝의 미래#장기 비전|장기 비전]]
6. [[#빠른 변화에 뒤쳐지지 않기|빠른 변화에 뒤쳐지지 않기]]
	1. [[#빠른 변화에 뒤쳐지지 않기#캐글로 연습하기|캐글로 연습하기]]
	2. [[#빠른 변화에 뒤쳐지지 않기#arXiv를 통해 최신 논문 읽기|arXiv를 통해 최신 논문 읽기]]
	3. [[#빠른 변화에 뒤쳐지지 않기#케라스 생태계 탐험하기|케라스 생태계 탐험하기]]


- 이 책은 AI 기술자를 위한 첫 걸음일 뿐이다.
- 마지막 장의 구성
	1. 거시적인 관점에서 배운 것 조망
	2. 딥러닝의 주요 한계점 : 가능한 것과 불가능한 것
	3. 저자의 개인적인 딥러닝, 머신러닝, AI의 발전에 대한 생각
	4. 머신러닝에 대해 더 공부하고 최신 기술을 습득하기 위해 필요한 자료와 방법

## 핵심 개념 리뷰

### AI를 위한 여러 방법
- `인공 지능` : 인지 과정을 자동화하기 위한 모든 방법. 엑셀의 스프레드시트 ~ 로봇까지 모든 것.
- `머신 러닝` : 훈련 데이터를 사용해 프로그램(`모델`)을 개발하는 AI의 하위 분야.
	- `학습` : 데이터를 프로그램으로 바꾸는 과정.
- `딥러닝` : 머신 러닝의 일종. 기하학적 변환 함수가 번갈아가며 연속적으로 길게 연결된 모델. 연산들이 `층`이라는 모듈을 구성하며, `층`이 쌓아올려진 게 `모델`이다. `층`은 `가중치` 파라미터를 가지며, 가중치에 지식이 저장된다. `학습`의 목적은 `손실 함수`를 최소화하는 가중치 값을 찾는 것이다. `경사 하강법`으로 가중치를 효율적으로 업데이트 할수 있다.

### 딥러닝이 특별한 이유
- 컴퓨터로 풀기 매우 어렵다고 인식된 다양한 문제에서 큰 성과를 거뒀다.
	- `기계 인지Machine Recognition` : 이미지, 비디오, 사운드 등에서 유용한 정보를 추출한다.
		- 충분한 훈련 데이터, 특히 사람이 레이블링한 훈련 데이터가 주어지면 사람이 인식하는 거의 모든 것을 데이터에서 추출할 수 있다.

- 이전의 AI 겨울들과 달리, 이번의 AI 여름은 많은 회사에 `비즈니스적 가치`를 제공하고 있다.
	- 기계 번역
	- 음성 인식
	- 이미지 분류
	- 스마트 비서 

- 저자는 전망을 낙관적으로 보고 있으며, 과잉이더라도 향후 모든 분야에 적용될 수 있다고 생각함.

### 딥러닝에 대해
딥러닝의 놀라운 점은 `단순함`에 있다. `경사 하강법`이 기계 인지에 놀라운 성과를 발휘할 것이라고 생각되진 않았기 때문이다. 이제는 그냥 충분히 큰 모수 모델을, 충분히 많은 샘플에서 훈련하는 게 필요한 전부이다.

- `모수 모델Parametric Model` : 로지스틱 회귀 등, 한정된 모델 파라미터를 가진 모델
- `비모수 모델Non-` : k-NN과 DT 등 모델 파라미터 수가 고정되어 있지 않은 모델.
- 저자는 딥러닝을 모수모델로 보지만, 구조에 따라 파라미터가 엄청 증가하므로 비모수모델로 생각되는 경우도 있다.  

딥러닝의 모든 것은 `벡터`이다. 모든 것이 기하학적 공간의 포인트이다. 따라서 입력과 출력을 벡터 공간으로 바꾼다. 그 다음 모델의 각 층은 데이터에 간단한 기하학적 변환을 수행하여 통과하고, 이게 쌓여서 복잡한 기하학적 변환이 된다. 층의 `가중치`가 변환을 결정하며, 모델이 잘 작동하는가를 기반으로 반복적으로 업데이트된다. 이 때, 변환은 `반드시 미분 가능`해야 한다. 즉, 입력 -> 출력으로 바뀌는 변환이 부드럽고 연속적이어야 한다. 이건 아주 큰 제약 사항이다.  

종이 공을 종이로 펼치는 변환이 있다면, 종이 공은 `입력 데이터의 매니폴드`이고, 사람이 공을 펼치는 움직임이 `간단한 기하학적 변환`, 전체 움직임은 `복잡한 기하학적 변환`이 되며, 딥러닝 모델은 고차원 매니폴드를 펼치는 수학 장치다.  이렇듯 **딥러닝에서 필요한 건 원본 데이터에 있는 모든 형태의 관계를 찾기 위한 충분히 큰 고차원 공간 뿐**이다.

이렇기 때문에 어떤 2가지가 있다면 이 2가지의 거리는 거리 함수로 측정할 수 있다.

### 핵심 기술
딥러닝에 기여한 요인은 다음 것들이 있다.
- **알고리즘** 혁신 : 역전파 이후 20년에 걸쳐 느렸지만, 2012년 이후 계속 빨라지고 있음.
- **대량 데이터** 사용 : 인터넷의 성장, 무어의 법칙이 적용된 저장 매체
- **고성능 병렬 하드웨어를 싸게 이용 가능** : GPU는 게임을 위한 장치지만 딥러닝을 위해 새로 디자인되었다. 
- **하드웨어를 위한 다양한 소프트웨어 스택** : CUDA 라이브러리, 텐서플로우, 케라스 등

### 일반적인 머신러닝 워크플로우
성공적인 머신러닝 앱을 위해서는 문제 영역을 이해하는 것이 중요하다. 전체적인 작업 흐름은 다음과 같다.  

1. 문제 정의
	- 어떤 데이터를 쓸 수 있는가?
	- 예측 대상은 무엇인가?
	- 데이터를 더 모아야 하는가?
	- 레이블링을 위해 사람을 고용해야 하는가?
2. 목표 달성을 위한 측정 방법.
	- `정확도` : 간단한 작업에 이용
	- 대부분 영역에 특화된 지표가 필요하다.
3. 모델 평가 검증 방법
	- 훈련, 검증, 테스트 세트를 준비해야 한다.
	- 검증, 테스트 세트의 레이블은 훈련 데이터에 노출되면 안된다.
	- 시계열의 경우 검증, 테스트 세트는 훈련보다 시간 순서상 뒤에 와야 한다.
4. 데이터를 벡터화하고, 신경망에 맞는 형태로 전처리
5. 상식 수준의 기본 모델보다 나은 모델을 만든다.
	- 머신러닝이 주어진 문제를 해결할 수 있는지 확인한다.
6. 모델 구조를 개선한다.
	- 하이퍼파라미터 튜닝, 규제 추가 등
	- 검증 데이터의 성능으로만 조정한다.
	- 모델의 과대적합 후 규제를 추가하거나 모델 크기를 줄인다.
	- 하이퍼파라미터 튜닝의 경우 검증 데이터에 과대적합된다. 테스트 세트를 따로 떼어놓을 필요가 있다.
7. 모델 배포
	- 웹 API, 자바스크립트, C++ 앱의 일부, 임베디드 등
	- 성능을 모니터링하고, 다음 모델을 개선한다.

### 주요 네트워크 구조
`완전 연결 네트워크`, `합성곱 네트워크`, `순환 네트워크`, `트랜스포머`가 있었다. 각 네트워크 종류는 특정 입력 형식을 의미하며, 네트워크 구조는 데이터의 구조에 대한 가정을 담는다. 이는 좋은 모델을 탐색하기 위한 `가설 공간`이 된다.  
다양한 네트워크 종류는 더 큰 다중 네트워크를 만들기 위해 연결될 수 있다. 아래는 `입력 데이터 - 적절한 네트워크`의 정리.
- 벡터 데이터 : `Dense`
- 이미지 : `Conv2D`
- 시퀀스 :
	- 시계열 - `RNN`
	- 이산적 시퀀스(ex)단어 시퀀스) - `Transformer`
	- `1D 컨브넷`도 이동 불변성의 연속 시퀀스(ex)새소리 파형(waveform))에 쓸 수 있다.
- 비디오 : 
	- `3D 컨브넷` - 연속 동작 감지
	- `2D 컨브넷` - 프레임 단위로 특성 추출에 이용되며, 뒤에 `시퀀스`를 처리하는 모델이 붙는다.
- 볼륨을 가진 데이터 : `Conv3D`

#### 밀집 연결 네트워크
- `완전 연결`이라고도 부른다.
- 벡터 데이터를 처리하는 `Dense` 층이 쌓인 것.
- 입력 특성에 특별한 가정을 두지 않는다. 층은 모든 입력 특성 간의 관계를 매핑하며, 2D 합성곱은 국부적인 관계만 바라본다.
- `입력 = 범주형 데이터`에 많이 쓰이며, 분류나 회귀 출력을 위해 다른 네트워크의 최종 단계에도 쓰인다.
	- 8장의 컨브넷, 10장의 순환 네트워크는 1~2개의 `Dense`로 끝난다.

##### 이진 분류  
- 마지막 `Dense`층의 유닛 1개, 
- `sigmoid` 활성화 함수, 
- `binary_crossentropy`
```python
# 이진 분류
from tensorflow import keras
from tensorflow.keras import layers

# num_input_features = 16
inputs = keras.Input(shape = (num_input_features, ))
x = layers.Dense(32, activation = 'relu')(inputs)
x = layers.Dense(32, activation = 'relu')(x)
outputs =layers.Dense(1, activation = 'sigmoid')(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')
```

##### 단일 레이블 다중 분류
- 1개의 샘플은 1개의 클래스에만 속한다.
- 마지막 `Dense` : 클래스 개수
- 마지막 활성화 함수 : `softmax`
- 손실 함수
	- 원-핫 인코딩 시 `categorical_crossentropy`, 
	- 정수라면 `sparse_categorical_crossentropy`
```python
# 단일 레이블 다중 분류
from tensorflow import keras
from tensorflow.keras import layers

# num_input_features
# num_classes

inputs = keras.Input(shape = (num_input_features, ))
x = layers.Dense(32, activation = 'relu')(inputs)
x = layers.Dense(32, activation = 'relu')(x)
outputs =layers.Dense(num_classes, activation = 'softmax')(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy')
```

##### 다중 레이블 다중 분류
- 1개의 샘플이 여러 클래스에 속할 수 있음.
- 마지막 `Dense`층의 유닛 수 = 클래스 개수, 
- 마지막 층 활성화 함수 : `sigmoid`
- 손실 함수 : `binary_crossentropy`
- `타깃은 멀티-핫 인코딩`되어야 한다.
```python
# 다중 레이블 다중 분류
from tensorflow import keras
from tensorflow.keras import layers

# num_input_features
# num_classes

inputs = keras.Input(shape = (num_input_features, ))
x = layers.Dense(32, activation = 'relu')(inputs)
x = layers.Dense(32, activation = 'relu')(x)
outputs =layers.Dense(num_classes, activation = 'sigmoid')(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')
```

##### 회귀
- 마지막 `Dense`층의 유닛 수 = 예측하려는 `값의 갯수`('가격' 같이 1개인 경우가 많음)
- 활성화 함수 사용 X
- 손실 함수 : `mean_squared_error`가 제일 흔하다.
```python
# 회귀 
from tensorflow import keras
from tensorflow.keras import layers

#num_input_features
#num_values

inputs = keras.Input(shape = (num_input_features, ))
x = layers.Dense(32, activation = 'relu')(inputs)
x = layers.Dense(32, activation = 'relu')(x)
outputs =layers.Dense(num_values)(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer = 'rmsprop', loss = 'mse')
```

#### 컨브넷
입력 텐서의 `패치(=여러 위치)`에 동일한 기하학적 변환을 적용, 공간 방향의 지역 패턴을 찾는다.  `이동 불변성`의 표현을 만들어 합성곱 층을 데이터 효율적으로 만들고 모듈화한다. `1D(시퀀스), 2D(이미지), 3D(볼륨)` 등 어느 차원의 공간에도 적용할 수 있다.   
더 가볍고 효율적인 대안으로 `SeparableConv2D` 같은 `깊이별 분리 합성곱 층`을 사용할 수도 있다.  
컨브넷은 합성곱과 최대 풀링 층이 쌓여 구성된다. `풀링 층`은 공간 방향으로 데이터를 다운샘플링한다. 특성 맵 수가 증가하므로, 적절한 크기로 특성 맵 크기를 유지해서 후속 합성곱 층이 입력에서의 더 큰 부분을 볼 수 있게 한다. 컨브넷은 `Flatten`이나 `전역 풀링 층`으로 끝나는 경우가 많은데, 이들은 공간 특성 맵을 벡터로 변환한다. 그 다음은 분류나 회귀를 위한 `Dense`층으로 이어진다.  
```python
# 합성곱층 : SeparableConv2D / 다중분류

from tensorflow import keras
from tensorflow.keras import layers

# height, width, channels, num_classes

inputs = keras.Input(shape = (height, width, channels))
x = layers.SeparableConv2D(32, 3, activation = 'relu')(inputs)
x = layers.SeparableConv2D(64, 3, activation = 'relu')(x)
x = layers.MaxPooling2D(2)(x)
x = layers.SeparableConv2D(64, 3, activation = 'relu')(x)
x = layers.SeparableConv2D(128, 3, activation = 'relu')(x)
x = layers.MaxPooling2D(2)(x)
x = layers.SeparableConv2D(64, 3, activation = 'relu')(x)
x = layers.SeparableConv2D(128, 3, activation = 'relu')(x)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(32, activation = 'relu')(x)
outputs = layers.Dense(num_classes, activation = 'softmax')(x)

model = keras.Model(inputs, outputs)
model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy')
```
- 모델이 깊어지는 경우 `BatchNormalziation`과 잔차 연결을 추가하는 게 일반적으로, 이 둘은 그래디언트 정보가 네트워크를 더 잘 흐르도록 돕는다.

#### RNN
1번에 1개의 `타임스텝` 씩 시퀀스를 처리하고, `상태State`를 유지한다. 상태는 1개의 벡터이거나 벡터의 집합이다. 시간 축에 따른 이동 불변성이 없다면, 1D컨브넷 대신 사용하는 게 바람직하다.  
`SimpleRNN, GRU, LSTM`이 있는데, 대부분 실전에서는 `LSTM, GRU`를 사용한다. LSTM이 더 강력하고 비용이 더 많이 든다.  
여러 RNN층을 쌓으려면 마지막 층 이전의 모든 층은 전체 시퀀스를 출력해야 한다. 추가적인 RNN 층을 쌓지 않는다면, 전체 시퀀스 정보가 담긴 마지막 RNN층만 반환한다.

##### 단일 RNN 층
```python

from tensorflow import keras
from tensorflow.keras import layers

# num_timesteps, num_features, num_classes

inputs = keras.Input(shape = (num_timesteps, num_features))
x = layers.LSTM(32)(inputs)
outputs = layers.Dense(num_classes, activation = 'sigmoid')(x)

model = keras.Model(inputs, outputs)
model.compile(optimizer='rmsprop', loss = 'binary_crossentropy')
```

##### 벡터 시퀀스 이진 분류 RNN 모델
```python
# RNN 벡터 시퀀스의 이진 분류
from tensorflow import keras
from tensorflow.keras import layers

# num_timesteps, num_features, num_classes

inputs = keras.Input(shape = (num_timesteps, num_features))
x = layers.LSTM(32, return_sequences = True)(inputs)
x = layers.LSTM(32, return_sequences = True)(x)
x = layers.LSTM(32)(x)
outputs = layers.Dense(num_classes, activation = 'sigmoid')(x)

model = keras.Model(inputs, outputs)
model.compile(optimizer='rmsprop', loss = 'binary_crossentropy')
```

#### 트랜스포머
벡터(단어 벡터 등)의 집합을 바라보고 `뉴럴 어텐션`을 활용해 각 벡터를 문맥을 고려한 표현으로 변환한다. 문맥은 집합 내의 다른 벡터로부터 만들어지며, 순서가 있는 시퀀스의 경우 `위치 인코딩`을 활용해 전역적인 문맥과 단어 순서를 모두 고려하는 트랜스포머를 만들 수 있다. RNN, 1D 컨브넷보다 훨씬 효율적으로, 긴 텍스트 문단을 처리할 수 있다.  
텍스트 분류를 포함, 어떤 종류의 집합 처리나 시퀀스 처리 작업에 사용할 수 있지만 특히 `시퀀스 투 시퀀스 학습`에 뛰어나다.  시퀀스 투 시퀀스 트랜스포머는 아래 두 부분으로 구성된다.
- `TransformerEncoder` : 입력 벡터 시퀀스를 문맥과 순서를 고려한 출력 벡터 시퀀스로 변환
- `TransformerDecoder` : `위 인코더`의 출력과 타깃 시퀀스를 받아, 타깃 시퀀스의 다음에 올 것을 예측

벡터 1개의 시퀀스만 처리한다면 `Encoder`만 사용한다. 

##### seq2seq 트랜스포머
- 소스 시퀀스 -> 타깃 시퀀스 / 기계 번역, 질문 응답에 사용 가능
- 구현된 클래스는 11장에 있다.
```python
# seq2seq 트랜스포머 : 소스 시퀀스 -> 타깃 시퀀스 / 기계 번역, 질문 응답에 사용 가능
from tensorflow import keras
from tensorflow.keras import layers

# sequence_length, voca_size, embed_dim, num_heads

encoder_inputs = keras.Input(shape = (sequence_length, ), dtype = 'int64') # 소스 시퀀스
x = PositionalEmbedding(sequence_length, voca_size, embed_dim)(encoder_inputs) # 다른 장에서 정의했음
encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) # 역시 다른 장에서 정의했음

decoder_inputs = keras.Input(shape = (None,  ), dtype = 'int64')
x = PositionalEmbedding(sequence_length, voca_size, embed_dim)(decoder_inputs)
x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)
decoder_outputs = layers.Dense(voca_size, activation = 'softmax')(x) # 한 스텝 앞의 타깃 시퀀스

transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)
transformer.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy')
```

##### 정수 시퀀스 이진 분류 : TransformerEncoder
```python
# 정수 시퀀스 이진 분류에 사용된 TransformerEncoder
from tensorflow import keras
from tensorflow.keras import layers

# sequence_length, voca_size, embed_dim, num_heads

inputs = keras.Input(shape = (sequence_length, ), dtype = 'int64') 
x = PositionalEmbedding(sequence_length, voca_size, embed_dim)(inputs) 
x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x) 
x = layers.GlobalMaxPooling1D()(x)
outputs = layers.Dense(1, activation = 'sigmoid')(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')
```

### 딥러닝의 가능성
- 입출력의 종류에 따른 주목할만한 애플리케이션. 그러나 이러한 각 과제를 모두 수행하는 모델을 훈련시킬 수는 있어도 일반화는 못할 것이다.

- 벡터 -> 벡터 매핑
	- 예측 의학 : 의료 기록 -> 건강 예측
	- 행동 타기팅 : 웹 사이트 속성 -> 사용자 체류 시간
	- 품질 제어 : 제조 상품 데이터 -> 내년 불량률 예측
- 이미지 -> 벡터 매핑
	- 의료 진단 보조 : 의료 영상 슬라이드 -> 암 진단 예측
	- 자율 주행 차 : 카메라 비디오 데이터 -> 휠 각도, 연료 분사, 브레이크 조정
	- 보드 게임 AI : 바둑, 체스 등에서 상대 말의 움직임 예측
	- 식단 도우미 : 음식 사진 -> 칼로리
	- 나이 예측 : 인물 사진 -> 나이
- 시계열 -> 벡터 매핑
	- 날씨 예측 : 지역별 날씨의 시계열 데이터 -> 특정 지역의 다음 주 온도
	- 뇌-컴퓨터 인터페이스 : 뇌자도(MEG) 데이터 -> 컴퓨터 명령 실행
	- 행동 타기팅 : 웹 사이트 사용자 시계열 데이터 -> 제품 구매 확률
- 텍스트 -> 텍스트 매핑
	- 기계 번역
	- 스마트 답장
	- 질문 응답
	- 요약
- 이미지 -> 텍스트 매핑
	- 텍스트 추출 : 텍스트를 포함한 이미지에서 텍스트 추출
	- 캡셔닝 : 이미지의 컨텐츠를 설명하는 캡션
- 텍스트 -> 이미지 매핑
	- 조건부 이미지 생성 : 짧은 텍스트 설명 -> 이미지 생성
	- 로고 생성/선택 : 회사 이름 or 설명 -> 로고 생성
- 이미지 -> 이미지 매핑
	- 초고해상도 변환 : 작은 크기의 이미지 -> 고해상도 버전 변환
	- 공간 깊이 감지 : 실내 이미지 -> 공간 지도
- 이미지 + 텍스트 -> 텍스트 매핑
	- 비주얼 QA : 이미지와 이미지 내용에 관한 자연어 질문 -> 자연어 답변
- 비디오 + 텍스트 -> 텍스트 매핑
	- 비디오 QA : 비디오와 비디오 내용에 관한 자연어 질문 -> 자연어 답변

거의 모든 것이 가능하지만, 전부는 아니다.

## 딥러닝의 한계
사람이 레이블링한 데이터가 아주 많더라도 현재 딥러닝으로 달성하기 어려운 앱이 많다. 예를 들면 소프트웨어 기능 정의서와 이를 이용해 개발한 소스 코드를 수백만 개 모을 수 있지만, 이걸로 제품 설명서 -> 소스코드 생성하는 딥러닝 모델은 훈련할 수 없다.  
**일반적으로 프로그래밍처럼 논증이 필요하거나, 장기 계획을 세워 과학적 방법을 적용하거나, 알고리즘을 사용해서 데이터를 조작하는 일은 주입하는 데이터양에 관계 없이 딥러닝 모델로 달성할 수 없는 영역이다.** 딥러닝으로는 정렬 알고리즘 훈련조차 어렵다.  
딥러닝 모델은 **벡터 공간 -> 벡터 공간 매핑을 위한 단순하고 연속된 기하학적 공간의 연결**이기 때문이다. 대부분의 프로그램은 딥러닝 모델로 표현할 수 없다. 딥러닝 모델이 표현할 수 있는 한계가 있고, 대부분의 학습 대상 프로그램은 데이터 매니폴드에 대한 연속된 기하학적 변환으로 나타낼 수 없는 문제가 있다.

### ML 모델의 의인화 위험
현대 AI의 실제 위험은 딥러닝 모델의 일을 이해하지 못하고, 그 능력을 과대평가하는 데서 온다. 사람의 특징은 `마음 이론Theory Of Mind`을 바탕으로 한다. 둘러싼 것들에 의도, 지식, 믿음을 투영하는 성향을 말한다. 이 때문에 사진을 설명하는 캡션 생성 모델이 성공적으로 훈련되었을 때, 모델이 그림의 내용을 `이해`하고 캡션을 만들었다고 생각한다.  
특히, `적대적 샘플Adversarial Sample`을 딥러닝 네트워크에 주입할 때 이런 문제가 두드러진다. 이전에 필터 시각화나 딥드림 알고리즘에서 경사 상승법을 적용해 활성화를 최대로 한 적이 있다.   
마찬가지로 주어진 클래스의 예측이 최대가 되도록 이미지`긴팔원숭이`를 조금 수정할 수 있는데(그 결과는 거의 노이즈 데이터에 가까움), 이를 원본 이미지`판다`에 더하면 사람이 봤을 때는 똑같이 `판다`이지만 딥러닝 모델은 `긴팔원숭이`로 분류한다. 이는 딥러닝 모델이 불완전하다는 증거이자, 입-출력 매핑과 사람 지각 사이의 큰 차이점을 보여준다.  
즉, **딥러닝 모델은 입력을 전혀 이해하지 못한다.** 모델이 이해하는 것은 최소한 사람이 느끼는 것과는 아예 다르다. 딥러닝이 학습한 매핑은 사람이 경험에서 학습해서 마음속에 내재된 모델을 단순하게 흉내낸 것에 불과하다.  
모델은 훈련 데이터에 맞추기 위해 가능한 짧은 경로를 택한다. 예를 들어 이미지 모델은 입력 이미지를 전체적으로 이해하는 것보다 지역적인 특징에 더 의존하는 경향이 있다. `표범 + 소파` 데이터셋에서 훈련한 모델은 `표범 패턴의 소파`를 `표범`으로 분류할 가능성이 높다.  

### 자동 기계 vs 지능 에이전트
사람의 뇌는 겁내 강력하다. 미분 가능한 모수 모델이랑은 비교할 수 없다.   
`뇌`라는 기관은 5억년 전, `행동 프로그램Behavioral Program`을 저장하고 실행하는 방법으로서 등장했다. 유기체가 환경에 반응하도록 하는 일련의 명령인데, 감각 입력과 운동 제어를 연결한다.  
최초에는 어떤 입력이 들어오면 기관이 적절히 반응하도록 행동 프로그램을 하드코딩하는 역할을 했다. 파리, 개미 등 곤충의 뇌는 여전히 이런 방식으로 동작한다.  
이런 소스 코드가 `신경 연결 패턴`으로 디코딩되는 `DNA`가 되면서 진화의 행동 공간의 제약은 사라졌다. 진화는 프로그래머이고, 뇌는 진화가 만든 코드를 실행하는 컴퓨터였다. 뇌는 결과적으로 어떤 형태, 어떤 형태의 조합 모두 처리할 수 있게 되었다.  
- 초기 뇌는 자동 기계에 가까웠다. 리스트 정렬 프로그램, 심층 신경망 등도 이쪽에 더 가깝다. 

### 지역 일반화 vs 궁극 일반화
```
데카르트 - 방법 서설(1637)
어떤 기계가 사람보다 일을 잘 할 수 있지만, 다른 일에는 반드시 실패할 것이다. 기계는 이해가 아니라 기관의 배치에 따라 움직인다.
```
지능의 특징은 `이해`이며, 어떤 새로운 상황이 발생해도 이에 대처할 수 있는 능력인 `일반화`가 이해를 입증한다. `지능형 에이전트`는 새롭고 예상치 못한 상황에 즉시 적응할 수 있다. 자동 기계는 프로그래밍된 것에 맞지 않는 것에 노출되면 실패한다.  
사람은 현재 상황과 자신, 다른 사람에 대한 복잡하고 추상적인 모델을 구성한다. 이 모델을 사용해 미래 가능성을 예측하고 장기 계획을 세운다.  
우리는 경험하지 못한 어떤 것을 표현하기 위해, 알고 있는 개념을 합친다. 복권 당첨됐을 때의 상상, 친구 열쇠를 가짜 열쇠로 바꿨을 때의 반응 예상 등, 새로움과 가정을 다루는 능력은 `추상Abstraction`과 `추론Reasoning`을 활용해 우리 마음 속의 모델 공간을 직접 경험할 수 있는 것 이상으로 확장한다. 필자는 이를 `궁극 일반화Extreme Generalization`라고 부른다. 데이터가 아예 없어도 새로운 상황에 적응하는 능력인데, 이런 능력이 사람과 고등 동물이 보여주는 지능의 핵심이다. 
자동 기계가 수행하는 것은 
1. 사전에 기술되지 않은 것을 처리할 수 없음(하드코딩)
2. 익숙한 것과 조금 다른 입력을 성공적으로 처리할 수 있음(심층 신경망)
그러나 자동 기계는 `지역 일반화Local Generalization`에 국한된다. 심층 신경망을 일반화할 때, `알려진 미지의 대상`으로만 일반화할 수 있다. 즉, 어느 정도 인풋을 예상할 수 있는 상황에만 쓸 수 있는데, `매니폴드 보간`을 통해 일반화하기 때문이다.  
예제로, 달에 로켓을 발사시키는 설정을 학습한다고 했을 때, 
1. 심층 네트워크는 수천 ~ 수백만의 발사 실험을 해야한다. 입력 공간에서의 조밀한 샘플링도 필요하다. 
2. 사람은 추상화의 힘을 사용하여, 가능한 적은 수의 실험으로 로켓을 달에 착륙시킬 수 있다.  **사람은 가상의 상황에 대한 추상 모델을 만드는 능력이 있다.**

#### 지능의 목적
뇌는 행동 생성에 대한 책임이 있다. 이미 알려진 문제라면 행동 생성이 쉽지만, 복잡도가 증가하면서 동물이 처리해야 하는 상황이 예상 불가능하게 되었다. 매일의 삶이 다름을 생각할 수 있겠음.  
우리 뇌는 이런 필요에 맞추기 위해 적응한 것이다. 적응성과 일반성에 최적화되어 있다. 그래서 유인원, 문어, 까마귀 등 매우 지능적인 동물이 탄생했다.  
데카르트가 `이해`라고 부르는 능력은, 새로운 상황을 처리하고 궁극의 일반화를 달성하기 위해 빠르게 용도를 변경할 수 있는, 재사용 가능한 모듈식 추상을 개발하기 위해 과거 경험을 `마이닝`하는 힘이다. 


#### 일반화의 스펙트럼
- 생물학적 지능의 진화 역사를 생각해보면, `자동 기계 같은 뇌 -> 일반화가 가능한 유기체 -> 궁극 일반화가 가능한 지능 구현, 인류세의 시작 촉발`
- 지난 70년 간 AI의 발전도 이와 비슷하다.
	1. 초기 AI 시스템은 자동 기계였음. 1960년대 ELIZA 프로그램이나 1970녀대 SHRDLU.
	2. 90~00년대 지역일반화가 가능, 머신러닝 시작
	3. 10년대 딥러닝 : 훨씬 큰 데이터셋과 더 강력한 표현 모델, 지역 일반화 능력 크게 확장.

- 그렇다면 `광범위한 일반화Broad Generalization`를 달성할 수 있는 시스템이 나올 수 있을까?
	- 광범위한 영역에서 개발자가 예상할 수 없는 상황이나 대상을 처리할 수 있는 능력이다.
	- `자율 주행 자동차` or `Woz 지능 테스트(어떤 부엌에서도 커피 만드는 테스트)`를 통과할 수 있는 가정용 로봇이다.
	- 딥러닝 + 수동으로 만든 세상에 대한 추상 모델을 결합, 가시적인 진전이 있긴 하다.

- 그러나 당분간 `인지 자동 기계Cognitive Automation`에 국한되어 있을 가능성이 높다.
- 지금의 `인공 지능`은 `인공 인지Artifical Recognition`에 가깝다. 
- 인지 자동화는 매우 유용하다. 모든 산업 분야의 게임 체인저가 될 가능성이 높다.
- 그러나 사람, 또는 동물 지능까지는 거리가 멀다. 지금까지의 모델은 지역 일반화만 수행할 수 있다.

## AI에서 일반화를 높이는 방법
- 사람의 두뇌와 경쟁할 수 있는 AI를 만들려면 `추론Reasoning`과 `추상화Abstraction`로 이동해야 한다.

### 올바른 목표 설정의 중요성 : 지름길 규칙
- `지름길 규칙Shortcut Rule` 
	- 2009년 넷플릭스 영화 추천 작업에서, 최고 추천 점수를 얻은 팀의 시스템을 넷플릭스는 사용하지 않았다. 너무 복잡하고 계산 집약적이기 때문이었는데, `예측 정확도`를 위해 다른 바람직한 특성(추론 비용, 유지보수성, 설명 가능성 등)을 희생했다고 할 수 있다.
	- 이렇듯 **하나의 지표를 최적화하면 목표를 달성할 수 있지만, 이 지표에 포함되지 않는 다른 부분에서의 희생**이 따라오게 되어 있다.
1970년대 인공 지능의 목표로 체스 게임이 제안되었는데, 사람이 체스를 두는 것이 `지각, 추론, 분석, 기억, 공부` 등과 같은 능력을 필요로 하는 것처럼 보였기 때문이다. 20년 후 `딥 블루`가 체스 챔피언을 꺾을 때, 연구자들은 AI를 만들면서 인간 지능을 거의 가르치지 않았다. 또한 이 모델은 체스 작업 이외에는 일반화되지 못했다. 이게 연구자들이 선택한 `지름길`이다.  
결과적으로 사람의 지능을 구현하지 않더라도, 작업을 해결하는 방법은 찾아내왔다.(MNIST, ImageNet, Atari 아케이드, 스타크래프트, 도타 2 등..)  
인간과 같은 지능은 특정 작업에 대한 기술이 아니라, **새로움에 적응하고 새로운 기술을 효율적으로 습득하고 이전에 본 적 없는 작업을 마스터하는 능력**이다. 
AI의 일반화 능력을 더 높이지 않고도 데이터나 하드코딩된 지식을 추가하면 AI를 위한 기술을 더 많이 제공할 수 있다. 훈련 데이터가 무한하다면 knn도 사람을 뛰어넘는 실력으로 게임을 할 수 있고, `if-then-else` 문도 마찬가지다. 그러나 게임의 규칙이 아주 조금 바뀌기만 해도, 비지능 시스템은 처음부터 다시 훈련하거나 재구축되어야 한다.  즉, `지능적 솔루션`이 아니라 `비지능적 솔루션`에 가깝다.  
사람은 `일반 지능 -> 새로운 작업`에서의 기술 습득이 가능하지만, 기계는 `작업에 특화된 기술 집합 -> 일반 지능`으로 가지 못한다.

### 새로운 목표
필자 생각에 지능은 `효율성 비율Efficiency Ratio`로 정량화할 수 있다. 세상에 대한 `관련 정보량Amount Of Relevant Information`과 적절한 행동을 취할 수 있는 `미래 운영 영역Future Operating Area` 사이의 전환 비율이다. 지능적일수록 더 적은 경험으로 광범위한 미래 작업, 상황을 처리할 수 있다.  
2018~2019년 `ARC 벤치마크 데이터셋`이 개발되었다. IQ테스트와 유사하게, 패턴에 대한 예시 3개를 던져주고 입력이 들어올 때 출력을 물어보는 문제임. IQ테스트와 다른 게 2가지인데, `이전에 본 적 없는 과제`만 테스트하고, `사전 지식을 통제`한다. 새로운 문제에 완전히 처음부터 접근하지 않고, 기존 기술과 정보를 사용한다. ARC는 모든 테스트 참여자가 `핵심 사전 지식Core Knowledge Priors`라는 일련의 사전 지식에서 시작해야 한다고 가정하는데, 이는 사람이 태어날 때 가지고 있는 지식 시스템이다. `ARC`는 영어 문장 등과 같은 습득한 지식을 절대 사용하지 않는다.  
`GPT-3`을 포함한 딥러닝 기반의 방법은 ARC 과제를 풀 수 없음이 증명되었다. 보간이 되지 않고, 커브 피팅 방식에는 맞지 않기 때문이다. 반면 사람은 1번째 시도에서 이런 과제를 푸는 데 아무 문제가 없다.  
그렇다면 ARC를 풀기 위해 필요한 게 무엇일까? 이는 실제 지능을 구현하기 위해 필요한 것을 묻는 것일 수도 있다.

## 지능 구현 : 누락된 구성 요소
### 추상적 비유에 뛰어난 지능
- `지능` : 과거 경험과 타고난 사전 지식으로 새롭고 예상치 못한 미래 상황에 대처하는 능력
전례가 있기 때문에 지능이 동작하며, 새로운 뭔가를 마주쳤을 때 과거 경험과 유사한 점을 찾는다. 이는 `비유`로 이어진다. `비유`는 마음에만 있지 않다. 물리적 현실 자체가 `동형성Isomorphism`으로 가득 차 있다. 예를 들면 전자기력과 중력은 유사함. 필자는 이를 `만화경 가설Kaleidoscope Hypothesis`이라고 부른다. 세상은 복잡한 것처럼 보이지만, 그 위에 있는 것들은 비슷하다. 원소의 종류는 매우 적지만, 이들의 재조합으로 끊임없이 변화하는 패턴이 생긴다.  
지능은 경험을 분석하여 재사용할 수 있는 원자를 식별하는 것이다. 이를 추출하면 `추상화Abstraction`라고 한다. 원자를 식별할 수 있는 이유는, 두 가지가 비슷할 때를 알아차릴 수 있기 때문이다. 
- 지능은 추상적인 비유에 민감하다.
	- 비유에 민감하다면 적은 경험에서 강력한 추상화가 도출되고, 이 추상화로 미래의 경험 공간에서 최대한 광범위하게 동작할수 있을 것이다. 

### 두 종류의 추상화
인공지능 구축은 비유를 위한 단계적 알고리즘 구축부터 시작해야 한다. 비유는 사물들을 비교하는 것에서 시작한다. 비교는 2가지 방법이 있다. 
1. `유사성 비교Similarity Comparison` : `가치 중심 비유Value-Centric Analogy` 를 만듦
2. `동일 구조 매칭Exact Structural Match` : `프로그램 중심 비유Program-Centric Analogy`를 만듦
두 경우 모두 한 객체에서 시작, 다른 객체를 합치고 객체 이면의 공통 요소를 잡아내는 추상화를 생성한다. `구분`과 `추상화로 합치는` 방법이 다르다.

#### 가치 중심 비유
유사성은 비유 객체가 거주하는 잠재 매니폴드를 정의하는 부드럽고 연속적인 `거리 함수Distance Function`이다. 딱정벌레끼리는 뭉칠 수 있고, 이 뭉친 그룹끼리 또 합치면 `프로토타입`으로 합칠 수 있다. 이 프로토타입은 이전까지 본 어떤 딱정벌레와도 다르지만, 공통적인 속성이 있기 때문에 새로운 딱정벌레가 나타나면 어떻게 대처할지 알 수 있다.  
새로운 것을 발견하면, 가장 가까운 프로토타입을 찾아 유용한 예측을 만들 수 있을 것이다.  
이는 `K-Means Clustering` 같은 비지도학습 머신러닝의 일과 매우 비슷하다. 모든 머신 러닝은 프로토타입을 통해 인코딩된 샘플 공간을 설명하는 잠재 매니폴드를 학습한다. (CNN의 특성이 시각적 프로토타입이라고 할 수도 있다.)
가치 중심 비유는 딥러닝 모델이 지역 일반화를 수행할 수 있도록 하는 비유 생성 방법이다.
또한, 여기서 사람의 많은 인지 능력이 실행된다. 사람으로서 우리는 `패턴 인식, 지각, 직관` 등의 기초가 되는 추상화와 가치 중심 비유를 수행한다. 영화를 보면서 무의식적으로 캐릭터들을 여러 유형으로 분류한다면 그게 `가치 중심 비유`다.

#### 프로그램 중심 비유
느리고, 정확하고, 신중한 추상화 생성 매커니즘.  
작업에서 많은 부분이 중복된 경우, `함수`나 `클래스`를 작성한다. 이 떄 추상 함수나 추상 클래스가 있는지 물을 수 있는데, 이게 프로그램 중심 비유에 해당한다.  
`거리 함수`로 비교하지 않고, `동일한 구조를 가진 부분이 있는가`에 관심이 있다. 이를 `서브그래프 동형성Subgraph Isomorphis`이라고 부르는데, 이걸 찾는다.
컴퓨터 과학이나 수학 외에도, `추론, 계획, 엄밀함` 개념의 시초가 된다.  

#### 두 추상화를 조합한 인지 
| 가치 중심 추상화                        | 프로그램 중심 추상화                    |
| --------------------------------------- | --------------------------------------- |
| 거리                                    | 구조                                    |
| 연속적, 기하학적 기반                   | 이산적, 토폴로지 기반                   |
| 객체를 프로토타입으로 평균, 추상화 생성 | 객체를 동일한 구조로 분리, 추상화 생성  |
| 지각과 직관의 기초                      | 추론과 계획의 기초                      |
| 즉각적, 모호함, 근사                    | 느림, 엄밀함, 정확함                    |
| 신뢰할 만한 결과를 위해 많은 경험 필요  | 경험 효율적, 2개의 객체에서도 작동 가능 |
|                                         |                                         |

- 우리가 하는, 생각하는 모든 것은 이 두 종류의 추상화를 조합한 것이다. 1개만 쓰는 경우가 더 드묾. 

#### 누락된 절반의 그림
그렇다면 현대 딥러닝에서 누락된 것은 `프로그램 중심 추상화`라고 볼 수 있다. 주의할 점은 저 2개는 반대되는 개념이라기보다는 스펙트럼에 가깝다. 연속적인 매니폴드에 이산적인 프로그램을 임베딩할 수도 있고, 이산적인 프로그램으로 연속적인 거리 함수를 모사할 수도 있다.  
그러나 둘 중 하나에 잘 맞는 문제 유형은 분명하다.   
정렬을 위해 딥러닝을 훈련한다고 하면, 매우 많은 훈련데이터가 필요한 반면 코드로는 몇 줄의 정렬 알고리즘만 작성하면 된다. 이 코드는 몇 개의 샘플에서 검증이 완료되면 어떤 크기의 리스트에서도 적용할 수 있는 강력한 일반화다.  
반대로 지각 문제는 이산 추론 처리와 잘 어울리지 않는다. 순수한 파이썬 프로그램으로 MNIST 숫자를 분류한다면? 숫자의 닫힌 동심원 갯수를 감지하거나, 숫자의 질량 중심 좌표를 계산하는 등의 노력이 들어가며, 수천 줄을 코딩한 다음에야 90% 정확도가 나온다.  
따라서 `추론 -> 매니폴드 보간으로 축소 `or `지각 -> 이산적인 추론으로 축소` 같은 식으로 문제를 해결할 방식이 생길 가능성이 없다. AI의 방향은 두 종류의 추상적인 비유를 통합하는 강력한 단일 프레임워크를 개발하는 것이다.

## 딥러닝의 미래
필자가 기대하는 방향은 아래 내용들이다.
- 모델은 범용 목적의 컴퓨터 프로그램에 가까워질 것이다. `미분 가능한 층`보다 더 뛰어난 모듈로 만들어질 것이다. 이게 `추상`과 `추론`을 보완할 수 있을 것이다.
- 딥러닝과 프로그램 공간에 대한 이산적인 탐색이 융합될 것이다. 전자는 지각, 직관을 제공하고 후자느 추론, 계획을 제공한다.
- 재사용가능하고 모듈화된 프로그램 서브루틴을 이용한 메타러닝처럼 더 훌륭하고 체계적으로 이전에 학습한 특성과 구조를 재사용할 것이다.

위 내용은 지도학습 외에도 비지도 학습, 자기 지도 학습, 강화 학습을 포함해 어떤 형태의 머신 러닝문제에도 적용된다. 레이블링이나 훈련 반복의 방식이 중요하지 않기 때문임.


### 프로그램 같은 모델
목표는 `궁극 일반화`인데, 기본적인 추론을 하는 현재 AI 프로그램은 모두 프로그래머의 `탐색 알고리즘, 그래프 처리, 형식 논리`에 기반한 하드코딩이다. 이런 상황은 곧 바뀔 수 있는데, `프로그램 합성Program Synthesis` 덕분이다. 탐색 알고리즘을 `아마 유전 탐색 방식으로`  사용하여 거대한 프로그래밍 가능 공간을 탐색, 자동으로 간단한 프로그램을 합성한다.  
프로그램이 입력 - 출력 쌍으로 제공되는 필요 사양을 만족시키면 탐색이 중지되는데, 이는 머신 러닝이 하는 일과 비슷하다. 차이는 하드코딩된 프로그램의 파라미터를 학습하지 않고 이산적인 탐색 프로세스를 통해 소스코드를 생성하는 것이다.  
AI 시스템에 프로그램 중심 추상화 능력을 추가하는 길로, `ARC 벤치마크 테스트`에서 희망적인 결과가 나오고 있다.

### 딥러닝과 프로그램 합성 혼합하기
- `프로그램 합성` 단품으로는 안되고, `딥러닝`과 합쳐질 것이다. 둘이 반반을 차지했기 때문.
1. 딥러닝 모듈과 이산 알고리즘 모듈을 통합하는 시스템 개발
2. 딥러닝을 사용, 프로그램 탐색 프로세스 자체를 더 효율적으로 만듦

#### 딥러닝 + 알고리즘 모듈 통합하기
**오늘날 대부분의 강력한 AI 시스템은 하이브리드다. 딥러닝과 수동으로 만든 심볼 조작 프로그램을 모두 활용한다.** 
`알파고`의 대부분의 지능은 프로그래머가 설계하고 하드코딩한 것이다. `몬테 카를로 트리 탐색` + `가치 네트워크Value Network` + `정책 네트워크Policy Network`만 데이터에서 학습한 것이다. 
자율주행차도 주변 세상에 대한 3D 모델이 있어서 매우 다양한 상황을 처리할수 있는데, 엔지니어가 하드코딩한 가정으로 가득 차 있다. 모델은 자동차의 주변 환경과 연결된 딥러닝 지각 모듈로 지속적으로 업데이트 된다.  
위 내용은 어느 한쪽만 가지고는 달성할 수 없는 수준이다. 현재는 사람이 하드코딩해서 넣지만, 미래에는 사람의 개입 없이 완전히 학습될 수 있다.  

예를 들면 현재의 RNN은 시간 축 방향으로 작용하는 `for` 루프는 개발자의 하드 코딩이 들어간 것이다. 그런데 프로그래밍 요소를 갖춘 신경망에서는 하드코딩된 `for` 루프를 쓰는 게 아니라, 프로그래밍 요소를 포함해서 이 모델이 자유롭게 조합해서 함수를 확장하는 것이다. `if, while, 변수 생성, 디스크 스토리지, 정렬 연산, 고급 데이터 구조 등` 이를 선택할 수 있으면 딥러닝이 표현하는 것보다 훨씬 광범위한 일반화 성능을 달성할 수 있을 것이다. 중요한 건 이런 프로그램은 엔드-투-엔드로 미분가능하지 않을 것인데, 따라서 이산 프로그램 탐색과 경사하강법을 조합해야 한다.  

하드코딩된 알고리즘 지능(`수동 소프트웨어`)과 학습된 기하학적 지능(`딥러닝`)을 탈피, `형식적 알고리즘(추론, 추상) + 기하학적 모듈(직관, 패턴 인식)`을 합칠 것이다. 전체 시스템은 사람의 개입이 거의 없이, 혹은 개입하지 않고 훈련될 것이다. 이는 머신 러닝으로 풀수 있는 문제 범위를 극적으로 확장해야 한다.  

#### 프로그램 탐색을 위한 딥러닝 사용
오늘날의 프로그램 탐색은 매우 비효율적이다. 탐색 공간의 가능한 모든 프로그램을 탐색하기 떄문인데, 이는 `조합적 폭발Combinational Explosion`에 직면하게 된다. 대충 너무 많은 곳을 탐색한다는 뜻.  
사람이 편집기를 열어 코드를 작성할 때, 모든 경우의 수를 생각하지 않는다. 이는 문제 이해와 과거 경험을 사용하기 때문이다. 
딥러닝은 프로그램 합성이 위와 같은 작업을 수행하도록 도울 수 있다. 여기서 생성하는 각 특정 작업은 보간이 아닌 데이터 조작을 수행하는 이산 객체일 수 있다. 하지만 지금까지 탐색된 바에 따르면 **유용한 프로그램 공간은 연속된 매니폴드와 매우 비슷할 가능성이 높다.**  
**사람의 추론은 가치 중심 비유 : 패턴 인식과 직관에 크게 의존**한다. 향후 10~20년 사이에 학습된 휴리스틱으로 프로그램 탐색을 돕는 일반적인 접근론에 대한 연구가 증가할 것으로 기대된다.

#### 영구 학습과 모듈화된 서브루틴 재사용
모델이 복잡해지고 풍부한 알고리즘 요소 위에서 구축되면, 작업 간의 재사용성이 증가할 것이다. 새로운 작업이나 데이터셋마다 모델을 만들고 훈련시키지 않아도 된다. 이전에 보았던 데이터셋에서 얻은 정보를 재사용할 필요가 있다. 현재 작업과 이전 작업 사이에 중복되는 점이 많기 때문에, 새로운 작업마다 처음부터 모델을 훈련하는 것이 비효율적이기도 하다. 

최근 몇 년간, **느슨하게 연관된 몇 개의 작업에서 같은 모델을 동시에 훈련하면 각 작업에서 더 뛰어난 모델을 만든다.** `영-독` 번역과 `프-이탈리아` 번역에 동일한 기계 번역 신경망 모델을 훈련하면, 각 언어 번역에서 더 뛰어난 모델을 얻게 된다.

비슷하게, 같은 합성곱 기반을 공유하는 `이미지 분류 모델`과 `이미지 분할 모델`을 함께 훈련하면 양쪽 작업에 더 뛰어난 모델을 만들 수 있다.

겉으로 보기에 관련 없어 보여도, 일정량의 정보가 항상 중복되어 있다. 병합 모델은 더 많은 정보를 제공할 수 있다.

현재는 가중치를 추출하지만, 미래에는 이게 더 일반화되어 모델 구조나 훈련 과정까지도 공유할 것으로 기대된다. 모델이 프로그램과 더 비슷해지면, 프로그램 언어에 있는 함수나 클래스처럼 `모델의 서브루틴`을 재사용하기 시작할 것이다. 

오늘날 소프트웨어 개발 과정은  
1. 엔지니어가 문제 해결 시 이를 추상화된 재사용 가능 라이브러리에 패키징한다
2. 비슷한 문제에 직면하면, 이미 만들어진 라이브러리를 찾아 내려받고 사용한다.

미래에는 이런 식으로 메타 학습 시스템이 전체 공통 라이브러리에서 고수준의 재사용 가능 블록을 바꿔가며 새로운 프로그램을 조합할 수 있을 것이다. 이러한 `서브루틴`은 기하학적(딥러닝 모델)이거나 알고리즘적(라이브러리) 모두가 가능할 것이다.

### 장기 비전
- 모델은 더 프로그램 같아질 듯.
- 알고리즘 모듈 + 기하학적 모듈 혼합할 듯
- 모델은 하드코딩되는 게 아니라 자동으로 만들어질 듯.
- 서브루틴 조합 탐색은 이산적인 탐색 과정일 듯. 근데 딥러닝으로 프로그램 공간에 대한 집중(제약)을 걸 수 있을 듯.
- 공통 서브루틴 라이브러리 + 모델 성장 시스템은 궁극 일반화의 형태를 달성할 수 있을 듯. 즉, 새로운 작업이 주어지면 시스템이 매우 적은 데이터로 작업에 적절한 작동 모델을 조립할 수 있을 듯.
	- 사람은 비디오 게임 플레이 경험이 있다면, 다른 게임도 빠르게 배운다. 경험이 있기 때문.
- 이런 식으로 영구 학습 모델 성장 시스템을 `인공 일반 지능Artifical General Intelligence, AGI`이라고 생각할 수 있다. 
	- 어떤 로봇 재앙이 나타날까? 이 책은 그런 견해를 따르진 않는다. 특이점을 추종하는 사람들이 지능과 기술에 대한 오해가 깊게 쌓여서 생긴 환상일 뿐이다.


## 빠른 변화에 뒤쳐지지 않기
- 현대 딥러닝 분야는 이제 10년 정도 됐다. 2013년부터 투자와 연구 인력이 급증했음.

### 캐글로 연습하기
- 두유노 [캐글?](https://www.kaggle.com)
- 학습 방법은 연습과 실전 코딩이며, 캐글은 지속적으로 데이터 과학 경연 대회가 열린다. 다수가 딥러닝에 관한 것이고, 여러 회사가 어려운 머신 러닝 문제에 대한 새로운 솔루션을 찾기 위해 등록된다. 
- 대부분의 우승자는 XGBoost(얕은 학습) 라이브러리나 케라스(깊은 학습)를 사용한다. 
- 개인이나 팀으로 여러 번 참여해보면 고급 실천 사항들에 익숙해진다 : 하이퍼파라미터 튜닝, 검증 세트 과대적합 피하기, 모델 앙상블 등

### arXiv를 통해 최신 논문 읽기
- 딥러닝 연구 분야는 완전히 오픈되어 있다. 논문이 쓰여지면 바로 공개된다.
- 많은 소프트웨어도 오픈 소스이다.
- [arXiv](https://arxiv.org)는 물리학, 수학, 컴퓨터 과학 분야의 연구 논문을 사전 출판하는 공개 서버이다. 
	- 최신 연구를 얻는 표준적인 방법이다.
	- 대다수의 딥러닝 연구자들이 논문 작성이 끝나자마자 아카이브에 업로드한다. 몇 달이 걸리는 학회 승인을 기다리지 않고 연구한 것을 주장하고 선점할 수 있다.
	- 이는 연구 속도를 더 빠르게 만들며, 즉시 모든 사람이 열람하고 재현할 수 있다.
- 단점으로는 모두 훑어보는 게 불가능하고, 동료 심사가 되지 않아서 중요한 논문을 구별하기 어렵다는 데 있다.
	- [구글 스칼라](https://scholar.google.com)를 사용해 좋아하는 저자별로 논문을 찾을 수 있다.
	- [아카이브 새니티](https://arxiv-sanity-lite.com/)를 통해 관심 있는 주제의 논문을 추천 받을 수 있음
	- [Papers With Code](https://paperswithcode.com)를 통해 논문과 함께 공개된 코드를 볼 수도 있다.

### 케라스 생태계 탐험하기
케라스는 튜토리얼, 가이드 문서, 오픈 소스 프로젝트들로 이뤄진 커다란 생태계가 있다.

- [온라인 문서](https://keras.io)
- [개발자 가이드](https://keras.io/guides)
- [예제](https://keras.io/examples)
- [케라스 소스 코드](https://github.com/keras-team/keras)
- 케라스 메일링 리스트(keras-users@googlegroups.com)에서 토론에 참여하거나 도움을 요청할 수 있다. 케라스 코리아 페이스북 그룹(https://www.facebook.com/groups/KerasKorea/)도 있다.
- 필자 트위터 계정@fchollet도 있다.