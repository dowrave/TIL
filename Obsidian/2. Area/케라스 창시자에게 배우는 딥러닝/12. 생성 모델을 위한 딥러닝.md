



- 예술 창작의 대부분은 패턴인식 + 기교이다. 사람의 지각, 언어, 예술 작품 등은 모두 통계적 구조를 가진다. 딥러닝은 이 구조를 학습하는 데에 뛰어나다.

- 머신러닝 모델은 이미지, 음악, 글의 통계적 `잠재 공간Latent Space`을 학습할 수 있다.

## 텍스트 생성
- RNN으로 시퀀스 데이터를 생성한다.
	- 같은 기법으로 어떤 종류의 시퀀스 데이터도 만들 수 있다.
		- 작곡
		- 연속된 붓질 시퀀스(아이패드에 그리는 과정 기록) 등

### 시퀀스 생성을 위한 딥러닝 모델의 역사
- 1997년 개발된 LSTM은 2014년에는 소수만이 알았고, 2016년에 주류가 되었다.
	- 2002년, LSTM을 음악 생성에 처음 적용한 사례가 있었고, 이걸 만든 사람이 2016년 구글에 `마젠타`란 연구 그룹을 만들었다.
	- 2013년 펜 위치를 기록한 시계열 데이터를 사용해  RNN + Fully Dense Connected 를 이용하여 사람이 쓴 것 같은 손글씨를 생성했다.
	- 2015년 ~ 2017년 사이, RNN은 텍스트, 대화, 음악, 음성 생성 등에 성공적으로 사용되었다.
- 2017년 ~ 2018년, 트랜스포머가 자연어 처리, 시퀀스 생성, 언어 모델링 등에서 RNN을 압도하기 시작했다.
	- `GPT-3`는 1750억개의 파라미터를 가진 텍스트 생성 모델이다.
		- 전체 인터넷을 크롤링한 텍스트 말뭉치에서 훈련했다.

### 시퀀스 데이터를 어떻게 생성할까?
일반적인 방법은 **이전 토큰을 입력으로 사용, 시퀀스의 다음 1개 or 몇 개의 토큰을 트랜스포머나 RNN으로 예측**하는 것이다. 이렇게 이전 토큰으로 다음 토큰의 확률을 모델링하는 네트워크를 `언어 모델Language Model`이라고 한다. 언어 모델은 언어의 통계적 구조인 잠재 공간을 탐색한다.  
언어 모델 훈련 후, 샘플링할 수 있다. 초기 텍스트 문자열`조건 데이터Conditioning Data`를 주입하고, 생성된 출력은 다시 입력 데이터로 추가된다. 이 과정을 반복한다.

> `the cat sat on the -> 언어 모델 -> 확률 분포 -> 샘플링 -> 다음 문자 : mat`
> -> `the cat sat on the mat -> 언어 모델 -> 확률 분포 -> 샘플링 전략 -> 다음 문자 : which`

### 샘플링 전략의 중요성
- 다음 문자를 선택하는 방법이 중요하다.

1. `탐욕적 샘플링Greedy Sampling` 
	- 반복적이고 예상 가능한 문자열을 만들며 논리적인 것처럼 보이지 않는다.
2. `확률적 샘플링Stochastic Sampling`
	- ML에서 `확률적 = 무작위`라는 뜻.
	- 샘플링 과정에 무작위성을 주입한다 : 어떤 단어가 다음 단어가 될 확률이 30%라면, 모델의 30% 정도는 이 단어를 서낵한다.
	- 탐욕적 샘플링을 이걸로 설명할 수도 있다 : 어떤 하나의 확률이 1이고, 나머지는 0인 식.

소프트맥스 출력은 확률적 샘플링에 사용하기 좋다.  샘플링될 것 같지 않은 단어가 선택된다. 가끔 선택될지 않을 것 같은 단어를 골라 선택하는 등, 창의성도 보인다. 단, **무작위성을 조절할 방법이 없다.**    

- 무작위성이 중요한 이유
	- 균등 분포 : 모든 샘플을 선택할 확률이 같음 -> 무작위성 최대, 엔트로피 최대 -> 흥미로운 것을 생산하지 못함
	- 탐욕적 샘플링 : 무작위성 X, 엔트로피 최소 -> 흥미로운 것을 만들지 못함
	- 엔트로피가 작으면 예상 가능한 시퀀스를 만들고 더 실제처럼 보이는 반면, 높은 엔트로피는 창의적인 시퀀스를 만든다.

- `소프트맥스 온도Softmax Temperature`
	-  샘플링에 사용되는 확률 분포의 엔트로피를 나타낸다.

```python
import numpy as np

def reweight_distribution(original_distribution, temperature = 0.5):
	distribution = np.log(original_distribution) / temperature
	distribution = np.exp(distribution)
	return distribution / np.sum(distribution)
```
- 원본 확률 분포는 `temperature = 1.0`이며, 값이 낮아지면 다른 확률은 거의 0에 가까워지는 탐욕적 샘플링이 된다.

### 케라스를 사용한 텍스트 생성 모델 구현
- IMDB 영화 리뷰 데이터셋을 사용, 영화 리뷰를 생성한다.
- 따라서 이 언어 모델은 영어를 모델링하지 않고 영화 리뷰의 스타일과 주제를 모델링한다.

- 데이터 다운로드
```
!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
!tar -xf aclImdb_v1.tar.gz
```
- 2개의 폴더(긍/부)로 나뉘어 있고, 리뷰마다 1개의 텍스트 파일로 구성된다.

- 텍스트 파일(1개의 파일 = 샘플)로 데이터셋 만들기
```python
# 텍스트 파일로 데이터셋 만들기
dataset = keras.utils.text_dataset_from_directory(
        directory = 'aclImdb', label_mode = None, batch_size = 256)
dataset = dataset.map(lambda x : tf.strings.regex_replace(x, "<br />", " ")) # HTML 태그 제거
```

- 어휘 사전 만들기 : `TextVectorization`
	- `sequence_length`개만 사용, 더 긴 리뷰 내용을 자른다.
```python
from tensorflow.keras.layers import TextVectorization

sequence_length = 100
voca_size = 15000 # 가장 자주 등장하는 15000개만 사용, 나머지는 OOV 토큰 [UNK]
text_vectorization = TextVectorization(
    max_tokens = voca_size,
    output_mode = 'int', # 정수 단어 인덱스의 시퀀스
    output_sequence_length = sequence_length, # 길이 100인 입력과 타깃. 타깃은 한 스텝 차이가 나므로 실제로 모델은 99개를 봄
)
text_vectorization.adapt(dataset)
```

- 언어 모델링 데이터셋
```python
# 언어 모델링 데이터셋 : 입력 샘플은 벡터화된 텍스트, 타깃은 한 스텝 앞의 동일 텍스트.
def prepare_lm_dataset(text_batch):
    vectorized_sequences = text_vectorization(text_batch)
    x = vectorized_sequences[:, :-1] # 마지막 단어 제외 입력
    y = vectorized_sequences[:, 1:] # 첫 단어 제외 타깃
    return x, y

lm_dataset = dataset.map(prepare_lm_dataset, num_parallel_calls = 4)
```

#### 트랜스포머 기반의 시퀀스투시퀀스 모델
`몇 개의 초기 단어`가 주어지면 `문장의 다음 단어 확률 분포를 예측`하는 모델 훈련.
- N개 단어의 시퀀스를 받아 N+1번째 단어를 예측한다고 했을 때, 시퀀스 생성 관점에서의 이슈가 있다.
	1. N개의 단어로 예측을 만드는 방법을 학습하지만, N개보다 적은 단어로 예측을 시작할 수 있어야 한다. 그렇지 않으면 비교적 긴 시작 문장을 사용해야 하는 제약이 생긴다.
	2. 훈련의 많은 시퀀스는 중복이다.
	- `A complete sentence must have, at minimum`이라고 하면
		- `A complete sentence must`
		- `complete sentence must have,`
		- `sentence must have, at`
		- `must have, at minimum`
	- 위와 같이 이전에 처리했던 시퀀스를 다시 인코딩하는 중복 작업이 필요해진다.

- 위 두 가지 이슈를 해결하고자 `시퀀스-투-시퀀스` 모델을 사용한다.
	- 즉, 0~N까지를 모델에 주입하고, 1~N+1까지를 예측한다.
	- `코잘 마스킹`을 사용하여 어떤 인덱스 `i`에서 모델은 0~i 까지의 단어로 `i+1`번째 단어를 예측한다.

- **시퀀스 투 시퀀스는 동시에 여러 개의 예측 문제를 최적화한다.**
```
다음 단어 예측
the cat sat on the -> mat

시퀀스-투-시퀀스
the -> cat sat on the mat
the cat -> sat on the mat
the cat sat -> on the mat
the cat sat on -> the mat
the cat sat on the -> mat
```

- 시퀀스 투 시퀀스의 일반 설정
1. 소스 시퀀스 -> 인코더 주입 -> 인코딩 시퀀스
2. 인코딩 시퀀스 + 타깃 시퀀스 -> 디코더 주입 -> 한 스텝 후의 타깃 시퀀스 예측

- 텍스트 생성에서는 소스 시퀀스가 없다. 과거 토큰이 주어지면 타깃 시퀀스의 다음 토큰을 예측하기만 한다. 따라서 `디코더`만 사용해서 수행할 수 있다.
	- 코잘 패딩으로 `N+1`번째 단어를 예측하기 위해 단어 `0~N`만 바라볼 수 있다.
	- `PositonalEmbedding`, `TransformerDecoder`를 재사용한다.

##### 재사용 코드(접었다폈다)
```python
# 재사용용 복붙
from tensorflow.keras import layers

class PositionalEmbedding(layers.Layer):

  # 위치 임베딩 : 시퀀스 길이를 미리 알아야 한다는 게 단점임
  def __init__(self, sequence_length, input_dim, output_dim, **kwargs):
    super().__init__(**kwargs)
    self.token_embeddings = layers.Embedding(
        input_dim = input_dim, output_dim = output_dim
    )
    self.position_embeddings = layers.Embedding(
        input_dim = sequence_length, output_dim = output_dim
    )
    self.sequence_length = sequence_length
    self.input_dim = input_dim
    self.output_dim = output_dim

  def call(self, inputs):
    length = tf.shape(inputs)[-1]
    positions = tf.range(start = 0, limit = length, delta = 1)
    embedded_tokens = self.token_embeddings(inputs)
    embedded_positions = self.position_embeddings(positions)
    return embedded_tokens + embedded_positions

  # 입력 0 패딩을 무시하는 마스킹 생성.
  # 프레임워크에 의해 자동으로 호출되며, 마스킹은 다음 층으로 전달된다.
  def compute_mask(self, inputs, mask = None):
    return tf.math.not_equal(inputs, 0)

  def get_config(self):
    config = super().get_config()
    config.update({
        "output_dim" : self.output_dim,
        "sequence_length" : self.sequence_length,
        "input_dim" : self.input_dim
    })
    return config

class TransformerDecoder(layers.Layer):
	def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):
		super().__init__(**kwargs)
		self.embed_dim = embed_dim
		self.dense_dim = dense_dim
		self.num_heads = num_heads
		self.attention_1 = layers.MultiHeadAttention(num_heads = num_heads,
		key_dim = embed_dim)
		self.attention_2 = layers.MultiHeadAttention(num_heads = num_heads,
		key_dim = embed_dim)
		self.attention_3 = layers.MultiHeadAttention(num_heads = num_heads,
		key_dim = embed_dim)
		self.dense_proj = keras.Sequential([layers.Dense(dense_dim, activation = 'relu'),
		layers.Dense(embed_dim),])
		self.layernorm_1 = layers.LayerNormalization()
		self.layernorm_2 = layers.LayerNormalization()
		self.layernorm_3 = layers.LayerNormalization()
		self.supports_masking = True # 입력 마스킹을 출력으로 전달하게 함
		# layer.compute_mask()는 위 속성이 False이면 에러를 반환한다.
	def get_config(self):
		config = super().get_config()
		config.update({
		'embed_dim' : self.embed_dim,
		'num_heads' : self.num_heads,
		'dense_dim' : self.dense_dim
		  })
		return config

	# 코잘 마스킹 : 미래 타임스텝의 데이터를 사용하지 못하게 한다
	def get_casual_attention_mask(self, inputs):
		input_shape= tf.shape(inputs)
		batch_size, sequence_length = input_shape[0], input_shape[1]
		i = tf.range(sequence_length)[:, tf.newaxis]
		j = tf.range(sequence_length)
		mask = tf.cast(i >= j, dtype = 'int32') #
		mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))

		mult = tf.concat([tf.expand_dims(batch_size, -1),
						  tf.constant([1, 1], dtype = tf.int32)], axis = 0)
		return tf.tile(mask, mult)

	def call(self, inputs, encoder_outputs, mask = None):
		casual_mask = self.get_casual_attention_mask(inputs)

		if mask is not None:
			padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype = 'int32')
			padding_mask = tf.minimum(padding_mask, casual_mask)

		attention_output_1 = self.attention_1(
			query = inputs,
			value = inputs,
			key = inputs,
			attention_mask = casual_mask
		)
		attention_output_1 = self.layernorm_1(inputs + attention_output_1)

		attention_output_2 = self.attention_2(
			query = attention_output_1,
			value = encoder_outputs,
			key = encoder_outputs,
			attention_mask = padding_mask, # 합친 마스킹을 소스 + 타깃 시퀀스를 연결시키는 2번째 어텐션 층에 전달
		)
		attention_output_2 = self.layernorm_2(
			attention_output_1 + attention_output_2
		)

		proj_output = self.dense_proj(attention_output_2)
		return self.layernorm_3(attention_output_2 + proj_output)
```



##### 계속
- 간단한 트랜스포머 기반 언어 모델
```python
from tensorflow.keras import layers
embed_dim = 256
latent_dim = 2048
num_heads = 2

inputs = keras.Input(shape = (None, ), dtype = 'int64')
x = PositionalEmbedding(sequence_length, voca_size, embed_dim)(inputs)
x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, x)
outputs = layers.Dense(voca_size, activation = 'softmax')(x) # 타임스텝마다 어휘 사전의 단어에 대해 소프트 맥스 확률을 계산
model = keras.Model(inputs, outputs)
model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'rmsprop')
```

#### 가변온도 샘플링을 사용한 텍스트 생성 콜백
- 에포크가 끝날 때마다 다양한 온도로 텍스트를 생성한다.
- `This Movie`라는 단어만 주고 텍스트 생성을 본다.
```python
import numpy as np

# 인덱스 -> 문자열 매핑. 디코딩에 사용된다.
tokens_index = dict(enumerate(text_vectorization.get_vocabulary()))

# 확률 분포에 대한 가변온도 샘플링
def sample_next(predictions, temperature = 1.0):
	predictions = np.asarray(predictions).astype('float64')
	predictions = np.log(predictions) / temperature
	exp_preds =  np.exp(predictions)
	predictions = exp_preds / np.sum(exp_preds)
	probas = np.random.multinomial(1, predictions, 1)
	return np.argmax(probas)

class TextGenerator(keras.callbacks.Callback):
	def __init__(self,
				prompt, # 시작 문장
				generate_length,
				model_input_length,
				temperatures = (1., ),
				print_freq = 1):
		self.prompt = prompt
		self.generate_length = generate_length
		self.model_input_length = model_input_length
		self.temperatures = temperatures
		self.print_freq = print_freq
	
	def on_epoch_end(self, epoch, logs = None):
		if (epoch + 1) % self.print_freq != 0:
			return
		for temperature in self.temperatures:
			print("== generating with temperature", temperature)
			sentence = self.prompt # 시작 단어에서 프롬프트 생성
			for i in range(self.generate_length):
				tokenized_sentence = text_vectorization([sentence])
				predictions = self.model(tokenized_sentence)
				next_token = sample_next(predictions[0, i, :])
				sampled_token = tokens_index[next_token]
				sentence += " " + sampled_token
			print(sentence)

prompt = "This Movie"
text_gen_callback = TextGenerator(prompt, 
								  generate_length = 50,
								  model_input_length = sequence_length,
								  temperatures = (0.2, 0.5, 0.7, 1., 1.5)
								  )

```

- `fit()` 메서드 호출
```python
model.fit(lm_dataset, epochs = 200, callbacks = [text_gen_callback])
```

- 생성 결과
```
# loss = 4.95 정도에서 실행
== generating with temperature 0.2
This Movie movie is clichés so a bad good when bad no faces it and does bad the but original honestly just i the have realistic you graphics realize were that still a oh bad so thing bad pretty its good got one in in a this joke the unless actors the

== generating with temperature 0.5
This Movie movie is would boring watch the this second one of like the a actors [UNK] and starts the the movie comedy to he be was it often laughable painful im end a its [UNK] straight and out better for now a the well most [UNK] adults people being to good

== generating with temperature 0.7
This Movie taped is me a afraid long to time such a trash magazine this with is the not start the it top but 10 i next know time with i his got work that if leather nothing jacket about is and a so girl cheap that and boring the try kids

== generating with temperature 1.0
This Movie is is absolutely not horrible the but lead the is series just it a is pretty not good worth in watching this i movie am any a of bad the but entire i [UNK] really and bad is the very usual very [UNK] bad good and shadow don pokes lee

== generating with temperature 1.5
This Movie is made just movie about there a is real nothing mess but good i and cant is stand freak music a in movie comedy that style least in the it only shows looks movie to ive begin ever a change few after times about many this years thing old that
```

- 샘플링을 다양하게 실험해봐야 한다! 아래의 경향을 띄지만, 어떤 지점이 가장 괜찮은가는 문제마다 다를 수 있기 때문.
	- 낮은 온도는 단조롭고 반복적이다
	- 높은 온도는 창의적이고 흥미로운 경우가 있다
	- 매우 높은 온도에서는 국부적인 구조가 무너지고, 출력이 랜덤하게 보인다.

- 데이터가 더 많고, 모델이 더 크고 깊으면 이것보다 더 논리적이고 실제와 같은 텍스트 샘플을 생성할 수 있다. 
	- `GPT-3`도 이 예제와 동일하지만, 더 많은 트랜스포머 디코더를 쌓고 더 큰 훈련 데이터를 사용했다.

- 자연어의 역할은 의사소통, 세상에 영향을 미치는 방법, 사회의 윤활유, 생각을 체계화, 저장, 검색하는 방법 등이 있다. 언어의 사용이 의미가 시작되는 곳이다. 그러나 딥러닝의 `언어 모델`은 언어의 이런 면을 감지하지 못한다.
- **언어 모델이 하는 일은 관찰 가능한 인공물의 통계적 구조를 감지하는 것이다.**
	- 사람의 언어는 통계적인 구조를 띄기 때문에 이러한 언어 모델이 기능할 수 있는 것이다.

### 정리
- 이전 토큰으로 다음 토큰(들)을 예측하는 모델을 훈련해 시퀀스 데이터를 만들 수 있다.
- 텍스트의 경우 이런 모델을 `언어 모델`이라고 부른다. 단어, 글자 단위 모두 가능하다.
- 다음 토큰을 샘플링할 때, 모델의 출력에 집중하는 것과 무작위성 사이에 균형을 맞춰야 한다.
	- `소프트맥스 온도`는 무작위성을 부여하며, 다양한 온도를 실험해서 적당한 값을 찾는다.
	- 

## 딥드림
합성곱 신경망의 표현을 학습하여 예술적으로 이미지를 조작하는 기법이다.
- 컨브넷 필터 시각화 기법과 거의 동일하다. 아래는 차이점.
	- 딥드림은 전체 층의 활성화를 최대화한다. 컨브넷은 상위 층만 적용했음.
	-  빈 이미지, 노이즈 입력이 아니라 이미 가지고 있는 이미지를 사용한다. 기존 시각 패턴을 바탕으로 이미지의 요소들을 예술적인 스타일로 왜곡시킨다.
	- 입력 이미지는 여러 다른 스케일`옥타브 : 이미지 크기를 일정 비율로 연속적으로 줄이거나 늘리는 방식`로 처리한다.

### 케라스 딥드림 구현

- 이미지 내려받기
```python
from tensorflow import keras
import matplotlib.pyplot as plt

base_image_path = keras.utils.get_file(
									   "coast.jpg",
									   origin = 'https://img-datasets.s3.amazonaws.com/coast.jpg'
)
plt.axis('off')
plt.imshow(keras.utils.load_img(base_image_path))
```

- 사전 훈련된 컨브넷 이용하기
	- `VGG16, VGG19, Xception, ResNet50` 등 모두 쓸 수 있다. 여기선 `inception_v3`을 사용함.
```python
from tensorflow.keras.applications import inception_v3

model = inception_v3.InceptionV3(weights = 'imagenet', include_top = False)
```

- 다양한 중간 층의 활성화를 반환하는 추출 모델 만들기
	- 각 층의 기여도에 가중치를 주기 위해 스칼라 값을 선택한다.
	- 다른 층을 선택하고 싶으면 `model.summary()`에 제공되는 이름을 보자.
```python
# 활성화 최대화할 층과 전체 손실에 대한 가중치.

layer_settings = {
				  "mixed4" : 1.0,
				  "mixed5" : 1.5,
				  "mixed6" : 2.0,
				  "mixed7" : 2.5
}

# 각 층의 심볼릭 출력
outputs_dict = dict(
					[
					(layer.name, layer.output) for layer in [model.get_layer(name) for name in layer_settings.keys()]
					]
)

# 각 타깃의 활성화층을 하나의 딕셔너리로 반환
feature_extractor = keras.Model(inputs = model.inputs, outputs = outputs_dict)
```

- 손실 계산하기
	- 경사 상승법으로 각 스케일마다 최대화할 값.
	- 여러 층의 모든 필터 활성화를 동시에 최대화한다. 특히, 상위층의 활성화 `L2 Norm`의 가중치 평균을 최대화한다.
```python
def compute_loss(input_image):
	features = feature_extractor(input_image)
	loss = tf.zeros(shape = ()) # 초기화 : 0
	for name in features.keys():
		coeff = layer_settings[name]
		activation = features[name]
		# 테두리가 아닌 픽셀만 손실에 추가
		loss += coeff * tf.reduce_mean(tf.square(activation[:, 2:-2, 2:-2, :]))
	return loss
```

- 경사 상승법 단계
```python
import tensorflow as tf

@tf.function # 속도 높이기
def gradient_ascent_step(image, learning_rate):
	# 현재 이미지에 대한 딥드림 손실 그래디언트 계산
	with tf.GradientTape() as tape:
		tape.watch(image)
		loss = compute_loss(image)
	grads = tape.gradient(loss, image)
	grads = tf.math.l2_normalize(grads) # 정규화
	image += learning_rate * grads
	return loss, image

# 주어진 이미지 스케일(옥타브)에 대한 경사 상승법 수행
def gradient_ascent_loop(image, iterations, learning_rate, max_loss = None):
	for i in range(iterations):
		loss, image = gradient_ascent_step(image, learning_rate)
		if max_loss is not None and loss > max_loss: # 손실이 임계값을 넘으면 중지 - 과도한 최적화 방지
			break
		print(f"... 스텝 {i}에서의 손실 값 : {loss:.2f}")
	return image
```

- 딥드림 바깥쪽 루프
1. `옥타브` 스케일의 리스트 정의
	- 3개의 다른 `옥타브`로 이미지를 처리한다
	- 각 옥타브에서 가장 작은 값 -> 큰 값까지 `gradient_ascent_loop`로 경사 상승법을 30번 적용한다. 
	- 각 옥타브 사이에서는 이미지가 40% 증가한다.
```python
# 파라미터 정의
step = 20. # 경사 상승법 단계
num_octave = 3 # 경사 상승법 실행할 스케일 횟수
octave_scale = 1.4 # 연속적인 스케일 사이의 크기 비율
iterations = 30 # 스케일 단계마다 수행하는 경사 상승법 단계 횟수
max_loss = 15. # 손실 임계값 : 이거보다 크면 중지

# 이미지 로드 & 저장 유틸리티 함수
import numpy as np

# 이미지 -> 넘파이 변환
def preprocess_image(image_path):
	img = keras.utils.load_img(image_path)
	img = keras.utils.img_to_array(img)
	img = np.expand_dims(img, axis = 0)
	img = keras.applications.inception_v3.preprocess_input(img)
	return img

# 넘파이 -> 이미지 변환
def deprocess_image(img):
	img = img.reshape((img.shape[1], img.shape[2], 3))
	# InceptionV3 전처리 복원
	img += 1.0
	img *= 127.5
	img = np.clip(img, 0, 255).astype('uint8')
	return img

```
- `InceptionV3`의 전처리 : 픽셀 값을 127.5로 나눠 0~2 사이로 만든 뒤, 1을 빼서 -1~1로 만든다.
	- `Xception`, `InceptionResNetV2, MobileNet, NASNet`도 같은 전처리 방식을 쓴다.

```python
# 여러 옥타브에 걸쳐 경사 상승법 실행하기
original_img = preprocess_image(base_image_path)
original_shape = original_img.shape[1:3]

# 여러 옥타브에서 이미지 크기 계산
successive_shapes = [original_shape]
for i in range(1, num_octave):
	shape = tuple([int(dim / (octave_scale ** i)) for dim in original_shape])
	successive_shapes.append(shape)
successive_shapes = successive_shapes[::-1]
shrunk_original_img = tf.image.resize(original_img, successive_shapes[0])

# 이미지 복사
img = tf.identity(original_img)

for i, shape in enumerate(successive_shapes):
	print(f"{shape} 크기와 {i}번째 옥타브 처리")
	img = tf.image.resize(img, shape) # 스케일을 높임
	img = gradient_ascent_loop(img, iterations = iterations, learning_rate = step, max_loss = max_loss) # 경사 상승법 실행, 이미지 수정
	upscaled_shrunk_original_img = tf.image.resize(shrunk_original_img, shape)
	same_size_original = tf.image.resize(original_img, shape) # 작은 버전의 원본 이미지 스케일 상승. 픽셀 경계가 보인다.
	lost_detail = same_size_original - upscaled_shrunk_original_img # 고해상도 원본 이미지 계산
	img += lost_detail # 손실된 디테일을 딥드림 이미지에 다시 넣음
	shrunk_origianl_img = tf.image.resize(original_img, shape)

keras.utils.save_img("dream.png", deprocess_image(img.numpy())) # 최종 결과 저장
```
> 원본 인셉션 네트워크가 299 x 299 크기라서 딥드림도 300x300 ~ 400x400 정도에서 좋은 결과를 만든다. 그러나 어떤 크기나 비율을 가진 이미지에서도 실행 가능하다.

![[dream.png]]

- 전체적인 훈련 과정은 이러함
1. `옥타브 1 원본 이미지` -> 딥드림 ->  `옥타브 1 딥드림 이미지` -> 스케일 증가 (`옥타브 2 딥드림(1) 이미지`)
2. `옥타브 2 딥드림(1) 이미지` + `옥타브 2 원본 이미지`(디테일 재주입) -> 딥드림 -> `옥타브 2 딥드림(2) 이미지` -> 스케일 증가 `옥타브 3 딥드림(2) 이미지`
3. `옥타브 3 딥드림(2) 이미지` + `옥타브 3 원본 이미지`(디테일 재주입) -> 딥드림 -> `옥타브 3 딥드림(3) 이미지` 

### 정리
- 딥드림은 네트워크가 학습한 표현을 기반으로, 컨브넷을 거꾸로 실행해서 입력 이미지를 생성한다.
- 음성, 음악 등에도 적용할 수 있다. 

## 뉴럴 스타일 트랜스퍼
- 이미지를 변경하는 다른 분야로는 `뉴럴 스타일 트랜스퍼 Neural Style Transfer`가 있다. 
- 타깃 이미지의 컨텐츠를 보존하면서, 참조 이미지의 스타일을 타깃 이미지에 적용할 수 있다.
	- `스타일` = 색깔, 질감, 이미지 등 다양한 요소
	- `콘텐츠` = 이미지에 있는 고수준의 대형 구조
	- 반 고흐의 스타일을 실제 사진에 적용할 때
		- 붓질 = 스타일, 사진의 건물 = 컨텐츠

- `스타일 트랜스퍼`의 아이디어 자체는 이미 이미지 처리 분야에서 오랜 역사가 있었다.
- `뉴럴 스타일 트랜스퍼`의 핵심 개념은 모든 알고리즘 핵심과 동일하다. 
	- 손실 함수 정의 & 손실 최소화.

- 여기서는 **참조 이미지의 스타일을 적용하되, 원본 이미지의 컨텐츠를 보존**해야 한다.
- 따라서 손실함수를 대충 정의하면 이런 느낌임
```
loss = distance(style(reference_image) - style(combination_image)) + distance((content(original_image) - content(combination_image)))
```
- `distance`는 L2 Norm 함수, `content`는 이미지의 콘텐츠 표현 계산, `style`은 이미지의 스타일 표현을 계산한다.
	- 이를 최소화하면 `style(combination_image)`는 `style(ref_img)`에 가까워지고, `content(comb_img)`는 `content(origin_img)`에 가까워진다.

### 컨텐츠 손실
네트워크의 하위 층은 국부적인 정보, 상위 층은 전역적이고 추상적인 정보를 담는다.  
달리 생각하면, 컨브넷의 활성화는 이미지를 **다른 크기의 컨텐츠로 분해한다**고 할 수 있다. 상위 층의 표현을 사용하면 전역적이고 추상적인 이미지 컨텐츠를 찾을 수 있을 것이다.  

- 타깃 이미지와 생성된 이미지를 사전 훈련 컨브넷에 주입, 상위 층의 활성화를 계산한다.
	- `손실`값으로 `L2 Norm`이 좋다. 

### 스타일 손실
- 컨텐츠 손실은 1개의 상위 층을 사용한다.  

- 스타일 손실은 컨브넷의 여러 층을 사용한다. 참조 이미지에서 컨브넷이 추출한 모든 크기의 스타일을 잡아야 한다.
- 층의 활성화 출력의 `그람 행렬Gram Matrix`을 스타일 손실로 사용한다.
	- 일련의 벡터가 주어졌을 때 이를 내적한 행렬이다. 특성 맵 하나를 하나의 벡터로 펼쳐 생각하면, 특성 맵의 그람 행렬을 얻을 수 있다.
	- 어떤 합성곱 층의 채널이 10개라면, 그람 행렬은 (10, 10) 크기가 된다. 
	- **어떤 특성 2개가 동시에 활성화되는 정도를 기록한 것으로, 스타일을 정의**한다.
		- 층 특성 사이의 상관관계를 잡는다고 해석할 수도 있다.
		- 이는 특성 크기의 공간적인 패턴 통계를 잡아내며, 경험적으로 해당 층에서 찾은 텍스쳐에 대응된다.

따라서 사전 훈련 컨브넷으로 다음 손실들을 정의할 수 있다.
1. 컨텐츠 보존을 위해 원본 - 생성된 이미지 사이에서 상위 층의 활성화를 비슷하게 유지한다.
2. 스타일 보존을 위해 저수준, 고수준 층에서 활성화 내의 상관관계를 비슷하게 유지한다.

### 케라스로 뉴럴 스타일 트랜스퍼 구현하기.
- `VGG19` 네트워크를 사용한다. `VGG16` 대비 3개의 층이 더 추가됨

- 과정
	1. `스타일 참조 이미지, 베이스 이미지(컨텐츠 제공 이미지), 생성된 이미지`를 위해 `VGG19`의 층 활성화를 동시에 계산하는 네트워크를 설정한다.
	2. 새 이미지에서 계산한 층 활성화를 사용, 손실 함수를 정의한다. 이를 최소화함.
	3. 손실 함수를 최소화할 경사 하강법을 설정한다.

- 스타일 참조 이미지, 베이스 이미지 경로 정의
```python
from tensorflow import keras

base_image_path = keras.utils.get_file(
    "sf.jpg", origin="https://img-datasets.s3.amazonaws.com/sf.jpg")
style_reference_image_path = keras.utils.get_file(
    "starry_night.jpg", origin="https://img-datasets.s3.amazonaws.com/starry_night.jpg")

original_width, original_height = keras.utils.load_img(base_image_path).size
img_height = 400
img_width = round(original_width * img_height / original_height)
```
- [컨텐츠 이미지](https://img-datasets.s3.amazonaws.com/sf.jpg) : 스타일이 덮혀질 이미지(구조 유지)
- [스타일 이미지](https://img-datasets.s3.amazonaws.com/starry_night.jpg)

- 유틸리티 함수 
	- 이미지 로드 & 크기 바꿔서 배열로 변환
	- 배열 -> 이미지 변환
```python
# 유틸리티 함수 : 이미지 <-> 배열
import numpy as np

def preprocess_image(image_path):
    img = keras.utils.load_img(
        image_path, target_size=(img_height, img_width))
    img = keras.utils.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = keras.applications.vgg19.preprocess_input(img)
    return img

# 넘파이 -> 이미지 변환
def deprocess_image(img):
    img = img.reshape((img_height, img_width, 3))
    img[:, :, 0] += 103.939
    img[:, :, 1] += 116.779
    img[:, :, 2] += 123.68
    img = img[:, :, ::-1]
    img = np.clip(img, 0, 255).astype("uint8")
    return img
```

- `VGG19` 네트워크 준비
	- 사전 훈련 컨브넷을 이용, 중간층의 활성화를 반환한다.
	- 모든 층을 사용함.
```python
model = keras.applications.vgg19.VGG19(weights="imagenet", include_top=False)

outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])
feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)
```

- 컨텐츠 손실 정의
	- VGG19 컨브넷의 상위 층은 베이스 이미지와 생성된 이미지에서 동일한 것을 봐야 함
```python
# 컨텐츠 손실 정의
def content_loss(base_img, combination_img):
    return tf.reduce_sum(tf.square(combination_img - base_img))
```

- 스타일 손실 정의
	- 입력 행렬의 그람 행렬을 계산한다. 원본 특성 행렬과의 상관관계를 기록함.
```python
# 스타일 손실 정의
def gram_matrix(x):
    x = tf.transpose(x, (2, 0, 1))
    features = tf.reshape(x, (tf.shape(x)[0], -1))
    gram = tf.matmul(features, tf.transpose(features))
    return gram

def style_loss(style_img, combination_img):
    S = gram_matrix(style_img)
    C = gram_matrix(combination_img)
    channels = 3
    size = img_height * img_width
    return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))
```

- 총 변위 손실(Total Variation Loss)
	- 생성된 이미지가 공간적 연속성을 갖도록 함
	- 픽셀의 격자 무늬가 과도한 것을 줄여준다.
```python
# 총 변위 손실 정의
def total_variation_loss(x):
    a = tf.square(
        x[:, : img_height - 1, : img_width - 1, :] - x[:, 1:, : img_width - 1, :]
    )
    b = tf.square(
        x[:, : img_height - 1, : img_width - 1, :] - x[:, : img_height - 1, 1:, :]
    )
    return tf.reduce_sum(tf.pow(a + b, 1.25))
```

- 최소화할 손실은 이 3가지 손실의 가중치 평균이다.
	- 컨텐츠 손실 : `block5_conv2` 층만 사용
	- 스타일 손실은 여러 층 사용
	- 마지막에 총 변위 손실 추가
	- 참고) 사용할 스타일 참조 이미지와 컨텐츠 이미지에 따라 `content_weight` 계수(전체 손실에 기여하는 `콘텐츠 손실의 비율`)를 조정하는 게 좋다. 높을수록 타깃 컨텐츠가 많이 나타남.
```python
# 최소화할 최종 손실 정의하기
style_layer_names = [
    "block1_conv1",
    "block2_conv1",
    "block3_conv1",
    "block4_conv1",
    "block5_conv1",
]
content_layer_name = "block5_conv2"
total_variation_weight = 1e-6
style_weight = 1e-6
content_weight = 2.5e-8

def compute_loss(combination_image, base_image, style_reference_image):
    input_tensor = tf.concat(
        [base_image, style_reference_image, combination_image], axis=0
    )
    features = feature_extractor(input_tensor)
    loss = tf.zeros(shape=())
    
    # 컨텐츠 손실을 더함
    layer_features = features[content_layer_name]
    base_image_features = layer_features[0, :, :, :]
    combination_features = layer_features[2, :, :, :]
    loss = loss + content_weight * content_loss(
        base_image_features, combination_features
    )
    
    # 스타일 손실을 더함
    for layer_name in style_layer_names:
        layer_features = features[layer_name]
        style_reference_features = layer_features[1, :, :, :]
        combination_features = layer_features[2, :, :, :]
        style_loss_value = style_loss(
          style_reference_features, combination_features)
        loss += (style_weight / len(style_layer_names)) * style_loss_value
        
    # 총 변위 손실을 더함
    loss += total_variation_weight * total_variation_loss(combination_image)
    return loss
```

- 경사 하강법 단계 설정하기
	- 원래 논문은 `L-BFGS` 알고리즘을 사용한다.
		- `의사 뉴턴 메서드` 중 하나로, `BFGS` 알고리즘을 제한된 메모리 공간에서 구현함
	- 하지만 텐서플로우에는 이 알고리즘이 없어서 `SGD`로 미니 배치 경사 하강법을 쓴다.
	- 추가로, `학습률 스케쥴링`을 쓴다 : 손실이 낮아질수록 학습률을 줄인다.
```python
# 경사 하강법 단계 설정하기
# 원 논문은 L-BFGS 알고리즘을 쓰나, 여기서는 SGD와 학습률 감소를 씀
import tensorflow as tf

@tf.function
def compute_loss_and_grads(combination_image, base_image, style_reference_image):
    with tf.GradientTape() as tape:
        loss = compute_loss(combination_image, base_image, style_reference_image)
    grads = tape.gradient(loss, combination_image)
    return loss, grads

optimizer = keras.optimizers.SGD(
    keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96
    )
)

base_image = preprocess_image(base_image_path)
style_reference_image = preprocess_image(style_reference_image_path)
combination_image = tf.Variable(preprocess_image(base_image_path))

iterations = 4000
for i in range(1, iterations + 1):
    loss, grads = compute_loss_and_grads(
        combination_image, base_image, style_reference_image
    )
    optimizer.apply_gradients([(grads, combination_image)])
    if i % 100 == 0:
        print(f"{i}번째 반복: loss={loss:.2f}")
        img = deprocess_image(combination_image.numpy())
        fname = f"combination_image_at_iteration_{i}.png"
        keras.utils.save_img(fname, img)
```
![[combination_image_at_iteration_4000.png]]
- 스타일 이미지의 텍스쳐가 두드러지고 비슷한 패턴이 많을 때 잘 작동하며, 
- 컨텐츠 타깃을 위한 수준 높은 이해가 필요하지 않을 때 잘 작동한다.
- AI보다는 고전적인 시그널 처리에 가까움.

- 느리지만 간단한 변환을 수행하므로, 작고 빠른 컨브넷을 사용하여 학습할 수 있다.

### 정리
- 스타일 트랜스퍼는 참조 이미지의 스타일 + 타깃 이미지의 콘텐츠를 보존해 새로운 이미지를 만든다.
	- 콘텐츠는 컨브넷 상위 층의 활성화에서
	- 스타일은 여러 컨브넷의 활성화 내의 상관관계에서 얻을 수 있다.
- 딥러닝에서는 사전 훈련 컨브넷으로 손실 정의 & 최소화하는 과정으로 스타일 트랜스퍼를 구성할 수 있다.
- 다양한 변종과 개선이 가능하다.

## 변이형 오토인코더(VAE)를 사용한 이미지 생성
AI에서 가장 인기 있고 성공적인 애플리케이션은 이미지 생성이다.  
잠재 시각 공간 학습 & 샘플링해서, 실제 사진에서 보간된 새로운 이미지를 만든다.  
이 분야의 주요 기법은 `변이형 오토인코더Variational AutoEncoder:VAE`와 `생성적 적대 신경망Generative Adversarial Networks:GAN`이다.  
- GAN, VAE를 사용해 소리, 음악, 텍스트의 잠재 공간을 만들 수 있으며, 사진에서 재밌는 결과가 많이 나온다.

### 이미지의 잠재 공간에서 샘플링하기
- 이미지 생성의 핵심 아이디어는, **각 포인트가 실제와 같은 이미지로 매핑될 수 있는 저차원 잠재 공간의 표현을 만드는 것**이다.
- 잠재 공간의 한 포인트를 입력으로 받아 이미지(픽셀의 그리드)를 출력하는 모듈을
	- GAN : `생성자Generator`
	- VAE : `디코더Decoder`다.
- 잠재 공간을 학습하면 포인트 하나를 샘플링한다.
- 그 다음 이미지 공간에 매핑해 이전에 본 적 없는 이미지를 생성한다.

```
훈련 데이터 -> 학습 -> 이미지의 잠재 공간(벡터 공간) -> 잠재 공간 벡터 -> 생성자or디코더 -> 합성 이미지
```
- VAE는 구조적인 잠재 공간 학습에 뛰어나다. 특정 방향은 데이터에서 의미 있는 변화의 방향을 인코딩한다.
- GAN은 매우 실제 같은 이미지를 만든다. 여기서 만든 잠재 공간은 구조적이거나 연속성이 없을 수 있다.

### 이미지 변형을 위한 개념 벡터
11장에서 `단어 임베딩` 을 다룰 때 이미 `개념 벡터Concept Vector`에 대한 아이디어가 나왔다.  
잠재 공간이나 임베딩 공간이 주어지면, 이 공간의 어떤 방향은 원본 데이터의 흥미로운 변화를 인코딩한 축일 수 있다.  
이런 `벡터`를 찾아내면, 이미지를 잠재 공간에 투영하여 의미 있는 방향으로 표현을 이동시킨 뒤 디코딩하여 복원하면 변형된 이미지를 얻을 수 있다.  
기본적으로 **이미지 공간에서 독립적으로 변화가 일어나는 모든 차원이 개념 벡터**다.  

### 변이형 오토인코더
- 2013년 12월 ~ 2014년 1월 동시에 발견됨
- VAE는 생성 모델의 한 종류로, 개념 벡터를 통해 이미지 변형에 아주 적절하다.
- `오토인코더`란 입력을 저차원 잠재 공간으로 인코딩한 뒤, 디코딩하여 복원하는 네트워크이다.
- `변이형 오토인코더`는 딥러닝과 베이즈 추론의 아이디어를 혼합한 오토인코더의 최신 버전이다.

`고전적인 오토인코더` 는 이미지를 입력받아 인코더 모듈을 사용, 잠재 벡터 공간으로 매핑한다. 이후 디코더 모듈을 사용해 원본 이미지와 동일한 차원으로 복원하여 출력한다.
- 입력 이미지와 동일한 이미지를 타깃 데이터로 사용하여 훈련한다. 
- 즉, **원본 입력을 재구성하는 방법을 학습**한다.
`코딩 : 인코더의 출력`에 여러 제약을 가하면, 오토 인코더가 더 흥미롭거나 덜 흥미로운 잠재 공간의 표현을 학습한다. 코딩이 저차원이고 희소하도록 제약을 가하며, 인코더는 입력 데이터의 정보를 적은 수의 비트에 압축하려 한다.  
그러나 `고전적인 오토인코더`는 특별히 유용하거나 구조화된 잠재공간을 만들지 못한다.  

한편 `VAE`는 약간의 통계 기법을 추가, 연속적이고 구조적인 잠재 공간을 학습하도록 만들었고, 이미지 생성을 위한 강력한 도구가 되었다.    
VAE는 입력 이미지를 잠재 공간의 고정된 `코딩`에 압축하지 않고, **`어떤 통계 분포의 파라미터로 변환한다.`** 입력 이미지를 어떤 통계적 과정의 결과로 가정하여 인코딩과 디코딩하는 동안 무작위성이 필요하다는 것을 의미한다. `평균과 분산` 파라미터를 이용해 이 분포에서 하나의 샘플을 추출하고, 이 샘플을 디코딩해서 원본 입력으로 복원한다.
- **무작위성을 더해서 안정성을 향상**하고 **잠재 공간 어디서든 의미 있는 표현을 인코딩**하도록 만든다. **잠재 공간에서 샘플링한 모든 포인트는 유효한 출력으로 디코딩**된다.

>- 기술적으로 VAE는 
>1. 인코더 모듈이 입력 샘플`input_img`을 잠재 공간의 두 파라미터 `z_mean`과 `z_log_var`로 변환
>2. 잠재 공간의 정규 분포에서 `z`를 `z = z_mean + exp(0.5 * z_log_var) * epsilon`처럼 무작위로 샘플링한다. `epsilon`은 작은 값을 가진 랜덤 텐서.
>3. 디코더 모듈은 잠재 공간의 이 포인트를 원본 입력 이미지로 매핑하여 복원한다.

- 랜덤 텐서 `epsilion`에 의해 `z_means`을 중심으로 다양한 변주가 있을 거고, 가까울수록 비슷한 이미지가 생성될 것이다. 
- 잠재 공간의 저차원 연속성은 잠재 공간에서 모든 방향이 의미 있는 데이터 변화의 축을 인코딩하도록 만든다. 매우 구조적이고 개념 벡터로 다루기 적합해진다.

- 2개의 손실 함수로 훈련한다.
	- `재구성 손실Reconstruction Loss` : 디코딩 샘플과 원본 입력
	- `규제 손실Regularization Loss` : 잠재 공간을 형성하고, 훈련 데이터 과적합을 줄임
		- `쿨백-라이블러 발산` : 인코더 출력의 분포 -> 정규 분포로 이동시킴

```python
z_mean, z_log_var = encoder(input_img)
z = z_mean + exp(0.5 * z_log_var) * epsilon
reconsructed_img = decoder(z)
model = Model(input_img, reconstructed_img)
```

### 케라스로 VAE 구현하기
- 모델은 크게
	1. 인코더 : 실제 이미지 -> 잠재 공간의 평균과 분산
	2. 샘플링 : 평균, 분산을 받아 잠재 공간에서 랜덤 포인트 샘플링
	3. 디코더 : 잠재 공간 포인트 -> 이미지 변환

- `인코더`의 경우, 다운샘플링할 때 최대풀링을 쓰지 않고 스트라이드를 쓴다.
	- `정보 위치Information Location`를 선호하는 모델의 경우 스트라이드가 최대 풀링보다 선호된다.
		- 이미지에서 사물의 위치
		- 유효한 이미지 재구성 시 쓸 수 있는 이미지 인코딩을 만들어야 하기 때문.

#### VAE 인코더
```python
from tensorflow import keras
from tensorflow.keras import layers

# 잠재 공간 차원
latent_dim = 2

# 인코더
encoder_inputs = keras.Input(shape = (28, 28, 1))
x = layers.Conv2D(32, 3, activation = 'relu', strides = 2, padding = 'same')(encoder_inputs)
x = layers.Conv2D(64, 3, activation = 'relu', strides = 2, padding = 'same')(x)
x = layers.Flatten()(x)
x = layers.Dense(16, activation = 'relu')(x)
z_mean = layers.Dense(latent_dim, name = "z_mean")(x)
z_log_var = layers.Dense(latent_dim, name = "z_log_var")(x)

# 마지막엔 2개의 파라미터를 반환해야 하므로
encoder = keras.Model(encoder_inputs, [z_mean, z_log_var], name = 'encoder')
```

#### VAE 샘플링
```python
# 샘플링
import tensorflow as tf

class Sampler(layers.Layer):
    def call(self, z_mean, z_log_var):
        batch_size = tf.shape(z_mean)[0]
        z_size = tf.shape(z_mean)[1]
        epsilon = tf.random.normal(shape = (batch_size, z_size)) # 정규 분포를 따르는 랜덤 벡터 배치
        return z_mean + tf.exp(0.5 * z_log_var) * epsilon # VAE 샘플링 공식
```

#### VAE 디코더
```python
# VAE 디코더
latent_inputs = keras.Input(shape = (latent_dim, ))
x = layers.Dense(7 * 7 * 64, activation = 'relu')(latent_inputs)
x = layers.Reshape((7, 7, 64))(x)

# Encoder 역순
x = layers.Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)
x = layers.Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)

# 최종 출력 : (28, 28, 1)
decoder_outputs = layers.Conv2D(1, 3, activation = 'sigmoid', padding = 'same')(x)
decoder = keras.Model(latent_inputs, decoder_outputs, name = 'decoder')
```

#### VAE 모델 만들기
- 오토인코더는 입력을 타깃으로 사용하는 `자기지도 학습` 중 하나임.
	- `지도 학습`이 아니다!
	- `지도 학습`의 경우 `Model` 클래스를 상속해서 `train_step()` 메서드를 구현하는 게 보통임.

```python
# VAE 모델 만들기
class VAE(keras.Model):
    def __init__(self, encoder, decoder, **kwargs):
        super().__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder
        self.sampler = Sampler()
        
        # 에포크마다 손실 평균 추적
        self.total_loss_tracker = keras.metrics.Mean(name = 'total_loss')
        self.reconstruction_loss_tracker = keras.metrics.Mean(name = "reconstruction_loss")
        self.kl_loss_tracker = keras.metrics.Mean(name = "kl_loss")
        
    @property
    def metrics(self):
        """
        각 에포크 완료 후 or fit()과 evaluate() 사이에 \
        모델이 손실을 재설정할 수 있도록 metrics 속성에 손실을 나열함
        """
        return [self.total_loss_tracker,
               self.reconstruction_loss_tracker,
               self.kl_loss_tracker]
    
    def train_step(self, data):
        with tf.GradientTape() as tape:
            z_mean, z_log_var = self.encoder(data)
            z = self.sampler(z_mean, z_log_var)
            reconstruction = decoder(z)
            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction),
                                                              axis = (1, 2)
                                                              )
                                                )
            # 규제항(쿨백-라이블러 발산)
            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))
            total_loss = reconstruction_loss + tf.reduce_mean(kl_loss)
        grads = tape.gradient(total_loss, self.trainable_weights)
        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))
        self.total_loss_tracker.update_state(total_loss)
        self.reconstruction_loss_tracker.update_state(reconstruction_loss)
        self.kl_loss_tracker.update_state(kl_loss)
        return {
            'total_loss' : self.total_loss_tracker.result(),
            'reconstruction_loss' : self.reconstruction_loss_tracker.result(),
            'kl_loss' : self.kl_loss_tracker.result()
        }
```
```python
# VAE 훈련
import numpy as np

(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()
mnist_digits = np.concatenate([x_train, x_test], axis = 0) # MNIST 전체 데이터를 쓸 거임(훈련 + 테스트)
mnist_digits = np.expand_dims(mnist_digits, -1).astype('float32') / 255

vae = VAE(encoder, decoder)
vae.compile(optimizer = keras.optimizers.Adam(), run_eagerly = True)
vae.fit(mnist_digits, epochs = 30, batch_size = 128)
```

- 이미지 그리드 샘플링
```python
# 2D 잠재 공간에서 이미지 그리드 샘플링
import matplotlib.pyplot as plt

n = 30 # 30 x 30 그리드
digit_size = 28
figure = np.zeros((digit_size * n, digit_size * n))

# 2D 그리드, 선형적으로 포인트 샘플링
grid_x = np.linspace(-1, 1 , n)
grid_y = np.linspace(-1, 1, n)[::-1]


for i, yi in enumerate(grid_y):
    for j, xi in enumerate(grid_x):
        
        # 각 위치의 숫자 샘플링해서 그림에 추가
        z_sample = np.array([[xi, yi]])
        x_decoded = vae.decoder.predict(z_sample) 
        digit = x_decoded[0].reshape(digit_size, digit_size)
        
        figure[
            i * digit_size : (i + 1) * digit_size,
            j * digit_size : (j + 1) * digit_size
        ] = digit
        
plt.figure(figsize = (15, 15))
start_range = digit_size // 2
end_range = n * digit_size + start_range
pixel_range = np.arange(start_range, end_range, digit_size)
sample_range_x = np.round(grid_x, 1)
sample_range_y = np.round(grid_y, 1)
plt.xticks(pixel_range, sample_range_x)
plt.yticks(pixel_range, sample_range_y)
plt.xlabel("z[0]")
plt.ylabel("z[1]")
plt.axis('off')
plt.imshow(figure, cmap = 'Greys_r')
```
![[Pasted image 20230726213411.png]]
###  정리
- 이미지 데이터셋에 대한 **통계 정보를 담은 잠재 공간을 학습해서 이미지를 생성**할 수 있다. 
- `VAE : 변이형 오토 인코더`와 `GAN : 생성적 적대 신경망`이 그것이다. 
- `VAE`는 구조적이고 연속적인 잠재 공간의 표현을 만든다.
	- 잠재 공간 내에 연속적으로 일어나는 모든 종류의 이미지 변형 작업에 알맞다.
		- 다른 얼굴로 바꾸기, 찌푸린 얼굴을 웃는 얼굴로 바꾸기 등
		- 잠재 공간을 가로질러 이미지가 변환하는 애니메이션에도 잘 맞다.
- `GAN`은 실제 같은 단일 이미지를 만들 수 있으나, 구조적이고 연속적인 잠재 공간을 만들지는 못한다.

## GAN : 생성적 적대 신경망 소개
- GAN은 생성된 이미지가 실제 이미지와 통계적으로 거의 구분되지 않도록 강제, 실제 같은 합성 이미지를 생성한다.

> 이해를 위한 예시
 1. 가짜 피카소 그림을 그리는 위조범을 생각한다. 진짜 피카소 그림과 가짜 그림을 판매상에게 동시에 보여준다.
>2.` 판매상`은 **진짜 그림이 뭔지를 평가**하고, 어떤 게 피카소 그림인가를 위조범에게 **피드백**을 준다.
>3. 위조범은 다시 새로운 위조품을 준비한다.
>4. 위 과정을 반복하면 
>> 1) **위조범의 그림은 피카소의 그림에 더 가까워진다.**
>> 2) **판매상은 위조품을 구분하는데 더 전문가가 된다.**

- 위조범과 전문가를 각각 네트워크라고 할 수 있다.
- `생성자 네트워크Generator Network` 
	- 랜덤 벡터를 입력으로 받아 이를 합성된 이미지로 디코딩
- `판별자 네트워크Discriminator Network or 적대 네트워크Adversary Network`
	- 이미지 or 합성 이미지를 인풋으로 받아 실제 이미지인지 생성자가 만든 이미지인지 판별한다.

- 훈련이 종료되면 생성자는 입력 공간의 어떤 포인트를 그럴 듯한 이미지로 변환하지만, VAE와 달리 이 잠재 공간은 의미 있는 구조를 보장하지 않는다. 특히, 연속적이지 않다.
- **GAN은 최적화의 최솟값이 고정되어 있지 않다.** 여태까지 배운 것 중 이런 건 없었다. 경사하강법에는 최솟값이 있음을 가정했던 걸 생각해보자.
- GAN은 언덕을 내려오는 매 단계가 조금씩 전체 공간을 바꾼다. 최적화 과정은 최솟값을 찾는 게 아니라, 두 힘 간의 평형점을 찾는 다이나믹 시스템이다.
- 그래서 GAN은 훈련하기 어렵다. 이를 만들려면 모델 구조와 훈련 파라미터를 주의 깊게 많이 조정해야 한다.

- [참고 사이트](https://thispersondoesnotexist.com) 와 여기에 사용된 [논문](https://arxiv.org/abs/1912.04958)

### GAN 구현 방법
- 가장 기본적인 형태의 GAN 구현 방법을 설명한다. 위 사이트 모델의 기술적인 내용을 설명하는 건 책 범위 밖이다. (StyleGAN2)
- 이 예제에서는 `심층 합성곱 GAN DCGAN`을 구현한다. 생성자와 판별자가 심층 컨브넷인 기본적인 GAN.

- 데이터셋 : [CelebA](https://mmlabe.ie.cuhk.edu.hk/projects/CelebA.html)
- 속도를 위해 64 x 64로 변경

- 모델 구조
```
1. Generator는 (latent_dim,) 크기의 벡터를 (64, 64, 3)으로 매핑
2. Discriminator는 (64, 64, 3) 이미지가 진짜일 확률을 추정, 이진값으로 매핑
3. 생성자 - 판별자 연결 GAN 네트워크를 만든다. gan(x) = discriminator(generator(x))임.
	- 잠재 공간의 벡터를 판별자의 평가로 매핑한다. 판별자는 생성자가 잠재 공간의 벡터를 디코딩한 것이 얼마나 현실적인지를 평가한다.
4. 진짜 / 가짜 레이블과 함께 진짜 / 가짜 이미지 샘플을 사용하여 판별자를 훈련한다. 
5. 생성자 훈련 시, gan 모델의 손실에 대한 생성자 가중치의 그래디언트를 사용한다. 
	- 뭔 소리냐) 매 단계마다 생성자에 의해 디코딩된 이미지를, 판별자가 "진짜"로 분류하도록 만드는 방향으로 생성자의 가중치를 이동한다. 즉, 판별자를 속이는 방향으로 생성자를 이동시킨다.
```

### 훈련 방법
- 누누이 말하지만 딥러닝의 대부분은 `경험적으로 발견되었다.` 왜 잘 작동하는지는 몰라도, 경험상 잘 작동한다고 알려져 있다.
- 이 책에서 사용하는 몇 가지 기법들
1. VAE 디코더처럼 맥스풀링 대신 `스트라이드`를 쓴다.
2. 균등 분포 대신 `정규 분포(가우스 분포)`를 사용해 잠재 공간에서 포인트를 `샘플링`한다.
3. 무작위성은 모델을 견고하게 만든다. GAN 훈련은 동적 평형을 만들어서 여러 방식으로 갇힐 가능성이 높다. 따라서 **훈련 중 무작위성을 주입하기 위해 판별자 레이블에 랜덤 노이즈를 추가**한다.
4. 희소 그래디언트는 GAN 훈련을 방해한다. 딥러닝에서 종종 바람직할 수 있으나 GAN에서는 그렇지 않다.
	- 그래디언트를 희소하게 만드는 연산은 `최대 풀링 연산`과 `relu 활성화 함수`이다.
	- `최대 풀링` 대신 `스트라이드`를 쓰고,
	- **`relu` 대신 `LeakyReLU`** 를 쓴다.
		- 0 대신 약한 음수를 써서 희소성을 완화시킨다.
5. 생성자에서 픽셀 공간을 균일하게 못 다뤄서 생성 이미지에서 체스판 모양이 나타난다. 이를 위해 생성자와 판별자에서 `스트라이드`를 사용할 때, **스트라이드 크기로 나눠질 수 있는 커널 크기**를 사용한다.
	- 커널 크기가 스트라이드의 배수가 아니면 픽셀이 공평하게 합성곱되지 않는다. 

### CelebA 데이터셋 준비하기
- [수동 다운로드](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) - 정확히 어떤 데이터셋인지 몰?루
- 코랩 사용 시
```python
!mkdir celeba_gan
!pip install gdown # 코랩이 아닌 경우 인스톨 필요
!gdown 1up5bN8LCE2vHigVY-Z9yY2_aKRW5jN_9 -O celeba_gan/data.zip
!unzip -qq celeba_gan/data.zip -d celeba_gan
```

- 디렉터리를 이용, 데이터셋 만들기
```python
from tensorflow import keras

dataset = keras.utils.image_dataset_from_directory(
    "celeba_gan",
    label_mode = None, # 레이블 x, 이미지만 반환
    image_size = (64, 64),
    batch_size = 32,
    smart_resize = True # 이미지 변환 시 가로세로 비율을 유지해준다
)

dataset = dataset.map(lambda x: x / 255.) # 0-1 범위로 조정

# 샘플 이미지 출력
# import matplotlib.pyplot as plt

# for x in dataset:
#     plt.axis('off')
#     plt.imshow((x.numpy() * 255).astype('int32')[0])
#     break
```

### 판별자
- GAN에서 발생하는 문제 중 하나는, 생성자가 노이즈 이미지를 생성하는 데서 멈춘다.
	- 이 때 드롭아웃이 해결책이 될 수 있음.
```python
from tensorflow.keras import layers

discriminator = keras.Sequential(
[
    keras.Input(shape = (64, 64, 3)),
    layers.Conv2D(64, kernel_size = 4, strides = 2, padding = 'same'),
    layers.LeakyReLU(alpha = 0.2), 
    layers.Conv2D(128, kernel_size = 4, strides = 2, padding = 'same'),
    layers.LeakyReLU(alpha = 0.2), 
    layers.Conv2D(128, kernel_size = 4, strides = 2, padding = 'same'),
    layers.LeakyReLU(alpha = 0.2), 
    layers.Flatten(),
    layers.Dropout(0.2), # 중요!
    layers.Dense(1, activation = 'sigmoid')
],
name = 'discriminator'
)
```
### 생성자
```python
latent_dim = 128 # 잠재 공간은 128차원 벡터

generator = keras.Sequential([
    keras.Input(shape = (latent_dim,)),
    layers.Dense(8 * 8 * 128), # 판별자의 Flatten() 층의 출력 크기와 동일하게 지정
    layers.Reshape((8, 8, 128)), # Flatten() 층 되돌리기
    layers.Conv2DTranspose(128, kernel_size = 4, strides = 2, padding = 'same'),
    layers.LeakyReLU(alpha = 0.2),
    layers.Conv2DTranspose(256, kernel_size = 4, strides = 2, padding = 'same'),
    layers.LeakyReLU(alpha = 0.2),
    layers.Conv2DTranspose(512, kernel_size = 4, strides = 2, padding = 'same'),
    layers.LeakyReLU(alpha = 0.2),
    layers.Conv2D(3, kernel_size = 5, padding = 'same', activation = 'sigmoid'),
],
name = 'generator',
)
```
### 적대 네트워크
- 생성자와 판별자를 연결한다.
- 훈련 : 생성자가 판별자를 속이는 능력이 커지도록 학습
	- 모델은 잠재 공간의 포인트를 `진짜 or 가짜의 분류`로 결정
	- 훈련의 타깃 레이블은 **항상 진짜**다.
	- 따라서, `gan`을 훈련하는 것은 `discriminator`가 가짜 이미지도 진짜로 예측하게끔 `generator`의 가중치를 업데이트하는 것이다.

- 훈련 내용
	1. 잠재 공간에서 무작위 포인트를 뽑음
	2. 랜덤 노이즈로 `생성자`에서 이미지 생성
	3. 생성된 진짜 이미지와 가짜 이미지를 섞음
	4. 진짜, 가짜 이미지와 대응하는 타깃을 사용해 `구별자`를 훈련. 타깃은 진짜 or 가짜
	5. 잠재 공간에서 무작위로 새로운 포인트를 뽑음
	6. `5.`를 활용해 `생성자`를 훈련한다. 모든 타깃은 진짜로 설정한다.

- 구현
```python
import tensorflow as tf

class GAN(keras.Model):
    def __init__(self, discriminator, generator, latent_dim):
        super().__init__()
        self.discriminator = discriminator
        self.generator = generator
        self.latent_dim = latent_dim
        self.d_loss_metric = keras.metrics.Mean(name = "d_loss")
        self.g_loss_metric = keras.metrics.Mean(name = 'g_loss')
        
    def compile(self, d_optimizer, g_optimizer, loss_fn):
        super(GAN, self).compile()
        self.d_optimizer = d_optimizer
        self.g_optimizer = g_optimizer
        self.loss_fn = loss_fn
        
    @property
    def metrics(self):
        return [self.d_loss_metric, self.g_loss_metric]
    
    def train_step(self, real_images):
        # 잠재 공간에서 랜덤 포인트 샘플링
        batch_size = tf.shape(real_images)[0]
        random_latent_vectors = tf.random.normal(shape = (batch_size, self.latent_dim))
        generated_images = self.generator(random_latent_vectors) # 랜덤 포인트 -> 가짜 이미지 인코딩
        combined_images = tf.concat([generated_images, real_images], axis = 0) # 가짜와 진짜 이미지 합침
        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis = 0) # 가짜와 진짜 이미지 레이블 합침
        labels += 0.05 * tf.random.uniform(tf.shape(labels)) # 레이블에 랜덤 잡음 추가
        
        # 판별자 훈련
        with tf.GradientTape() as tape:
            predictions = self.discriminator(combined_images)
            d_loss = self.loss_fn(labels, predictions)
        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)
        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))
        
        random_latent_vectors = tf.random.normal(shape = (batch_size, self.latent_dim)) # 랜덤 포인트 샘플링
        misleading_labels = tf.zeros((batch_size, 1)) # 모두 진짜라고 말하는 레이블 만들기(실제로는 아님)
        
        # 생성자 훈련
        with tf.GradientTape() as tape:
            predictions = self.discriminator(self.generator(random_latent_vectors))
            g_loss = self.loss_fn(misleading_labels, predictions)
        grads = tape.gradient(g_loss, self.generator.trainable_weights)
        
        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))
        self.d_loss_metric.update_state(d_loss)
        self.g_loss_metric.update_state(g_loss)
        return {'d_loss' : self.d_loss_metric.result(),
               'g_loss' : self.g_loss_metric.result()}
```

- 훈련 중 이미지 생성하는 콜백 함수
```python
class GANMonitor(keras.callbacks.Callback):
    def __init__(self, num_img = 3, latent_dim = 128):
        self.num_img = num_img
        self.latent_dim = latent_dim
        
    def on_epoch_end(self, epoch, logs = None):
        random_latent_vectors = tf.random.normal(shape = (self.num_img, self.latent_dim))
        generated_images = self.model_generator(random_latent_vectors)
        generated_images *= 255
        generated_images.numpy()
        
        for i in range(self.num_img):
            img = keras.utils.array_to_img(generated_images[i])
            img.save(f"generated_img_{epoch:03d}_{i}.png")
```

- 모델 컴파일 및 훈련
```python
# GAN 모델 컴파일 및 훈련
epochs = 100

gan = GAN(discriminator = discriminator, generator = generator, latent_dim = latent_dim)

gan.compile(d_optimizer = keras.optimizers.Adam(learning_rate = 0.0001),
           g_optimizer = keras.optimizers.Adam(learning_rate = 0.0001),
           loss_fn = keras.losses.BinaryCrossentropy())

gan.fit(dataset, epochs = epochs,
       callbacks = [GANMonitor(num_img = 10, latent_dim = latent_dim)])
```
만약 판별자의 손실이 0으로, 적대적 손실이 지나치게 증가하는 경우 판별자의 학습률을 낮추고 판별자의 드롭아웃 비율을 높여서 시도할 수 있다.

### 정리
- GAN은 생성자 네트워크 + 판별자 네트워크의 연결로 구성된다.
	- `판별자`는 **생성자의 출력과, 훈련 데이터셋에서 가져온 진짜 이미지를 구분**하도록 훈련된다.
	- `생성자`는 **판별자를 속이도록 훈련하며, 훈련 세트의 이미지를 직접 보지 않는다.** 데이터에 관한 정보는 판별자에서만 얻는다.
- GAN은 훈련하기 어렵다 : 고정된 공간에서의 경사하강법이 아니라, 동적 과정이기 떄문이다.
	- 올바르게 훈련하기 위해 경험적으로 찾은 여러 기교를 사용하고, 많은 튜닝을 해야 한다.
- GAN은 매우 실제 같은 이미지를 만들 수 있다. `VAE`와 달리 학습된 잠재 공간이 깔끔하게 연속적인 구조를 가지지 않는다.
	- 잠재 공간의 개념 벡터를 사용하여 이미지를 변형하는 실용적인 특정 앱과는 맞지 않는다.
- 여기서 다룬 기법은 기초일 뿐이고, 생성 모델 딥러닝 자체가 책 1권 분량이다.

## 전체 요약
- `시퀀스-투-시퀀스` 모델로 한 번에 한 스텝씩 시퀀스 데이터를 만들 수 있다. 텍스트 생성, 음악 생성 등 시계열 데이터를 적용하는 곳에 모두 사용할 수 있다.
- 딥드림은 입력 공간에 경사 상승법을 적용, 컨브넷 활성화를 최대화한다.
- 스타일 트랜스퍼는 경사하강법을 통해 콘텐츠 - 스타일 이미지를 연결한다. 콘텐츠의 고수준 특성과 스타일의 국부적인 특징을 가진 이미지를 만든다.
- `VAE`와 `GAN`은 이미지의 잠재 공간을 학습하고, 잠재 공간에서 샘플링하여 완전히 새로운 이미지를 만들 수 있는 모델이다. `개념 벡터`를 사용해 이미지를 변형할 수도 있다.