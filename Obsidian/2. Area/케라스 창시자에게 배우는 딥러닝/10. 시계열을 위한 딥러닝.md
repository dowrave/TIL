1. [[#다양한 종류의 시계열 작업|다양한 종류의 시계열 작업]]
2. [[#온도 예측 문제|온도 예측 문제]]
	1. [[#온도 예측 문제#데이터 준비|데이터 준비]]
	2. [[#온도 예측 문제#상식 수준의 기준점|상식 수준의 기준점]]
	3. [[#온도 예측 문제#기본적인 머신러닝 모델 시도하기|기본적인 머신러닝 모델 시도하기]]
	4. [[#온도 예측 문제#1D 합성곱 시도하기|1D 합성곱 시도하기]]
	5. [[#온도 예측 문제#1번째 순환 신경망|1번째 순환 신경망]]
3. [[#순환 신경망 이해하기|순환 신경망 이해하기]]
	1. [[#순환 신경망 이해하기#케라스의 순환 층|케라스의 순환 층]]
4. [[#순환 신경망의 고급 사용법|순환 신경망의 고급 사용법]]
	1. [[#순환 신경망의 고급 사용법#순환 드롭아웃|순환 드롭아웃]]
	2. [[#순환 신경망의 고급 사용법#스태킹 순환 층|스태킹 순환 층]]
	3. [[#순환 신경망의 고급 사용법#양방향 RNN 사용하기|양방향 RNN 사용하기]]


## 다양한 종류의 시계열 작업
- `시계열Timeseries` 데이터는 일정 간격으로 측정하여 얻은 모든 데이터를 의미한다.
- 시계열을 다루려면 시계열의 `역학Dynamics`을 이해해야 한다.
	- 주기성
	- 트렌드
	- 규칙적인 형태
	- 급격한 증가 등

- 가장 일반적인 작업은 `예측Predictions`이다. 
	- 현 시점의 시계열 데이터 이후에 일어날 일을 예측한다.
- 이외에도
	- `분류` : 방문자가 봇인가 사람인가
	- `이벤트 감지` : 특히 `핫워드 감지`로, 모델이 오디오 스트림을 모니터하다가 `오케이 구글` 같은 시작 단어를 감지한다.
	- `이상치 감지Anonamly Detection` : 연속적인 데이터 스트림에서 발생하는 비정상적 현상.
		- 비지도 학습으로 수행된다.

- 시계열을 다루는 데이터 기법
	- `퓨리에 변환Fourier Transform` : 주기와 진동이 특징인 데이터 처리
		- 딥러닝에서는 퓨리에 분석 or 멜 주파수 분석과 다른 도메인 특화된 표현을 특성 공학의 형태로 사용, 모델 훈련 전에 데이터를 전처리할 수 있다.

- 여기서는 기법보다는 모델링 부분에 초점을 맞춘다.

## 온도 예측 문제
> 건물 센서의 기압, 습도 데이터가 있을 때 24시간 뒤의 온도를 예측하는 문제

- 데이터 준비
```sh
wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip
unzip jena_climate_2009_2016.csv.zip
```
```python
import os
fname = os.path.join('jena_climate_2009_2016.csv')

with open(fname) as f:
  data = f.read()

lines = data.split("\n")
header = lines[0].split(",")
lines = lines[1:]
print(header)
print(len(lines))
```

- 데이터 전체를 넘파이 배열로 바꾼다. 온도와 나머지를 분리하며, 나머지 배열로 온도를 예측한다.
```python
import numpy as np

temperature = np.zeros((len(lines), ))
raw_data = np.zeros((len(lines), len(header) - 1))
for i, line in enumerate(lines):
  values = [float(x) for x in line.split(",")[1:]]
  temperature[i] = values[1] # 2번째 열을 temperature 배열에 저장
  raw_data[i, :] = values[:] # 모든 열을 raw_data 배열에 저장

# 시각화
import matplotlib.pyplot as plt

plt.plot(range(len(temperature)), temperature)
plt.show()
```
![[Pasted image 20230724202714.png]]

- 데이터는 10분마다 측정되며, 하루에 144개의 데이터 포인트가 있다.
- 첫 열흘 동안의 데이터
```python
plt.plot(range(1440), temperature[:1440])
plt.show()
```
![[Pasted image 20230724202828.png]]
- 기온이 섭씨이므로, 위 데이터는 겨울에 해당하는 데이터임을 알 수 있다

> **데이터에서 항상 주기성을 찾자.**   
> 주기성은 시계열 데이터에서 중요하고 일반적인 성질이다. 데이터 탐색 시 이런 패턴을 찾아보자.

Q) 데이터셋에서 몇 달 간의 데이터로 다음 달의 평균 온도를 예측하는 것은 쉽다. 연간 데이터의 주기성은 안정적이기 떄문이다. 그렇다면 하루하루 단위의 시계열 데이터 예측은 어떨까?

- 훈련 50%, 검증 25%, 테스트 25% 데이터 분리.
- **시계열 데이터의 경우 검증과 테스트 데이터는 훈련 데이터보다 최신**이어야 한다. 
	- 예측하는 곳은 과거가 아니라 미래이기 때문.
```python
num_train_samples = int(0.5 * len(raw_data))
num_val_samples = int(0.25 * len(raw_data))
num_test_samples = len(raw_data) - num_train_samples - num_val_samples

print(num_train_samples, num_val_samples, num_test_samples)
```

### 데이터 준비
- 문제 정의 : 1시간에 1번씩 샘플링된, 5일간의 데이터가 있을 때 24시간 뒤의 온도는?

1. 데이터를 신경망에 넣을 수 있는 형태로 전처리
- 각 피쳐 값이 다르므로, 정규화를 해줘야 한다.
```python
# 데이터 정규화
mean = raw_data[:num_train_samples].mean(axis = 0)
raw_data -= mean
std = raw_data[:num_train_samples].std(axis = 0)
raw_data /= std
```
당연히 훈련 데이터에 대해서만 정규화를 진행한다.

2. 과거 5일치 데이터와 24시간 뒤 타깃 온도 배치를 반환하는 `Dataset` 객체 만들기
- `N`번째 샘플과 `N+1`번째 샘플에는 많은 데이터포인트가 중복된다. 따라서 모든 샘플을 적재하면 메모리 낭비가 심하므로, `raw_data`와 `temperature` 배열만 유지하고 샘플은 그때그떄 만든다.
- 파이썬 제너레이터 기능이 있지만, 케라스에 내장된 데이터셋 유틸리티가 있다.
---
> `timeseries_dataset_from_array()`  
> 시계열 데이터 배열을 `data` 매개변수에 넣으면, 시계열에서 추출한 윈도우(시퀀스)를 제공한다.  
> ex) `[0, 1, 2, 3, 4, 5]`가 있다면, `[0, 1, 2]`, `[1, 2, 3]`, `[2, 3, 4]` ... 가 있는 식.  
> `target` 매개변수로 타깃 배열을 전달할 수 있다. 시계열 예측의 경우, 약간의 시간 차를 두되 `data` 배열과 동일해야 한다.  
> ex) `sequence_length = 3`이라면, `[3, 4, 5, 6, 7, 8]`이어야 한다.

- 테스트
```python
int_sequence = (np.arange(10))
dummy_dataset = keras.utils.timeseries_dataset_from_array(
														  data = int_sequence[:-3],
														  targets = int_sequence[3:],
														  sequence_length = 3,
														  batch_size = 2
)

for inputs, targets in dummy_dataset:
	for i in range(inputs.shape[0]):
		print([int(x) for x in inputs[i]], int(targets[i]))


"""
[0, 1, 2] 3 
[1, 2, 3] 4 
[2, 3, 4] 5 
[3, 4, 5] 6 
[4, 5, 6] 7
"""
```

---
- `timeserie_dataset_from_array()`가 받는 매개변수는
	- `sampling_rate = 6` : 시간당 1개의 데이터포인트가 샘플링된다. 6개중 1개만 쓴다는 뜻.
	- `sequence_length = 120` : 이전 120시간 데이터 사용
	- `delay = sampling_rate * (sequence_length + 24 - 1)` : 시퀀스의 타깃은 시퀀스 끝에서 +24시간 뒤의 온도이다.

- 데이터셋 준비
```python
sampling_rate =  6
sequence_length = 120
delay = sampling_rate * (sequence_length + 24 - 1)
batch_size = 256

train_dataset = keras.utils.timeseries_dataset_from_array(
    raw_data[:-delay],
    targets = temperature[delay:],
    sampling_rate = sampling_rate,
    sequence_length = sequence_length,
    shuffle = True,
    batch_size = batch_size,
    start_index = 0,
    end_index = num_train_samples
)

val_dataset = keras.utils.timeseries_dataset_from_array(
    raw_data[:-delay],
    targets = temperature[delay:],
    sampling_rate = sampling_rate,
    sequence_length = sequence_length,
    shuffle = True,
    batch_size = batch_size,
    start_index = num_train_samples,
    end_index = num_train_samples + num_val_samples
)

test_dataset = keras.utils.timeseries_dataset_from_array(
    raw_data[:-delay],
    targets = temperature[delay:],
    sampling_rate = sampling_rate,
    sequence_length = sequence_length,
    shuffle = True,
    batch_size = batch_size,
    start_index = num_train_samples + num_val_samples
)

```

- 크기 확인
```python
for samples, targets in train_dataset:
  print("샘플 크기 : ", samples.shape)
  print("타깃 크기 : ", targets.shape)
  break
```

### 상식 수준의 기준점
- 여기서는 `지금으로부터 24시간 후의 온도는 지금과 동일하다`로 간다. 
	- 시계열 데이터는 연속성, 일자별로 주기성이 있다고 생각할 수 있기 때문이다.
	- 이를 `np.mean(np.abs(preds - targets))`로 나타낼 수 있다.
```python
# 상식 수준의 평가
def evaluate_naive_method(dataset):
  total_abs_err = 0
  samples_seen = 0
  for samples, targets in dataset:
    
    # 특성이 이미 정규화되었음 -> 온도를 섭씨로 바꾸는 과정
    preds = samples[:, -1, 1] * std[1] + mean[1] # 온도 특성은 칼럼 인덱스 1에 있다.

    total_abs_err += np.sum(np.abs(preds - targets))
    samples_seen += samples.shape[0]
  return total_abs_err / samples_seen


print(f"검증 MAE : {evaluate_naive_method(val_dataset):.2f}") # 2.44
print(f"테스트 MAE : {evaluate_naive_method(test_dataset):.2f}") # 2.52
```
- 여기서는 2.5도라는, 무작위일 때의 기준점을 정한 것이다.

### 기본적인 머신러닝 모델 시도하기
- 정말 단순한 층만 구성함 
```python
# 기본 머신러닝 모델로 시도하기
from tensorflow import keras
from tensorflow.keras import layers

inputs = keras.Input(shape =  (sequence_length, raw_data.shape[-1]))
x = layers.Flatten()(inputs)
x = layers.Dense(16, activation = 'relu')(x)
outputs = layers.Dense(1)(x)
model = keras.Model(inputs, outputs)

callbacks = [
    keras.callbacks.ModelCheckpoint("jena_dense.keras", save_best_only = True)
]

model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])
history = model.fit(train_dataset, epochs = 10, validation_data = val_dataset, callbacks = callbacks)

model = keras.model.load_model('jena_dense.keras')
print(f"테스트 MAE : {model.evaluate(test_dataset)[1]}:.2f")
```


- 시각화
```python
# 시각화 
import matplotlib.pyplot as plt

loss = history.history['mae']
val_loss = history.history['val_mae']
epochs = range(1, len(loss) + 1)
plt.figure()
plt.plot(epochs, loss, 'bo', label = "Training MAE")
plt.plot(epochs, loss, 'b-', label = "Validation MAE")
plt.title("Training and Valdiation MAE")
plt.legend()
plt.show()
```

![[Pasted image 20230724211451.png]]
> 2.5 정도로 상식 수준과 비슷한 경우도 있지만 기본적으로 들쭉날쭉하다.

- 간단한 모델이 데이터 - 타깃 매핑이 된지만 왜 훈련한 모델은 못 찾을까?
	- 가설 공간은 매개 변수로 설정한 2개의 층을 가진, 네트워크의 모든 가능한 가중치 조합이 된다. 상식 수준의 모델은 이러한 공간 속의 수백만 가지 중 하나일 뿐이다.
	- **가설 공간에 좋은 솔루션이 있다 != 경사 하강법으로 찾을 수 있다**
- 이게 머신러닝이 가진 제약이다. 하드코딩하지 않으면, 간단한 문제를 위한 간단한 해결책을 찾지 못할 때가 있다.
- 따라서 이전에 배운 `아키텍처 구조`와 좋은 `특성 공학`이 중요한 이유가 된다.

### 1D 합성곱 시도하기
- 입력 시퀀스가 일별 주기를 가지기 때문에 합성곱 모델을 생각해볼 수 있다. 
- 시간 축에 대한 합성곱은 `다른 날에 있는 동일한 표현을 재사용`할 수 있다.
	- 공간 방향의 합성곱이 이미지에 있는` 다른 위치의 같은 표현을 재사용`하는 것과 같다.
	- `1D` 컨브넷 또한 평행 이동 불변성 가정을 따르는 시퀀스 데이터에 잘 맞는다.
```python
inputs = keras.Input(shape =  (sequence_length, raw_data.shape[-1]))
x = layers.Conv1D(8, 24, activation = 'relu')(inputs)
x = layers.MaxPooling1D(2)(x)
x = layers.Conv1D(8, 12, activation = 'relu')(inputs)
x = layers.MaxPooling1D(2)(x)
x = layers.Conv1D(8, 6, activation = 'relu')(inputs)
x = layers.GlobalAveragePooling1D()(x)
outputs = layers.Dense(1)(x)
model = keras.Model(inputs, outputs)

callbacks = [
    keras.callbacks.ModelCheckpoint("jean_conv.keras", save_best_only = True)
]

model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])
history = model.fit(train_dataset, epochs = 10, validation_data = val_dataset, callbacks = callbacks)

model = keras.model.load_model('jean_conv.keras')
print(f"테스트 MAE : {model.evaluate(test_dataset)[1]:.2f}")
```


- 밀집 연결 모델보다 성능이 나쁘다. 2가지 이유가 있음.
1. 날씨 데이터는 평행 이동 불변성 가정을 많이 따르지 않는다.
	- 일별 주기성이 있지만, 아침 데이터는 저녁, 한밤중과는 다르다. 매우 특정 시간 범위에 한해서만 평행 이동 불변성을 가진다.
2. 순서가 많이 중요하다.
	- 최근 데이터는 5일 전 데이터보다 내일 온도를 예측하는데 훨씬 더 유용하다.
	- 1D 컨브넷은 순서를 활용할 수 없으며, 최대풀링과 전역평균풀링층 때문에 순서 정보가 많이 삭제된다.

### 1번째 순환 신경망
- 밀집 연결 모델은 시계열 데이터를 펼쳐서 시간 개념이 없어졌다.
- 합성곱 모델은 순서 정보를 잃어버렸다.

- **인과 관계와 순서가 의미 있을 때를 위해 고안된 구조가 순환 신경망**이다. LSTM이 오래 인기가 많았기 때문에 이를 사용해보자.
```python

```

## 순환 신경망 이해하기
- 모든 신경망의 특징은 **메모리가 없다**는 것이다.
- 입력은 개별적으로 처리되며, 입력 간에 유지되는 상태가 없다. 

- 이러한 네트워크에 시퀀스나 시계열 데이터 포인트를 처리하려면, 네트워크에 전체 시퀀스를 주입해야 한다. 
	- 전체 시퀀스를 하나의 데이터 포인트로 변환해야 한다.

- 밀집 연결 모델에서 5일치 데이터를 1개의 큰 벡터로 처리했는데, 이런 네트워크를 `피드포워드 네트워크Feedforward Network`라고 한다.

- 위와 반대로, 사람은 문장을 읽을 때 이전에 나온 걸 들어오는 만큼 처리한다.
- 정보 처리를 위한 내부 모델을 유지하며 점진적으로 정보를 처리한다. 이 모델은 과거로부터 얻은 정보를 계속해서 업데이트한다.

- 이를 `순환신경망Recurrent Neural Network`이라고 한다. 
	- 시퀀스의 원소를 순회하며 처리한 정보는 `상태State`에 저장된다.
	- `RNN`은 실제로 내부에 루프를 가진 신경망의 한 종류이다.
- `RNN`의 상태는 2개의 다른 시퀀스를 처리하는 사이에 재설정된다. 1개의 시퀀스 = 1개의 입력으로 간주할 수 있다.
	- 중요한 건 데이터 포인트가 한꺼번에 처리되지 않는다는 것이다.
	- 대신, 네트워크는 내부적으로 시퀀스의 원소를 순회한다.

- 간단한 RNN 정방향 계산 구현하기
```python
# pseudo code
state_t = 0 # 타임스텝 t의 상태
for input_t in input_sequence:
  output_t = activation(dot(W, input_t) + dot(U, state_t) + b)
  state_t = output_t

# numpy로 구현
timesteps = 100
input_features = 32
output_features = 64
inputs = np.random.random((timesteps, input_features)) # 랜덤 잡음
state_t = np.zeros((output_features,  )) # 초기 상태 : 0벡터

# 랜덤 가중치 행렬
W = np.random.random((output_features, input_features))
U = np.random.random((output_features, output_features))
b = np.random.random((output_features,))

successive_outputs = []
for input_t in inputs: # inputs.shape : (input_features,)
  output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b) # 1.
  successive_outputs.append(output_t) # 현재 timestep의 결과를 저장
  state_t = output_t # 2.

final_output_sequence = np.stack(successive_outputs, axis = 0) # 3.

```
1. 입력과 현재 상태(이전 출력)를 연결, 현재 출력을 얻는다. `tanh`을 써서 비선형성도 얻는다.
	- 활성화 함수는 다른 걸 써도 된다.
2. 다음 타임스텝을 위해 네트워크 상태를 업데이트한다. 기본 RNN의 상태를 `은닉 상태Hidden State`라고도 한다.
3.  최종 출력은 `timesteps, output_features` 크기의 랭크-2 텐서이다.

### 케라스의 순환 층
- 위에서 구현한게 `SimpleRNN`층임. 
- 하나 다른 점은, 하나의 시퀀스가 아니라 시퀀스의 배치 단위로 처리한다는 점이다.
	- `batch_size, timesteps, input_features`의 입력을 받는다. 
	- `Input(timesteps = None)`으로 설정 시 임의의 길이를 가진 시퀀스를 처리할 수 있다.

```python
num_features = 14
inputs = keras.Input(shape =(None, num_features))
outputs = layers.SimpleRNN(16)(inputs)
```

- 시퀀스 길이가 모두 같다면 입력 크기를 지정하는 게 좋다. 최적화를 활용할 수 있기 때문.

- 케라스의 모든 `순환 층SimpleRNN, LSTM, GRU`은 2가지 모드로 실행할 수 있다.
	- 각 타임스텝의 출력을 모은 전체 시퀀스`Batch_size, timesteps, output_features` 반환
	- 입력 시퀀스의 마지막 출력만 `batch_size, output_Features` 반환
- 생성자의 `return_sequences` 매개변수로 제어할 수 있다.

- `SimpleRNN` 예제
```python
num_features = 14
steps = 120

inputs = keras.Input(shape =(steps, num_features))

outputs = layers.SimpleRNN(16, return_sequences = False)(inputs) # 기본, 마지막 스텝만 출력
outputs = layers.SimpleRNN(16, return_sequences = True)(inputs) # 전체 상태 시퀀스 반환

print(outputs.shape)
```

- 여러 순환층 쌓기
```python
inputs = keras.Input(shape =(steps, num_features))
x = layers.SimpleRNN(16, return_sequences = True)(inputs)
x = layers.SimpleRNN(16, return_sequences = True)(x)
outputs = layers.SimpleRNN(16)(x)
```


- `SimpleRNN`은 일반적으로 많이 쓰지 않음 : `그래디언트 소실Gradient Vanishing` 문제로, 층이 많아질수록 훈련하기 어려워진다.

- 이를 보완한게 `LSTM`과 `GRU`가 있다.
	- 쉽게 생각하면 `잔차 연결`처럼, 일정한 시점에 뗴어낸 정보를 필요한 시점에 다시 연산에 넣는 방식을 이용한다.
	- 기존 RNN은 `np.activation(np.dot(W, input_t) + np.dot(U, state_t) + b)`가 출력 상태가 됨.
	- LSTM은 별도의 이동 상태 `c_t`가 추가되어, 출력 상태는 위에 `activation(c_t)`을 앞에 곱하면 됨.
	- 이 때 별도의 이동상태 `c_t`를 `셀 상태Cell State`라고 함.

- `LSTM` 구조의 의사 코드
```python
output_t = activation(c_t) * activation(dot(input_t, Wo) + dot(state_t, Uo) + bo)
i_t = activation(dot(state_t, Ui) + dot(input_t, Wi) + bi)
f_t = activation(dot(state_t, Uf) + dot(input_t, Wf) + bi)
k_t = activation(dot(state_t, Uk) + dot(input_t, Wi) + bk)

c_{t+1} = i_t * k_t + c_t * f_t
```

> 이게 뭔 소리임? 대충 살펴보면 이런 느낌이다.
> `c_t * f_t` : 관련이 적은 정보를 의도적으로 삭제함. `삭제 게이트Forget Gate`
> `i_t * k_t` : 현재 정보를 제공하고, 이동 트랙을 새로운 정보로 업데이트한다. `입력 게이트Input Gate`

- 그러나 이런 식으로 **해석하는 건 큰 의미는 없다.** 
- 연산들이 실제로 하는 일은 연산에 관련된 가중치 행렬에 의해 결정되기 때문이다.  이런저런 연산에 특정 목적을 부여하는 게 불가능하다.
- RNN 셀의 구조는 가설 공간을 설정한다. 훈련할 때 좋은 파라미터를 찾는다.
	- 셀이 하는 일은 셀의 구조가 아니라 가중치에 달려 있다.
	- 즉, 같은 셀이더라도 다른 가중치를 가진다면 매우 다른 작업을 수행한다.
- 따라서, RNN 셀을 구성하는 연산 조합은 엔지니어링적인 설계보다는 **가설 공간의 제약 조건으로 해석하는 것이 낫다.**

> 요약) LSTM 셀의 **구체적인 구조에 대해 이해할 필요가 전혀 없다.** LSTM 셀의 역할만 기억하면 된다. **과거 정보를 다시 주입, 그래디언트 소실 문제를 해결하는 것이다.**

## 순환 신경망의 고급 사용법
- `순환 드롭아웃 Recurrent Dropout` : 순환 층에서의 과대적합 방지
- `스태킹 순환 층Stacking Recurrent Layer` : 모델의 표현 능력 증가(비용도 같이 증가)
- `양방향 순환 층Bidirectional Recurrent Layer` : 같은 정보를 다른 방향으로 주입하여 정확도를 높이고, 기억을 더 오래 유지시킴

### 순환 드롭아웃
- 과대적합을 방지할 수 있다.
- 순환 네트워크의 드롭아웃은 
	- 타임스텝마다 랜덤하게 드롭아웃 마스크를 바꾸는 게 아니라, (이는 규제가 아니라 방해임)
	- **같은 드롭아웃 마스크를 모든 타입스텝에 적용**하는 것이다.
- GRU, LSTM 등 순환 게이트에 의해 만들어지는 표현을 규제하려면 
	- 순환 층 내부 계산에 사용된 활성화 함수에 타임스텝마다 같은 드롭아웃 마스크를 적용한다. `순환 드롭 아웃 마스크`

- 케라스의 모든 순환층은 2개의 드롭아웃 매개변수값을 가진다.
	- `dropout` : 드롭아웃 비율
	- `recurrent_dropout` : 순환 상태의 드롭아웃 비율

- 드롭아웃 덕분에 네트워크 크기에 신경 쓸 필요가 적어진다. 다음 예제는 드롭아웃이 없다면 바로 과대적합됨.

```python
inputs = keras.Input(shape = (sequence_length, ), raw_data.shape[-1])
x = layers.LSTM(32, recurrent_dropout = 0.25)(inputs)
x = layers.Dropout(0.5)(x) # dense 층에 규제를 추가함
outputs = layers.Dense(1)(x)
model = keras.Model(inputs, outputs)

callbacks = [
			 keras.callbacks.Modelcheckpoint('jena_lstm_dropout.keras',
			 save_best_only = True)
]

model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])
history = model.fit(train_dataset,
				   epochs = 50,
				   validation_data = val_dataset,
				   callbacks = callbacks)
```

> **RNN 런타임 성능**  
> 파라미터가 매우 적은 RNN은 GPU보다 멀티코어 CPU에서 더 빠른 경향이 있다.  
> 대규모 RNN에서는 GPU가 도움이 될 수 있다.  
> `LSTM, GRU`는 `cuDNN` 커널을 활용할 수 있다. 고도로 최적화된 저수준 알고리즘 구현임. 근데 여기서 순환 드롭아웃을 추가하면 GPU보다 2~5배 느린 일반 텐서플로우 구현을 쓰게 된다.
> `cuDNN`을 쓸 수 없는 경우, 층을 `언롤링(Unrolling)`하는 방법이 있다.   
> `for` 루프를 언롤링하면 루프를 제거하고 단순히 그 내용을 N번 기술한다.  
> RNN의 for 루프의 경우 언롤링하면 계산 그래프 최적화에 도움이 될 수 있지만, 메모리 사용량을 상당히 증가시킨다. 따라서 비교적 작은 시퀀스에만 적용할 수 있다.  
> 또한, 모델이 데이터의 타임 스텝 수를 미리 알 수 있는 경우에만 사용할 수 있다.

- 언롤링 사용법
```python
inputs = keras.Input(shape = (sequence_length, num_features)) # None이면 안됨!
x = layers.LSTM(32, recurrent_dropout = 0.2, unroll = True)(inputs)
```

### 스태킹 순환 층
- 성능상 병목이 있는 것 같으면 네트워크의 용량과 표현력을 늘려야 한다.
	- 과대적합이 일어나는 시점을 기준으로 한다. 과대적합이 아니라면, 충분한 용량에 도달한 것이 아니다.
- 용량을 늘리는 일반적인 방법은 유닛이나 층을 더추가하는 것이다.
- `순환 층 스태킹`은 더 강력한 네트워크를 만드는 고전적인 방법이다.
	- 2016년 구글 번역 알고리즘은 7개의 대규모 LSTM 층을 쌓은 대규모 모델을 사용했다.
-  케라스에서 순환층을 차례대로 쌓으려면 **모든 중간층은 전체 시퀀스`랭크3 텐서`를 출력**해야 한다.
	- `return_sequences = True` 지정하면 된다는 뜻

- 드롭아웃 규제 & 2개의 순환층 스태킹
```python
inputs = keras.Input(shape = (sequence_length, raw_data.shape[-1]))

# 그냥 순환층을 쌓는데, 마지막 순환층을 제외하고 모두 return_sequences = True임.
x = layers.GRU(32, recurrent_dropout = 0.5, return_sequences = True)(inputs)
x = layers.GRU(32, recurrent_dropout = 0.5)(x)
x = layers.Dropout(0.5)(x) 
outputs = layers.Dense(1)(x)
model = keras.Model(inputs, outputs)

callbacks = [
			 keras.callbacks.Modelcheckpoint('jena_lstm_dropout.keras',
			 save_best_only = True)
]

model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])
history = model.fit(train_dataset,
				   epochs = 50,
				   validation_data = val_dataset,
				   callbacks = callbacks)
```
- `GRU`는 `LSTM`의 간단하고 간소화된 버전으로 생각할 수 있다.
	- 1개의 `셀 상태`를 가지며, 1개의 게이트가 삭제&입력 게이트 역할을 한다.
```python
# GRU pseudo code
output_t = z_t x state_t + (1 - z_t) x g_t
z_t = sigmoid(dot(state_t, Uz) + dot(input_t, Wz) + bz)
r_t = sigmoid(dot(state_t, Ur) + dot(input_t, Wr) + br)
g_t = tanh(dot(r_t x state_t, Ug) + dot(input_t, Wg) + bg)
```

- 성능 향상이 많이 이뤄지지 않는다면, 네트워크 용량을 늘리는 게 크게 도움이 되지 않는다고 할 수 있다.

### 양방향 RNN 사용하기

- `자연어 처리`에선 특히 즐겨 사용된다.

- RNN은 순서에 민감하다. 타임 스텝이 섞이거나 거꾸로 하면, RNN이 시퀀스에서 학습하는 표현이 완전히 바뀐다.
- `양방향 RNN`은 이 순서에 민감하다는 특징을 사용한다.
- `GRU`나 `LSTM` 같은 RNN 2개를 사용한다.
	- 각 RNN은 입력 시퀀스를 한 방향으로 처리한 후 각 표현을 합친다.
	- 단방향 RNN이 놓치기 쉬운 패턴을 감지할 수 있다.

- 실험은 단순하게, 데이터를 거꾸로 집어넣어보면 된다.
- **시계열 데이터는 최근 데이터를 더 잘 기억하고, 최근 데이터는 미래 예측에 있어 오래된 데이터보다 예측에 유용하다.**
- 하지만 자연어 처리를 비롯, 다른 많은 문제에서는 순서가 중요할 수는 있어도 결정적으로 중요하진 않다.
	- 문장을 이해할 때 단어의 중요성은 단어의 위치로 결정되는 게 아니다.
	- 텍스트 데이터셋은 순서를 뒤집는 것과 순서대로 처리하는 것이 비슷하게 작동한다.

- 거꾸로 된 시퀀스에서 훈련한 RNN은 원래 시퀀스에서 훈련한 것과 다른 표현을 학습한다.
- 즉, 여러 모델을 활용하는 `앙상블Ensemble` 개념이 된다.
`a,b,c,d,e -> RNN ` ㄱ
`e,d,c,b,a -> RNN` -> `합침` -> 입력 데이터

- 케라스에서는 `Bidirectional` 픙으로 양방향 RNN을 만든다.
	- 1번째 매개변수로 순환 층의 객체를 받는다.
	- 전달받은 순환 층으로 2번째 객체를 만든다.
	- 하나는 시간 순서대로, 다른 하나는 역순으로 입력 시퀀스를 처리한다.

```python
inputs = keras.Input(shape = (sequence_length, raw_data.shape[-1]))
x = layers.Bidirectional(layers.LSTM(16))(inputs)
outputs = layers.Dense(1)(x)
					 
model = keras.Model(inputs, outputs)
model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mae'])
history = model.fit(train_dataset,
				   epochs = 10,
				   validation_data = val_dataset,
)
```
- 이 문제(온도 예측)에서는 평범한 LSTM 층보다 성능이 낮게 나오는데, 최근 데이터가 예측에 더 유용하기 때문에 시간 반대 순서로 처리하는 절반의 낮은 성능이 전체 성능에 영향을 준다.
- 또한 네트워크 용량이 2배가 되고, 과대적합도 일찍 시작된다.

- 양방향 RNN은 텍스트 데이터 or 순서가 중요한(하지만 사용하는 순서는 중요하지 않은) 데이터에 잘 맞는다.
- `트랜스포머Transformer` 구조가 등장하기 전,양방향 LSTM 층은 많은 자연어 처리 작업에서 최고 성능을 냈다(2016년)

- 이 예제에서 계속 비볐을 때 상식 기준점 + 10%가 이 데이터셋에서 최선이다.
- 한 지역의 측정값만으로는 날씨를 예측하기 어렵다. 날씨는 주변 지역의 날씨 패턴에 의해 달라진다.

> 주식 시장과 머신 러닝  
> 주식 시장은 날씨와는 다른 통계적 특성을 갖는다. 일반적으로 예측은 과거 지표를 보고 하는데, 주식은 이 특성이 맞지 않다. 백미러를 보고 운전하는 것과 똑같음.  
> 모든 거래는 `정보 차익거래Information Arbitrage`이다. 잘 알려진 머신러닝 기법과 공개된 데이터를 쓰면 결국 다른 사람보다 정보 이익이 없기 때문에 막다른 골목에 다다를 것이다.


