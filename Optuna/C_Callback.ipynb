{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bb5294e-e74c-4614-a8b8-b2adfdc98031",
   "metadata": {},
   "source": [
    "# Optmize()에 대한 Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f066dc2-ce11-48d9-969a-5008e2905051",
   "metadata": {},
   "source": [
    "- `Callback`은 `objective`의 매 평가 이후에 호출되며, `Study`나 `FrozenTrial`을 인자로 삼음\n",
    "- [MLflowCallback](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.integration.MLflowCallback.html#optuna.integration.MLflowCallback)이 좋은 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b88f4b0-215d-40a3-831d-9901858feb67",
   "metadata": {},
   "source": [
    "## Pruning이 연속으로 일어났을 때 최적화 중지 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab16c92f-238c-4c71-af75-237f334535d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "class StopWhenTrialKeepBeingPrunedCallback:\n",
    "    \n",
    "    def __init__(self, threshold: int):\n",
    "        self.threshold = threshold\n",
    "        self._consequtive_pruned_count = 0\n",
    "    \n",
    "    # def func() -> None : 리턴값 명시해줌\n",
    "    def __call__(self, study: optuna.study.Study, trial: optuna.trial.FrozenTrial) -> None:\n",
    "        \n",
    "        if trial.state == optuna.trial.TrialState.PRUNED:\n",
    "            self._consequtive_pruned_count += 1\n",
    "        \n",
    "        else:\n",
    "            self._consequtive_pruned_count = 0\n",
    "            \n",
    "        if self._consequtive_pruned_count >= self.threshold:\n",
    "            study.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7478115c-4576-4bc8-9d98-1676a4444a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    if trial.number > 4:\n",
    "        raise optuna.TrialPruned\n",
    "        \n",
    "    return trial.suggest_float('x', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac074e1a-7206-4475-a693-5747a073595e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 15:30:07,459]\u001b[0m A new study created in memory with name: no-name-6ad989b8-76ea-4fa4-8bc2-63217912d060\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A new study created in memory with name: no-name-6ad989b8-76ea-4fa4-8bc2-63217912d060\n",
      "A new study created in memory with name: no-name-6ad989b8-76ea-4fa4-8bc2-63217912d060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 15:30:07,468]\u001b[0m Trial 0 finished with value: 0.5954513530385738 and parameters: {'x': 0.5954513530385738}. Best is trial 0 with value: 0.5954513530385738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0 finished with value: 0.5954513530385738 and parameters: {'x': 0.5954513530385738}. Best is trial 0 with value: 0.5954513530385738.\n",
      "Trial 0 finished with value: 0.5954513530385738 and parameters: {'x': 0.5954513530385738}. Best is trial 0 with value: 0.5954513530385738.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 15:30:07,475]\u001b[0m Trial 1 finished with value: 0.899763320305922 and parameters: {'x': 0.899763320305922}. Best is trial 0 with value: 0.5954513530385738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 finished with value: 0.899763320305922 and parameters: {'x': 0.899763320305922}. Best is trial 0 with value: 0.5954513530385738.\n",
      "Trial 1 finished with value: 0.899763320305922 and parameters: {'x': 0.899763320305922}. Best is trial 0 with value: 0.5954513530385738.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 15:30:07,482]\u001b[0m Trial 2 finished with value: 0.40839507729528035 and parameters: {'x': 0.40839507729528035}. Best is trial 2 with value: 0.40839507729528035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished with value: 0.40839507729528035 and parameters: {'x': 0.40839507729528035}. Best is trial 2 with value: 0.40839507729528035.\n",
      "Trial 2 finished with value: 0.40839507729528035 and parameters: {'x': 0.40839507729528035}. Best is trial 2 with value: 0.40839507729528035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 15:30:07,489]\u001b[0m Trial 3 finished with value: 0.5746463026872782 and parameters: {'x': 0.5746463026872782}. Best is trial 2 with value: 0.40839507729528035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 finished with value: 0.5746463026872782 and parameters: {'x': 0.5746463026872782}. Best is trial 2 with value: 0.40839507729528035.\n",
      "Trial 3 finished with value: 0.5746463026872782 and parameters: {'x': 0.5746463026872782}. Best is trial 2 with value: 0.40839507729528035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 15:30:07,494]\u001b[0m Trial 4 finished with value: 0.07268867423664616 and parameters: {'x': 0.07268867423664616}. Best is trial 4 with value: 0.07268867423664616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 finished with value: 0.07268867423664616 and parameters: {'x': 0.07268867423664616}. Best is trial 4 with value: 0.07268867423664616.\n",
      "Trial 4 finished with value: 0.07268867423664616 and parameters: {'x': 0.07268867423664616}. Best is trial 4 with value: 0.07268867423664616.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 15:30:07,498]\u001b[0m Trial 5 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 pruned. \n",
      "Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 15:30:07,505]\u001b[0m Trial 6 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 6 pruned. \n",
      "Trial 6 pruned. \n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "optuna.logging.get_logger('optuna').addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "study_stop_cb = StopWhenTrialKeepBeingPrunedCallback(2)\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials = 10, callbacks = [study_stop_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9ef2c-be3a-4649-8fe9-fa442340d8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
