{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_SanFranciscoCrimeClassification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPk9KpmuS4MMY+93cH7GeiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dowrave/PythonToKaggle/blob/main/4_SanFranciscoCrimeClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 모델을 돌리는 부분은 시간이 너무 오래걸려서 실행시키지 않고 커밋함.\n"
      ],
      "metadata": {
        "id": "sg7i7wzZ0eD8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXjI0sQ3Dy2G"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle/\n",
        "!mv kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c sf-crime\n",
        "!unzip '*.zip'"
      ],
      "metadata": {
        "id": "PZGy1IU9E82K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 크기 확인\n",
        "import os\n",
        "DATA_PATH = \"./\"\n",
        "for file in os.listdir(DATA_PATH):\n",
        "  if 'csv' in file and 'zip' not in file:\n",
        "    print(file.ljust(30) + str(round(os.path.getsize(file) / 1000000, 2)) + 'MB')"
      ],
      "metadata": {
        "id": "yiFCJsh7FhJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "_V8db4ItGQW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape, test.shape"
      ],
      "metadata": {
        "id": "29PaMYz1Gk14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "XvSC95aOGo3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "metadata": {
        "id": "OpwoJuEjGsS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train과 Test Feature의 차이 : Category, Descript, Resolution은 Train에만 있다\n",
        "# Category는 종속변수 y\n",
        "# Descript, Resolution은 개요, 마무리에 관한 글이나 테스트 데이터에 없기 때문에 제거해준다."
      ],
      "metadata": {
        "id": "kVCHeFP8Gs1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 나머지 Feature에 대한 설명\n",
        "- 시간 데이터 : Dates, DayOfWeek\n",
        "- 공간 데이터 : PdDistrict, Addres, X, Y \n",
        "--> 시, 공간 데이터를 활용해 범죄의 유형을 예측하는 문제\n",
        "\n",
        "### Submission의 형태\n",
        "- 상기한 6개의 feature를 통해 범죄 유형을 39가지로 분류하라"
      ],
      "metadata": {
        "id": "fPo82E_IHb0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_submission.csv\n",
        "sample = pd.read_csv('sampleSubmission.csv')\n",
        "sample.info()"
      ],
      "metadata": {
        "id": "kjRG25aHG5Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류 결과값은 원핫 인코딩과 같이, 1개의 샘플 당 39개의 벡터가 있고 그 중 하나만 1이면 ㅇㅇ"
      ],
      "metadata": {
        "id": "EHqkqhiJHyZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 다중분류 문제임\n",
        "- Multi-Class Logarithm Loss..인데 결국 모든 샘플에 대한 다중 엔트로피 공식과 비슷함\n",
        "- 차이라면 앞에 곱해지는 값이 p가 아니라 데이터가 속하는지 아닌지 여부인 y값(0 or 1 이라는 점?)\n",
        "- https://www.kaggle.com/competitions/sf-crime/overview/evaluation\n",
        "- 각 샘플에 대한 Loss 값의 합이 작을수록 좋은 모델\n"
      ],
      "metadata": {
        "id": "MzToebv7IoOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 탐색적 자료 분석\n",
        "- 데이터를 탐색할 때, 원래의 데이터를 복제해서 사용하는 것을 권장함\n",
        "  - 원래 데이터에서 다시 출발해야 하는 경우가 생기기 때문"
      ],
      "metadata": {
        "id": "T6G3mhv2Jk12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train.copy()\n",
        "train_df.shape == train.shape # 아니 책은 왜 자꾸 ==를 전부 =로 쓰냐고?"
      ],
      "metadata": {
        "id": "xxb-doNWImYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_na(data):\n",
        "  isnull_na = (data.isnull().sum() / len(data)) * 100\n",
        "  data_na = isnull_na.drop(isnull_na[isnull_na == 0 ].index).sort_values(ascending = False)\n",
        "  missing_data = pd.DataFrame({\"Missing Ratio\" : data_na,\n",
        "                               \"Data Type\" : data.dtypes[data_na.index]})\n",
        "  print(\"결측치 데이터 칼럼과 건수 : \\n\", missing_data)\n",
        "\n",
        "check_na(train_df)"
      ],
      "metadata": {
        "id": "qqWtaC28J38y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# .duplicated : 중복된 데이터들을 띄워주는 듯. \n",
        "train_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "-vr1JtAOKWCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복 데이터 제거\n",
        "train_df.shape\n",
        "train_df.drop_duplicates(inplace = True)\n",
        "train_df.shape"
      ],
      "metadata": {
        "id": "mTskJ_piKmXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 상기한 범죄 내용에 관한 텍스트 변수 2개 제거\n",
        "train_df.drop(['Descript', 'Resolution'], axis = 1, inplace = True)\n",
        "train_df.shape"
      ],
      "metadata": {
        "id": "-iE9hd37NndK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 종속변수의 분포 확인\n",
        "train_df['Category'].value_counts()[:5]"
      ],
      "metadata": {
        "id": "uNAshYr8OHQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Category'].value_counts()[-5:]"
      ],
      "metadata": {
        "id": "4AK0vnp0OPYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = train_df.groupby('DayOfWeek').count().iloc[:, 0]\n",
        "temp = temp.reindex([\n",
        "                     'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'\n",
        "])\n",
        "\n",
        "print(temp)"
      ],
      "metadata": {
        "id": "DJPVTNFvOSlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위 내용 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import cm # 이건 뭘까?\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10, 6))\n",
        "\n",
        "ax = sns.barplot(\n",
        "    temp.index, (temp.values / temp.values.sum())  * 100,\n",
        "    orient = 'values'\n",
        ")\n",
        "ax.set_title('Incident Rates by DayOfWeek', fontdict = {'fontsize' : 16})\n",
        "ax.set_xlabel('Weekday')\n",
        "ax.set_ylabel('Incidents (%)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N5fahj-ZOiKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 그래프에서 볼 수 있는 것\n",
        "--> 금요일이 제일 범죄 발생 많고 일요일은 적다\n"
      ],
      "metadata": {
        "id": "oAah4Y2bPGBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 요일별 범죄 유형 확인하기\n",
        "\"\"\" \n",
        "사실 책을 따라가면서 기억해둬야 할 지점은 이런 곳들이다. 되게 당연한 듯이 하는데 직접 해보면 생각 안나는 곳들\n",
        "특히 이거는 쓸 일이 많으니까 어떤 원리로 돌아가는지 이해해두는 게 좋을 듯!\n",
        "\"\"\"\n",
        "for idx, data in enumerate(train_df.groupby(['Category'])['DayOfWeek']):\n",
        "  print(data) # 직관적으로 해석하자. groupby로 묶인 'Category' 및 'DayOfWeek'만 가진 항목임\n",
        "              # 반복문은 각 'Category'에 대해 돌아감\n",
        "              # data[0] 은 각 'Category'를, data[1]은 각 카테고리에 속하는 샘플들의 인덱스와 'DayOfWeek'을 같이 보여줌\n",
        "  print(\"The Current Index : \", data[0])\n",
        "  print(round(data[1].value_counts()  / data[1].count()*100 , 1) \n",
        "  )\n",
        "  print()\n",
        "\n",
        "  if idx == 1:\n",
        "    break"
      ],
      "metadata": {
        "id": "VGhz0G7pO9_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 지역에 따른 범죄 수\n",
        "temp = train_df.groupby('PdDistrict').count().iloc[:, 0]\n",
        "print(temp)"
      ],
      "metadata": {
        "id": "vvyouMqQPaKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 얘도 시각화\n",
        "fig, ax = plt.subplots(figsize = (10, 6))\n",
        "\n",
        "ax = sns.barplot(\n",
        "    temp.index, (temp.values / temp.values.sum()) * 100,\n",
        "    orient = 'v'\n",
        ")\n",
        "ax.set_title('Incident Rates by PdDistrict', fontdict = {'fontsize' : 16})\n",
        "ax.set_xlabel('PdDistrict')\n",
        "ax.set_ylabel('Incidents (%)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JYQYXhWcRbUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 범죄 유형과 지역 조사\n",
        "for idx, data in enumerate(train_df.groupby(['Category'])['PdDistrict']):\n",
        "  print(data[0])\n",
        "  print(round(data[1].value_counts() / data[1].count() * 100, 1))\n",
        "  print()\n",
        "\n",
        "  if idx == 1:\n",
        "    break"
      ],
      "metadata": {
        "id": "pKXK0yUGRxLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 지역에 따른 범죄 비율이 다름을 관찰할 수 있다\n",
        "- 위도, 경도를 조사해보자"
      ],
      "metadata": {
        "id": "gJL2a1zUTCXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize = (10, 6))\n",
        "sns.scatterplot(x= \"X\", y = \"Y\",\n",
        "                data = train_df, alpha = 0.01, hue = \"PdDistrict\", ax = ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zwuu3-7hSBr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "TENDERLOIN만 유독 동떨어져있는 걸 볼 수 있다.\n",
        "그러나 바로 제거해서는 안됨 : 저게 많은 비중을 차지하는 데이터라면 성능에 영향을 줄 수 있기 때문이다.\n",
        "따라서 저 데이터의 수가 얼마나 되는지부터 확인해본다\n",
        "\"\"\"\n",
        "print(train_df.loc[train.Y > 85].count()[0], train_df.loc[train.Y < 85].count()[0])"
      ],
      "metadata": {
        "id": "EQzJ5xd4TUaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TENDERLOIN이 소수이기 때문에 제거해주고, 다시 산점도를 그려본다\n",
        "train_df = train_df[train_df['Y'] < 90]\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10, 6))\n",
        "sns.scatterplot(x='X', y='Y',\n",
        "                data = train_df, alpha = 0.01, hue = \"PdDistrict\", ax = ax)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T-sCQPOmUEzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 더 깊게 들어간다면, 범죄 유형을 세분화해서 살펴본다.\n",
        "theft_df = train_df[train_df['Category'] == 'LARCENY/THEFT']\n",
        "theft_df.shape\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10 , 6))\n",
        "sns.scatterplot(x = 'X', y = 'Y', data = theft_df, alpha = 0.01, hue = 'PdDistrict', ax = ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V7JaRelTUjcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 날짜 데이터\n",
        "- 반드시 먼저 날짜데이터의 타입을 확인하고 시작하자"
      ],
      "metadata": {
        "id": "FGiA1RzrVXNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Dates'].dtypes "
      ],
      "metadata": {
        "id": "I67_jVxCVJGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Object니까 바꾸자\n",
        "train_df.loc[: ,'Dates'] = pd.to_datetime(train_df['Dates'])\n",
        "train_df.loc[: ,'Dates'].sample(1)"
      ],
      "metadata": {
        "id": "q45UTP2lVc1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datetime으로 데이터타입이 바뀌었다면 .dt.(뽑고 싶은 단위) 로 데이터를 뽑아낼 수 있음\n",
        "train_df['Date'] = train_df.Dates.dt.date\n",
        "train_df['Hour'] = train_df.Dates.dt.hour\n",
        "daily_df = train_df.groupby('Date').count().iloc[:, 0]\n",
        "daily_df"
      ],
      "metadata": {
        "id": "250QCySGVnbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Dates'].dtypes"
      ],
      "metadata": {
        "id": "Ix3r6KN2WMAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col = sns.color_palette()\n",
        "\n",
        "fig, ax = plt.subplots(ncols = 2, figsize = (16, 6))\n",
        "sns.lineplot(daily_df.index, daily_df.values, ax = ax[0])\n",
        "ax[0].set_title('# of Incidents per day', fontdict = {\"fontsize\" : 16})\n",
        "ax[0].set_ylabel(\"Incidents\")\n",
        "\n",
        "sns.kdeplot(data = daily_df, shade = True, ax = ax[1]) # ? 처음보는 거 같다\n",
        "ax[1].axvline(x = daily_df.median(), ymax = 0.95, linestyle = '-', color = col[1])\n",
        "ax[1].annotate(\n",
        "    'Median: ' + str(daily_df.median()),\n",
        "    xy = (daily_df.median(), 0.004),\n",
        "    xytext = (200, 0.005), \n",
        "    arrowprops = dict(arrowstyle = '->', color = col[1], shrinkB = 10)\n",
        ")\n",
        "ax[1].set_title('Distribution of number of incidents per day', fontdict = {'fontsize' : 16})\n",
        "ax[1].set_xlabel('Incidents')\n",
        "ax[1].set_ylabel('Density')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6J6mrmBzWSbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 왼쪽 그래프 : 일자별 데이터의 이상치가 있음\n",
        "# 이상치 조사\n",
        "print(\"min Incidents of day : \", daily_df[daily_df.values == min(daily_df.values)])\n",
        "print(\"max Incidents of day : \", daily_df[daily_df.values == max(daily_df.values)])"
      ],
      "metadata": {
        "id": "wj4DAwv4XBkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 왜 min값이 발생했는지, Max 값이 발생했는지 알 방법은 없다 그러나 이런 것들도 파악하는 게 데이터 분석가의 업무임"
      ],
      "metadata": {
        "id": "TWSKM6J5XWSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 하루 시간대별 범죄 발생율\n",
        "hour_df = train_df.groupby('Hour').count().iloc[:, 0]\n",
        "print('min incident hour : ', hour_df[hour_df.values == min(hour_df.values)])\n",
        "print('max incident hour : ', hour_df[hour_df.values == max(hour_df.values)])\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (16, 5))\n",
        "ax = sns.lineplot(x= hour_df.index, y = hour_df.values)\n",
        "plt.title('Total Incidents per Hour')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qJlFGU7OXkUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 위 그래프는 '전체' 데이터에 대한 것이기 때문에\n",
        "- 범죄별로 들어가려면 별도로 데이터 뽑아서 확인하면 됨"
      ],
      "metadata": {
        "id": "dUBzjryJYEo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 피쳐 엔지니어링\n",
        "- 하나의 함수로 만드는 것을 권장 \n",
        "  -  공통으로 처리해야 하는 내용과, 데이터마다 전처리 성질이 조금 다른 것을 구분하는게 좋다"
      ],
      "metadata": {
        "id": "GaSvLm8gYJug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineering(data):\n",
        "\n",
        "  # common\n",
        "  data.drop_duplicates(inplace = True)\n",
        "  data['Dates'] = pd.to_datetime(data['Dates'])\n",
        "  # data['Date'] = pd.to_datetime(data['Dates'].dt.date) # 얘는 왜 기껏 뽑고 안쓰고 드랍함?\n",
        "  data['DayOfWeek'] = data['Dates'].dt.weekday\n",
        "  data['Month'] = data['Dates'].dt.month\n",
        "  data['Year'] = data['Dates'].dt.year\n",
        "  data['Hour'] = data['Dates'].dt.hour\n",
        "  data.drop(columns = ['Dates', 'Address'], axis = 1, inplace = True)\n",
        "\n",
        "  # 테스트 데이터의 Id 제거 및 훈련 데이터의 필요없는 column 제거\n",
        "  if \"Id\" in data.columns:\n",
        "    data.drop(['Id'], axis = 1 , inplace = True)\n",
        "  else:\n",
        "    data.drop(['Descript', 'Resolution'], axis = 1, inplace = True)\n",
        "\n",
        "  return data\n"
      ],
      "metadata": {
        "id": "5hOjOOxOYAKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('./train.csv')\n",
        "test = pd.read_csv('./test.csv')"
      ],
      "metadata": {
        "id": "eLD82Le_aXre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = feature_engineering(train)\n",
        "test = feature_engineering(test)"
      ],
      "metadata": {
        "id": "VjULGaDZZI2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape, test.shape"
      ],
      "metadata": {
        "id": "eCjGfJMbZTHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tree 모델을 사용하므로 별도의 스케일링을 하지 앟는다\n",
        "- 종속변수 PdDistrict에 Label Encoding을 진행한다"
      ],
      "metadata": {
        "id": "aMbxJBnPalW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "le1 = LabelEncoder()\n",
        "train['PdDistrict'] = le1.fit_transform(train['PdDistrict']) # fit은 훈련 데이터에 맞춘다\n",
        "test['PdDistrict'] = le1.transform(test['PdDistrict']) # 그래서 테스트는 transform만 한다"
      ],
      "metadata": {
        "id": "b9JL4hOhZYIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le2 = LabelEncoder()\n",
        "x = train.drop(columns = ['Category'])\n",
        "y = le2.fit_transform(train['Category'])\n"
      ],
      "metadata": {
        "id": "9RglQczVbIpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델링\n",
        "- 모델링 구현 과정 : Baseline 모델 구축 -> 최적의 파라미터 찾기 -> 그럼에도 성능이 개선되지 않는다면 다시 피처 엔지니어링 / 기존 변수를 재활용함\n",
        "- 이번 챕터는 GridSearchCV 를 통해 LightGBM, XGBoost, CatBoost 모형을 만듦"
      ],
      "metadata": {
        "id": "F1IkzZ4mbRlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 모델 구축\n",
        "import lightgbm as lgb\n",
        "\n",
        "train_set = lgb.Dataset(x, label = y, categorical_feature = ['PdDistrict'], free_raw_data = False)\n",
        "\n",
        "params = {'objective' : \"multiclass\",\n",
        "          'num_class' : 39}\n",
        "\n",
        "lgbm_b0 = lgb.train(params, train_set, num_boost_round =6)\n",
        "preds = lgbm_b0.predict(test)\n",
        "preds"
      ],
      "metadata": {
        "id": "w-4yKIFEbQqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본 구축 모델로 제출\n",
        "submission = pd.DataFrame(preds, columns = le2.classes_, index = test.index)\n",
        "submission.to_csv('LGBM_base_model.csv', index_label = \"Id\")"
      ],
      "metadata": {
        "id": "jUpptqlDbvAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle competitions submit -c sf-crime -f LGBM_base_model.csv -m 'BaseModel'"
      ],
      "metadata": {
        "id": "neKrYABxcHw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 검증 데이터 만들고 GridSearchCV로 확인하기"
      ],
      "metadata": {
        "id": "1O4AbWZQj_kv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "id": "TYE1i8xycbB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV : 대충 40분 이상 걸림\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMClassifier\n",
        "import timeit\n",
        "start_time = timeit.default_timer()\n",
        "params = {'max_depth' : [5, 7],\n",
        "          'min_child_weight' : [1, 3]}\n",
        "lgbm = LGBMClassifier(objective = \"multiclass\", num_class = 39)\n",
        "gridcv = GridSearchCV(estimator = lgbm,\n",
        "                      param_grid = params,\n",
        "                      n_jobs = -1,\n",
        "                      verbose = 10,\n",
        "                      cv = 2,\n",
        "                      refit = True)\n",
        "\n",
        "gridcv.fit(X_train, y_train, early_stopping_rounds = 5 , eval_set=[(X_train, y_train), (X_val, y_val)])\n",
        "\n",
        "gridcv_df = pd.DataFrame(gridcv.cv_results_)\n",
        "gridcv_df.loc[:, ['mean_test_score', 'params']]\n",
        "\n",
        "terminate_time = timeit.default_timer()\n",
        "print(terminate_time - start_time)"
      ],
      "metadata": {
        "id": "83HYahWFkP4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best parameter\n",
        "gridcv.best_params_"
      ],
      "metadata": {
        "id": "ViMWPKbIkM1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'max_depth' : 7,\n",
        "          'min_child_weight' : 1,\n",
        "          'num_leaves' : 300,\n",
        "          'objective' : 'multiclass',\n",
        "          'num_class' : 39,\n",
        "          'n_jobs' : -1}\n",
        "\n",
        "lgtrain, lgval = lgb.Dataset(X_train, y_train), lgb.Dataset(X_val, y_val)\n",
        "lgbmodel = lgb.train(params,\n",
        "                     lgtrain,\n",
        "                     num_boost_round = 100,\n",
        "                     valid_sets = [lgtrain, lgval],\n",
        "                     early_stopping_rounds = 10,\n",
        "                     verbose_eval = True)"
      ],
      "metadata": {
        "id": "tbw4eKNtlOi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = lgbmodel.predict(test)\n",
        "submission = pd.DataFrame(preds, columns = le2.classes_, index = test.index)\n",
        "submission.to_csv('LGBM_base_model.csv', index_label = \"Id\")"
      ],
      "metadata": {
        "id": "73kl0Q5-lOlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 처음부터 GPU 켜고 lightGBM 쓰면 됐잖아?\n",
        "- 관련 코드가 적혀 있는데 어떤 역할을 수행하는지 나와있지 않음"
      ],
      "metadata": {
        "id": "jtF9_zBCnpBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone -recursive https://github.com/Microsoft/LightGBM\n",
        "# %cd LightGBM\n",
        "# !mkdir build\n",
        "# !cmake-DUSE_GPU = 1\n",
        "# !makje-j$(nproc)\n",
        "# !sudo apt-get-y install python-pip\n",
        "# !sudo-H pip install setuptools pandas numpy scipy scikit-learn-U\n",
        "# %cd /content/LightGBM/python-package\n",
        "# !sudo python setup.py install\n",
        "# !pip3 uninstall scikit-learn\n",
        "# !pip3 install scikit-learn == 0.21.3"
      ],
      "metadata": {
        "id": "09BmFQuvlOn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 런타임 재시작 후 아래 코드 실행. 일단 위의 커맨드는 생략하고 GPU만 켜고 진행해봄\n",
        "import LightGBM as lgb\n",
        "\n",
        "train_set = lgb.Dataset(X, label = y, categorical_Feature = ['PdDistrict'], free_raw_data = False)\n",
        "\n",
        "params = {'objective' : 'multiclass',\n",
        "          'num_class' : 39,\n",
        "          'device' : 'gpu'}\n",
        "\n",
        "lgbm_b0 = lgb.train(params, train_set, num_boost_round = 0)"
      ],
      "metadata": {
        "id": "PaISe6s0lOqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost : RandomSearchCV까지 이용해봄"
      ],
      "metadata": {
        "id": "_lzkj8WgotYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import timeit\n",
        "start_time = timeit.default_timer()\n",
        "\n",
        "train_set = xgb.DMatrix(X, label = y)\n",
        "\n",
        "params = {\n",
        "    'objective' : 'multi:softprob'\n",
        "    'num_class' : 39\n",
        "}\n",
        "\n",
        "xgb_b0 = xgb.train(params, train_set, num_boost_round = 6)\n",
        "\n",
        "terminate_time = timeit.default_timer()\n",
        "print(terminate_time)\n",
        "\n",
        "test_xgb = xgb.DMatrix(test)\n",
        "preds = xgb_b0.predict(test_xgb)\n",
        "submission = pd.DataFrame(preds, columns = le2.classes_, index = test.index)\n",
        "submission.to_csv('XGBoost_base_model.csv', index_label = 'Id')"
      ],
      "metadata": {
        "id": "uYv9F8xTlOsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c sf-crime -f XGBoost_base_model.csv -m 'XGBoost_base_model'"
      ],
      "metadata": {
        "id": "2Vk3RAn9lOvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV 활용\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "start_time = timeit.default_timer()\n",
        "\n",
        "params = {'max_depth' : list(range(5, 7)),\n",
        "          'min_child_weight' : list(range(1, 3))\n",
        "          }\n",
        "\n",
        "xgboost = xgb.XGBClassifier(objective = 'multi:softprob',\n",
        "                            num_class = 39,\n",
        "                            eval_metric = 'mlogloss')\n",
        "\n",
        "randomcv = RandomizedSearchCV(estiamtor = xgboost,\n",
        "                              param_distributions = params,\n",
        "                              n_jobs = -1,\n",
        "                              verbose = 10,\n",
        "                              cv = 2,\n",
        "                              random_state = 42,\n",
        "                              refit = True)\n",
        "\n",
        "randomcv.fit(X_train, y_train, early_stopping_rounds = 5, eval_set=[(X_train, y_train), (X_val, y_val)])\n",
        "randomcv_df = pd.DataFrame(randomcv.cv_results_)\n",
        "randomcv_df.loc[: , ['mean_test_score', 'params']]\n",
        "\n",
        "terminate_time = timeit.default_timer()\n",
        "print(terminate_time - start_time)"
      ],
      "metadata": {
        "id": "7icIdOjSlOxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost는 LightGBM보다 학습 시간 소요가 많다 : 충분한 학습 시간을 가질 필요가 있음\n",
        "print(randomcv.best_params_)"
      ],
      "metadata": {
        "id": "gHYt9pUGqKqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 찾은 최적의 하이퍼파라미터 값으로 모델 다시 설계\n",
        "start_time = timeit.default_timer()\n",
        "\n",
        "params = {'max_depth' : 6,\n",
        "          'min_child_weight' : 1,\n",
        "          'num_leaves' : 300,\n",
        "          'objective' : 'multi:softprob',\n",
        "          'num_class' : 39,\n",
        "          'eval_metric' : 'mlogloss',\n",
        "          'n_jobs' : -1}\n",
        "\n",
        "xgbtrain, xgbval = xgb.DMatrix(X_train, y_train), xgb.DMatrix(X_val, y_val)\n",
        "xgb_final_model = xgb.train(params, xgbtrain, 100, evals = [(xgbtrain, 'train'), (xgbval, 'eval')],\n",
        "                            verbose_eval = 2)\n",
        "\n",
        "terminate_time = timeit.default_timer()\n",
        "print(terminate_time - start_time)"
      ],
      "metadata": {
        "id": "zFpzKpmdqKoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과 제출\n",
        "test_xgb = xgb.DMatrix(test)\n",
        "preds = xgb_final_model.predict(test_xgb)\n",
        "submission = pd.DataFrame(preds,\n",
        "                          columns = le2.classes_,\n",
        "                          index = test.index)\n",
        "submission.to_csv('XGBoost_final_model.csv', index_label = 'Id')"
      ],
      "metadata": {
        "id": "82xmlJAHqKmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c sf-crime -f XGBoost_final_model.csv -m 'XGBoost_Final_Model'"
      ],
      "metadata": {
        "id": "ysJ7pCadqKjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습시간은 LightGBM보다 많지만 스코어는 조금 더 나음\n",
        "# GPU를 쓰고 싶다면 파라미터에 Tree_Method, Gpu-Hist를 추가하면 됨\n",
        "  # 모든 파라미터가 GPU를 활용하는 것이 아니기 때문에 공식 홈페이지에서 확인하고 사용할 것"
      ],
      "metadata": {
        "id": "wDc4pfjsrcSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Catboost"
      ],
      "metadata": {
        "id": "yaBXIfKQrZvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩에선 catboost를 지원하지 않는다고 한다 : 설치해줌\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "dhT8nQPsqKa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CatBoost는 입력 데이터로 변환 시 Pool을 사용한다(XGBoost에서는 DMatrix를 썼다)\n",
        "from catboost import Pool, CatBoostClassifier\n",
        "\n",
        "train_pool = Pool(data = X, label = y, cat_features = ['PdDistrict'])\n",
        "cat_clf = CatBoostClassifier(iterations = 100, loss_function = 'MultiClass')\n",
        "\n",
        "cat_clf.fit(train_pool)"
      ],
      "metadata": {
        "id": "szKuhJafr15W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 후 예측값 뽑아서 제출\n",
        "preds = cat_clf.predict_proba(test)\n",
        "submission = pd.DataFrame(preds, columns = le2.classes_, index = test.index)\n",
        "submission.to_csv('CatBoost_base_model.csv', index_label = 'Id')"
      ],
      "metadata": {
        "id": "9oXQaqLer18A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c sf-crime -f XGBoost_final_model.csv -m \"CatBoostBaseModel\""
      ],
      "metadata": {
        "id": "xTs75z6Hr1_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적의 하이퍼파라미터 뽑기\n",
        "X_train, X_val, y_train, y_val = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "id": "rtrCnfQxr2BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timeit.default_timer()\n",
        "\n",
        "params= {'max_depth' : [5, 6],\n",
        "         'learning_rate' : [0.03, 0.1]}\n",
        "\n",
        "catboost = CatBoostClassifier(objective='MultiClass', iterations = 100)\n",
        "\n",
        "grid_cv = GridSearchCV(estimator = catboost,\n",
        "                       param_grid = params,\n",
        "                       cv = 2,\n",
        "                       refit = True)\n",
        "\n",
        "grid_cv.fit(X_train, y_train, early_stopping_rounds = 5, eval_set=[(X_train, y_train), (X_val, y_val)])\n",
        "grid_cv_df = pd.DataFrame(grid_cv.cv_results_)\n",
        "grid_cv_df.loc[:, ['mean_test_score', 'params']]\n",
        "\n",
        "terminate_time = timeit.default_timer()\n",
        "print(terminate_time - start_time)"
      ],
      "metadata": {
        "id": "8Vv5N4Slr2Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(grid_cv.best_params_)"
      ],
      "metadata": {
        "id": "yWex7wdfr2F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 대충 최고의 파라미터 집어넣기\n",
        "start_time = timeit.default_timer()\n",
        "params = {'max_depth' : 6,\n",
        "          'learning_rate' : 0.1,\n",
        "          'min_data_in_leaf' : 3,\n",
        "          'colsample_bylevel' : 0.8}\n",
        "\n",
        "catboost_final = CatBoostClassifier(obejctive = 'MultiClass', iterations = 100, **params)\n",
        "\n",
        "train_pool = Pool(data = X_train, label = y_train, cat_features = ['PdDistrict'])\n",
        "test_pool = Pool(data = X_val, label = y_val, cat_features = ['PdDistrict'])\n",
        "\n",
        "catboost_final.fit(train_pool, eval_set = test_pool)\n",
        "\n",
        "terminate_time = timeit.default_timer()\n",
        "print(terminate_time - start_time)"
      ],
      "metadata": {
        "id": "UPP1VTK4r2ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = catboost_final_evals_result_\n",
        "results['learn']['Multiclass'][0:10]"
      ],
      "metadata": {
        "id": "2bYzPBJAtyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['validation']['Multiclass'][0:10]"
      ],
      "metadata": {
        "id": "ARBq9TLatyQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그래프 작성\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = len(results['validation']['Multiclass'])\n",
        "x_axis = range(0, epochs)\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (10, 6))\n",
        "ax.plot(x_axis, results['learn']['Multiclass'], label = 'Train')\n",
        "ax.plot(x_axis, results['validation']['Multiclass'], label = 'Test')\n",
        "ax.legend()\n",
        "plt.ylabel(\"Log Loss\")\n",
        "plt.title('CatBoost Log Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sm8LTSxHtyTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 과적합 발생 시 모형 재학습 필요\n",
        "# 이 때 피쳐 엔지니어링부터 재시작하는 것이 좋음.\n",
        "# 필자의 경우 변수의 수를 10개 이하로 줄이려고 함 - 여기서 많은 시간이 투자됨\n",
        "# 간편한 방법은 L1, L2를 활용한 규제 및 Early_Stopping_rounds 파라미터를 활용함"
      ],
      "metadata": {
        "id": "3oUX05fjuVJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds =  catboost_final.predict_proba(test)\n",
        "submission = pd.DataFrame(preds,\n",
        "                          columns = le2.classes_,\n",
        "                          index = test_index)\n",
        "\n",
        "submission.to_csv('CatBoost_final_model.csv', index_label = 'Id')\n",
        "\n",
        "!kaggle competitions submit -c sf-crime -f CatBoost_final_model.csv -m \"CatBoost_Final_Model\""
      ],
      "metadata": {
        "id": "3g2cLSq9uhbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_BFbqBU1uheK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X8GJvT_iuhhL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}