{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c915bcef-107a-4890-a165-e3b3923080f4",
   "metadata": {},
   "source": [
    "# Ask & Tell Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583caf0f-e92b-4b42-acda-7ef23aee74bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. 최소한의 수정 문제에 Optuna 적용하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37641e06-4c46-406e-a6a3-d8d6d9243bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "X, y = make_classification(n_features = 10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "C = 0.01\n",
    "clf = LogisticRegression(C = C)\n",
    "clf.fit(X_train, y_train)\n",
    "val_accuracy = clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc1651f-fd92-4c56-bf5a-14dc62fe3750",
   "metadata": {},
   "source": [
    "- 이후 하이퍼파라미터를 C와 solver를 이용해 최적화하고 싶다면~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4daf6af3-2bb2-4b46-89a4-3ed3f54fd329",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 15:54:23,619]\u001b[0m A new study created in memory with name: no-name-85936349-b0a8-40c9-9b01-f3f1b9a8f74e\u001b[0m\n",
      "\u001b[32m[I 2022-12-12 15:54:23,636]\u001b[0m Trial 0 finished with value: 0.92 and parameters: {'C': 0.003038349854617212, 'solver': 'saga'}. Best is trial 0 with value: 0.92.\u001b[0m\n",
      "\u001b[32m[I 2022-12-12 15:54:23,651]\u001b[0m Trial 1 finished with value: 0.48 and parameters: {'C': 8.08989303264751e-05, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.92.\u001b[0m\n",
      "\u001b[32m[I 2022-12-12 15:54:23,661]\u001b[0m Trial 2 finished with value: 0.92 and parameters: {'C': 0.1745187608259836, 'solver': 'saga'}. Best is trial 0 with value: 0.92.\u001b[0m\n",
      "C:\\Users\\dowra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-12-12 15:54:23,676]\u001b[0m Trial 3 finished with value: 0.36 and parameters: {'C': 1.2248026201238313e-05, 'solver': 'saga'}. Best is trial 0 with value: 0.92.\u001b[0m\n",
      "\u001b[32m[I 2022-12-12 15:54:23,690]\u001b[0m Trial 4 finished with value: 0.88 and parameters: {'C': 0.00884740683530088, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.92.\u001b[0m\n",
      "\u001b[32m[I 2022-12-12 15:54:23,703]\u001b[0m Trial 5 finished with value: 0.96 and parameters: {'C': 2.307160262077729, 'solver': 'saga'}. Best is trial 5 with value: 0.96.\u001b[0m\n",
      "\u001b[32m[I 2022-12-12 15:54:23,715]\u001b[0m Trial 6 finished with value: 0.92 and parameters: {'C': 0.37464209442688146, 'solver': 'saga'}. Best is trial 5 with value: 0.96.\u001b[0m\n",
      "\u001b[32m[I 2022-12-12 15:54:23,730]\u001b[0m Trial 7 finished with value: 0.44 and parameters: {'C': 2.524637318443367e-05, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.96.\u001b[0m\n",
      "\u001b[32m[I 2022-12-12 15:54:23,749]\u001b[0m Trial 8 finished with value: 0.96 and parameters: {'C': 4.09420967583547, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.96.\u001b[0m\n",
      "\u001b[32m[I 2022-12-12 15:54:23,759]\u001b[0m Trial 9 finished with value: 0.56 and parameters: {'C': 0.0074212834546820835, 'solver': 'saga'}. Best is trial 5 with value: 0.96.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    X, y = make_classification(n_features = 10)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    C = trial.suggest_float(\"C\", 1e-7, 10.0, log = True)\n",
    "    solver = trial.suggest_categorical('solver', ('lbfgs', 'saga'))\n",
    "    \n",
    "    clf = LogisticRegression(C = C, solver = solver)\n",
    "    clf.fit(X_train, y_train)\n",
    "    val_accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    return val_accuracy\n",
    "\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd90913-d8a0-4443-b569-3c766863c22b",
   "metadata": {},
   "source": [
    "- 위 결과를 보면 요런 말이 있음\n",
    "```\n",
    "ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
    "```\n",
    "- `trial` 외에 `objective`가 추가적인 인수가 필요하다면 아예 class를 정의해야 함\n",
    "- 아래 예제는 위와 동일하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10f66efb-223e-4dd9-aa3f-3093139848b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 15:58:49,670]\u001b[0m A new study created in memory with name: no-name-39e9e81d-6a10-4093-a86e-b5f17e7dfcc2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = 'maximize')\n",
    "\n",
    "n_trials = 10\n",
    "\n",
    "for _ in range(n_trials):\n",
    "    trial = study.ask() # trial은 Trial임. FrozenTrial이 아님!\n",
    "    \n",
    "    C = trial.suggest_float(\"C\", 1e-7, 10.0, log = True)\n",
    "    solver = trial.suggest_categorical('solver', ('lbfgs', 'saga'))\n",
    "    \n",
    "    clf = LogisticRegression(C=C, solver = solver)\n",
    "    clf.fit(X_train, y_train)\n",
    "    val_accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    # tell 메서드를 이용해 trial과 objective_value를 같이 준다\n",
    "    study.tell(trial, val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b3140-9eda-4b9d-b918-a605a042ac45",
   "metadata": {},
   "source": [
    "- 다른점은 2가지임\n",
    "1. `optuna.study.Study.ask()` : 하이퍼파라미터를 샘플링하는 trial을 만듦\n",
    "2. `optuna.study.Study.tell()` : trial을 완료함. \n",
    "\n",
    "- 위 방법을 이용하면 `objective function` **없이 하이퍼파라미터 최적화를 이용할 수 있음**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37abdf40-b2b6-4c1c-9cfb-e43d5e537e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 16:05:06,950]\u001b[0m A new study created in memory with name: no-name-03f10ca1-7e4a-4879-b6ee-9b9467a1df03\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X, y = load_iris(return_X_y = True)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "classes = np.unique(y)\n",
    "n_train_iter = 100\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction = 'maximize',\n",
    "    pruner = optuna.pruners.HyperbandPruner(\n",
    "        min_resource = 1, max_resource = n_train_iter, reduction_factor = 3\n",
    "    )\n",
    ")\n",
    "\n",
    "for _ in range(20):\n",
    "    trial = study.ask()\n",
    "    \n",
    "    alpha = trial.suggest_float('alpha', 0.0, 1.0)\n",
    "    \n",
    "    clf = SGDClassifier(alpha = alpha)\n",
    "    pruned_trial = False\n",
    "    \n",
    "    for step in range(n_train_iter):\n",
    "        clf.partial_fit(X_train, y_train, classes = classes)\n",
    "        \n",
    "        intermediate_value = clf.score(X_valid, y_valid)\n",
    "        trial.report(intermediate_value, step)\n",
    "        \n",
    "        if trial.should_prune():\n",
    "            pruned_trial = True\n",
    "            break\n",
    "            \n",
    "    if pruned_trial:\n",
    "        study.tell(trial, state = optuna.trial.TrialState.PRUNED)\n",
    "    else:\n",
    "        score = clf.score(X_valid, y_valid)\n",
    "        study.tell(trial, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc687520-6e10-4e94-8a36-9682bf4ad4ef",
   "metadata": {},
   "source": [
    "- `optuna.study.Study.tell()` 메서드는 `trial` 객체보다 더 많은 수를 가질 수 있다. \n",
    "- `study.tell(trial.number, y)` = `study.tell(trial, y)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cece152-fd33-4908-b07f-04e3941e1329",
   "metadata": {},
   "source": [
    "## Define and Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a259ccb-8480-490c-863a-8462229fc134",
   "metadata": {},
   "source": [
    "- 하이퍼파라미터의 분포를 `ask()`를 호출하기 전에 정의할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca5c541f-ab47-46d1-9c03-20318341837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = {\n",
    "    'C' : optuna.distributions.FloatDistribution(1e-7, 10.0, log = True),\n",
    "    'solver' : optuna.distributions.CategoricalDistribution(('lbfgs', 'saga')),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e343e87c-f1b6-4e16-a339-e52a538c6752",
   "metadata": {},
   "source": [
    "`distributions`을  `optuna.study.Study.ask()`에 통과시켜보자\n",
    "- 위에서는 `study.ask()` 를 정의한 다음 `suggest`를 이용했다면, 여기서는 하이퍼파라미터의 범위를 `dict`로 정의한 다음 `ask()` 내에 통과시켜줬음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "370df54e-a608-4651-bd7f-32da585ff32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64660cd8-f248-4188-9d5b-a272cde3b64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 16:13:32,741]\u001b[0m A new study created in memory with name: no-name-35c1455c-6ab5-4c60-acba-57c6d665037b\u001b[0m\n",
      "C:\\Users\\dowra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dowra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dowra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dowra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\dowra\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction = 'maximize')\n",
    "n_trials = 10\n",
    "\n",
    "for _ in range(n_trials):\n",
    "    trial = study.ask(distributions)\n",
    "    \n",
    "    # 사전에 분포를 정의했기 떄문에 `ask()`를 통해 안에 파라미터로 들어가 있음\n",
    "    C = trial.params['C']\n",
    "    solver = trial.params['solver']\n",
    "    \n",
    "    clf = LogisticRegression(C = C, solver = solver)\n",
    "    clf.fit(X_train, y_train)\n",
    "    val_accuracy = clf.score(X_test, y_test)\n",
    "    \n",
    "    study.tell(trial, val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3338548-945d-4ff3-b716-af88d78fec55",
   "metadata": {},
   "source": [
    "## Batch Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e9698-317f-438b-bd8c-f829914f00b4",
   "metadata": {},
   "source": [
    "- Ask and Tell 인터페이스를 이용하면 일괄 처리된 목표를 더 빠르게 최적화할 수 있다\n",
    "- 병렬화 가능한 평가, 벡터 작업 등\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f5c4f29-be19-4e47-b4f6-49470babf012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_objective(xs: np.ndarray, ys: np.ndarray):\n",
    "    return xs ** 2 + ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec659edf-0343-46af-bbf3-3c2f92ad2ca0",
   "metadata": {},
   "source": [
    "- 아래 예제에서 batch의 하이퍼파라미터 쌍 갯수는 10개이고, `batched_objective`는 3번 평가된다. 따라서 총 trial 수는 30개이다.\n",
    "- batch 평가 후 `trial_numbers`나 `trial`을 저장하려면 `optuna.study.Study.tell()`메서드를 호출해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff0be13d-d22a-41e7-828b-d90a171c0248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-12 16:20:27,950]\u001b[0m A new study created in memory with name: no-name-690b1afd-b3fa-4f62-a62d-14ddf8712e17\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "study = optuna.create_study(sampler = optuna.samplers.CmaEsSampler())\n",
    "\n",
    "for _ in range(3): # 각각이 1개의 batch\n",
    "    trial_numbers = []\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    \n",
    "    for _ in range(batch_size):\n",
    "\n",
    "        trial = study.ask()\n",
    "        trial_numbers.append(trial.number)\n",
    "        x_batch.append(trial.suggest_float('x', -10, 10))\n",
    "        y_batch.append(trial.suggest_float('y', -10, 10))\n",
    "        \n",
    "    x_batch = np.array(x_batch)\n",
    "    y_batch = np.array(y_batch)\n",
    "    objectives = batched_objective(x_batch, y_batch)\n",
    "    \n",
    "    for trial_number, objective in zip(trial_numbers, objectives):\n",
    "        study.tell(trial_number, objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5bfa71-ef54-4290-bf7d-8ce2db25f4ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
