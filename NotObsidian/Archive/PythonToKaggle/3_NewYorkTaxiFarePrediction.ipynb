{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_NewYorkTaxiFarePrediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPixbr9JsovTxgYer/bNWOQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dowrave/PythonToKaggle/blob/main/3_NewYorkTaxiFarePrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdjDGodXA77j"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle/\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c new-york-city-taxi-fare-prediction # 아니 ㄹㅇ 책이 검수가 덜 됨\n",
        "!unzip new-york-city-taxi-fare-prediction.zip"
      ],
      "metadata": {
        "id": "bjKCHtHYIIyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 파일 크기 확인 함수\n",
        "import os\n",
        "def convert_bytes(file_path, unit = None):\n",
        "  size = os.path.getsize(file_path)\n",
        "  if unit == \"KB\":\n",
        "    return print(\"File size :\" , str(round(size/1024, 3)), \"KB\")\n",
        "  elif unit == \"MB\":\n",
        "    return print(\"File size :\" , str(round(size/1024**2, 3)), \"MB\")\n",
        "  elif unit == \"GB\":\n",
        "    return print(\"File size :\" , str(round(size/1024**3, 3)), \"GB\")\n",
        "  else:\n",
        "    return print(\"File size :\" , str(size/1024), \"Bytes\")\n",
        "\n",
        "  \n",
        "file_path = 'train.csv'\n",
        "convert_bytes(file_path)\n",
        "convert_bytes(file_path, 'GB')"
      ],
      "metadata": {
        "id": "Ynec7fQbIbP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def skip_logic(index, skip_num):\n",
        "  if index % skip_num == 0:\n",
        "    return False\n",
        "  return True \n",
        "\n",
        "# 이 과정은 한나절 걸림. 6gb이기 때문.\n",
        "train = pd.read_csv('train.csv', skiprows = lambda x: skip_logic(x, 4), parse_dates = ['pickup_datetime'])\n",
        "print(train.shape)\n",
        "test = pd.read_csv('./test.csv')\n",
        "submission = pd.read_csv('./sample_submission.csv')"
      ],
      "metadata": {
        "id": "N5al0l2IIgJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 지도 학습에서 가장 먼저 시각화 할 것은 종속 변수 Y이다\n",
        "- 수치 데이터라면 정규 분포를 이루는지 확인하는 것이 기초 통계의 여러 통계 모델을 적용할 때 매우 중요하기 때문.\n"
      ],
      "metadata": {
        "id": "Qg9qjxMHL9kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.info, '-' * 30, test.info)"
      ],
      "metadata": {
        "id": "zTxXghOnKm7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "LGWR1-qYL8r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.describe() # fare_amount 값은 음수가 나올 수 없는 값임 - 음수가 나온 데이터는 신뢰할 수 없는 데이터이니 삭제하는 게 좋음"
      ],
      "metadata": {
        "id": "jzwl5-x9L8t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.describe()"
      ],
      "metadata": {
        "id": "xJeyTiYoL8wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(train['fare_amount'] < 0)"
      ],
      "metadata": {
        "id": "oir2Elk6L8yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 음수의 개수 확인하기\n",
        "from collections import Counter\n",
        "Counter(train['fare_amount'] < 0 ) # 조건을 만족하는 값은 True에, 아니면 False에 들어간다"
      ],
      "metadata": {
        "id": "msHrSTx7L81F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 음수 데이터 삭제\n",
        "train = train.drop(train[train['fare_amount'] < 0].index, axis = 0).reset_index(drop = True)\n",
        "Counter(train['fare_amount'] < 0 )"
      ],
      "metadata": {
        "id": "ualr96DOL83e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그 외에도 지나치게 높은 값 (가령 최댓값은 9만 달러가 넘음 : 전산 오류인지 실제인지 알 도리가 없음) 제거\n",
        "train = train.drop(train[train['fare_amount'] > 500].index, axis = 0 ).reset_index(drop = True)\n",
        "print(train['fare_amount'].min())\n",
        "print(train['fare_amount'].max())"
      ],
      "metadata": {
        "id": "YP4GienoKRfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터가 1천만 개 정도 되므로, 모든 데이터에 대해 시각화 작업을 진행하는 것은 비용적인 측면에서 나쁘다\n",
        "# 따라서 Stratified Sampling을 진행한다.\n",
        "train['passenger_count'].unique()"
      ],
      "metadata": {
        "id": "jRHCe2owKtQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 택시를 타는데 208, 0, 129, 51, 6, 8, 9 등의 값은 이상함(물론 6까지는 택시 자체가 특수한 종류의 차였을 수도 있겠다고 할 수는 있다)\n",
        "# 어쨌든 책에서는 6을 초과하는 데이터는 제거함\n",
        "train = train.drop(train[train['passenger_count'] > 6].index, axis = 0).reset_index(drop = True)\n",
        "train['passenger_count'].unique()"
      ],
      "metadata": {
        "id": "RiEAVcJJLIOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0도 그냥 같이 제거하지;\n",
        "train = train.drop(train[train['passenger_count']  == 0].index, axis = 0).reset_index(drop = True)\n",
        "train['passenger_count'].unique()"
      ],
      "metadata": {
        "id": "CHP3uy__LkBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Passenger_Count의 비율 확인하기 (비율은 value_counts에 normalize = True 를 전달해서 만들 수 있다)\n",
        "train['passenger_count'].value_counts(\n",
        "    normalize = True\n",
        "    ) "
      ],
      "metadata": {
        "id": "pI-0RlnNLv7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "\"\"\" Stratified 예제임 실제 코드 실행과는 관련 없는 부분\"\"\"\n",
        "# sample = pd.DataFrame({'group' : np.repeat(['A', 'B', 'C'], (60, 40, 20)),\n",
        "#                        'sample_value' : np.random.randn(120)})\n",
        "\n",
        "# split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.7, random_state = 42)\n",
        "\n",
        "# # strat_train_set = []\n",
        "# # test_set = []\n",
        "\n",
        "# for train_idx, test_idx in split.split(sample, sample['group']):\n",
        "#   # 여기서 선언됐는데 잘 작동하네?\n",
        "#   strata_train_set = sample.loc[train_idx]\n",
        "#   test_set = sample.loc[test_idx]\n",
        "\n",
        "# print(sample['group'].value_counts(normalize = True))\n",
        "# print(sample.shape)\n",
        "# print('-' * 40)\n",
        "# print(strata_train_set['group'].value_counts(normalize = True))\n",
        "# print(strata_train_set.shape)"
      ],
      "metadata": {
        "id": "3oDLaaIKL5j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 본 데이터에 적용 : 전체 표본의 0.1%의 데이터만 선택\n",
        "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.001, random_state = 42)\n",
        "\n",
        "\n",
        "for large_index, sample_index in split.split(train, train['passenger_count']):\n",
        "  large_df = train.loc[large_index]\n",
        "  sample_df = train.loc[sample_index]\n",
        "\n",
        "print(train['passenger_count'].value_counts(normalize = True), train.shape)\n",
        "print('-' * 40)\n",
        "print(sample_df['passenger_count'].value_counts(normalize = True), sample_df.shape)"
      ],
      "metadata": {
        "id": "oS4b2pekMvH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.hist(sample_df['fare_amount'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IW6noeaxN3NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 그래프 해석 : 전형적인 왜도의 그래프. 0 ~ 25 $ 구간이 가장 많은 비율을 보인다\n",
        "- 이런 데이터의 특성은 피쳐 엔지니어링 진행 시 로그 변환을 진행한다"
      ],
      "metadata": {
        "id": "aMWNMe5IOMtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 위도, 경도 파악하기"
      ],
      "metadata": {
        "id": "32sGn9mUOV5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(train['pickup_latitude'] < -90)"
      ],
      "metadata": {
        "id": "OautsMzbOF61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Counter(train['pickup_latitude'] > 90)"
      ],
      "metadata": {
        "id": "1j_aGwsMObWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위도의 범위는 -90 ~ 90, 경도의 범위는 -180 ~ 180이다. 이외의 값은 모두 제거해주자.\n",
        "train = train.drop(train[train['dropoff_latitude'] < - 90 ].index, axis = 0).reset_index(drop = True)\n",
        "train = train.drop(train[train['dropoff_latitude'] > 90 ].index, axis = 0).reset_index(drop = True)\n",
        "train = train.drop(train[train['pickup_longitude'] < - 180].index, axis = 0).reset_index(drop = True)\n",
        "train = train.drop(train[train['pickup_longitude'] > 180 ].index, axis = 0).reset_index(drop = True)\n",
        "train = train.drop(train[train['dropoff_longitude'] < - 180 ].index, axis = 0).reset_index(drop = True)\n",
        "train = train.drop(train[train['dropoff_longitude'] > 180 ].index, axis = 0).reset_index(drop = True)\n",
        "\n",
        "train.shape"
      ],
      "metadata": {
        "id": "IkOHJb6TOjpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "rZO0lGKzRAJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.iloc[:3 , 0] # object이므로 date time으로 바꿔주자\n",
        "# 책과 달리 pickup_datetime은 datetime으로 저장되어 있음\n",
        "pd.to_datetime(train['key'], format = '%Y-%m-%d %H:%M:%S')\n"
      ],
      "metadata": {
        "id": "J6RN1kIARRLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split = StratifiedShuffleSplit(n_splits = 1, test_size = 0.001, random_state = 42) \n",
        "for large_index, sample_index in split.split(train, train['passenger_count']):\n",
        "  print(len(sample_index))\n",
        "  large_df = train.loc[large_index]\n",
        "  sample_df = train.loc[sample_index] "
      ],
      "metadata": {
        "id": "mpf4Q7GdRgxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(large_df.shape)\n",
        "print(sample_df.shape)"
      ],
      "metadata": {
        "id": "bQaA79wuWKfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위도, 경도를 가져오면 지도 위에 시각화를 할 수 있다.\n",
        "# folium으로 가능하지만 여기서는 matplotlib을 통해 이미지 위에 점을 그릴 것\n",
        "\n",
        "Bounding_Box = (-74.5, -72.8, 40.5, 41.8)\n",
        "Bounding_Box_Zoom = (-74.3, -73.7, 40.5, 40.9)\n",
        "\n",
        "# 지도의 범위 내에 있는 데이터만 추리는 함수\n",
        "def select_within_boundingbox(data, BB):\n",
        "  return (data.pickup_longitude >= BB[0]) & (data.pickup_longitude <= BB[1]) & \\\n",
        "        (data.pickup_latitude >= BB[2]) & (data.pickup_latitude <= BB[3]) & \\\n",
        "        (data.dropoff_longitude >= BB[0]) & (data.dropoff_longitude <= BB[1]) & \\\n",
        "        (data.dropoff_latitude >= BB[2]) & (data.dropoff_latitude <= BB[3])"
      ],
      "metadata": {
        "id": "8mtPxcg1Sjds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Old Size : %d\"%len(sample_df))\n",
        "sample_df = sample_df[select_within_boundingbox(sample_df, Bounding_Box)]\n",
        "print(\"New Size : %d\"%len(sample_df))"
      ],
      "metadata": {
        "id": "oXHWE4SgT-DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 불러오기\n",
        "import ssl\n",
        "from urllib.request import urlopen\n",
        "context = ssl._create_unverified_context() # 웹 크롤링 시 자주 활용되는 함수\n",
        "\n",
        "Bounding_Box = (-74.5, -72.8, 40.5, 41.8)\n",
        "NYC_MAP_img_path = \"https://aiblog.nl/download/nyc_-74.5_-72.8_40.5_41.8.png\"\n",
        "NYC_MAP = urlopen(NYC_MAP_img_path, context = context)\n",
        "nyc_map = plt.imread(NYC_MAP)\n",
        "\n",
        "\n",
        "Bounding_Box_Zoom = (-74.3, -73.7, 40.5, 40.9)\n",
        "NYC_MAP_ZOOM_img_path = \"https://aiblog.nl/download/nyc_-74.3_-73.7_40.5_40.9.png\"\n",
        "NYC_MAP_ZOOM = urlopen(NYC_MAP_ZOOM_img_path, context = context)\n",
        "nyc_map_zoom = plt.imread(NYC_MAP_ZOOM)"
      ],
      "metadata": {
        "id": "KJSY04NkUc9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize = (16, 10))\n",
        "ax[0].imshow(nyc_map, zorder=0 ,extent = Bounding_Box)\n",
        "ax[0].set_title(\"NY Map\")\n",
        "\n",
        "ax[1].imshow(nyc_map_zoom, zorder = 0, extent = Bounding_Box_Zoom)\n",
        "ax[1].set_title(\"NY Map Zoom\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d6plpA9YZzXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위에 산점도 그리기\n",
        "def scatter_plot_on_map(df, BB, nyc_map, s=10, alpha = 0.2):\n",
        "  fig,ax = plt.subplots(1, 2, figsize=(16,10))\n",
        "\n",
        "  # Scatter 1\n",
        "  ax[0].scatter(df.pickup_longitude, df.pickup_latitude, zorder = 1, alpha = alpha, c = 'r', s = s)\n",
        "  ax[0].set_xlim(BB[0], BB[1])\n",
        "  ax[0].set_ylim(BB[2], BB[3])\n",
        "  ax[0].set_title('Pickup Locations')\n",
        "  ax[0].imshow(nyc_map, zorder=0, extent = BB)\n",
        "\n",
        "  # Scatter 2\n",
        "  ax[1].scatter(df.dropoff_longitude, df.dropoff_latitude, zorder = 1, alpha = alpha, c = 'r', s = s)\n",
        "  ax[1].set_xlim(BB[0], BB[1])\n",
        "  ax[1].set_ylim(BB[2], BB[3])\n",
        "  ax[1].set_title('Dropoff Locations')\n",
        "  ax[1].imshow(nyc_map, zorder=0, extent = BB)\n",
        "\n",
        "scatter_plot_on_map(sample_df, Bounding_Box, nyc_map, s=1, alpha = 0.3)"
      ],
      "metadata": {
        "id": "rI-EvvgnaHqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scatter_plot_on_map(sample_df, Bounding_Box_Zoom, nyc_map, s=1, alpha = 0.3)\n"
      ],
      "metadata": {
        "id": "j3KqtSeYa_-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 날짜 데이터 빼내기\n",
        "sample_df['Year'] = sample_df['pickup_datetime'].dt.year\n",
        "sample_df['Month'] = sample_df['pickup_datetime'].dt.month\n",
        "sample_df['Date'] = sample_df['pickup_datetime'].dt.day\n",
        "sample_df['Day of Week'] = sample_df['pickup_datetime'].dt.dayofweek # 0 : 월 ~ 6 : 일\n",
        "sample_df['Hour'] = sample_df['pickup_datetime'].dt.hour\n",
        "print(sample_df.iloc[:, 8:])"
      ],
      "metadata": {
        "id": "7Y1cR9GPbTm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_df.head()"
      ],
      "metadata": {
        "id": "Ey-m0bGycsv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2, 1, figsize=(10,6))\n",
        "sns.histplot(sample_df['Day of Week'], ax= ax[0])\n",
        "ax[0].set_xlabel(\"Day of Week\")\n",
        "ax[0].set_ylabel(\"Count\")\n",
        "\n",
        "sns.boxplot(x='Day of Week', y='fare_amount', data = sample_df, ax = ax[1])\n",
        "ax[1].set_xlabel('Day of Week')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q4OTh3HvbrX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 목, 금, 토에 이용객이 많음\n",
        "- 아래 BoxPlot의 경우 log scale로 변환하면 더 쉽게 비교할 수 있으나 책에서는 생략되었음"
      ],
      "metadata": {
        "id": "5TvOyT0adgey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 시간대별 금액 확인"
      ],
      "metadata": {
        "id": "4yRn5JildpZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
        "sns.barplot(x='Hour', y='fare_amount', data = sample_df, \n",
        "            estimator = sum, ax = ax[0]) # 디폴트 값은 mean임\n",
        "ax[0].set_xlabel('Hours')\n",
        "ax[0].set_ylabel('Sum : Fare Amount $')\n",
        "\n",
        "sns.barplot(x='Hour', y='fare_amount', data = sample_df, \n",
        "            ax = ax[1]) \n",
        "ax[1].set_xlabel('Hours')\n",
        "ax[1].set_ylabel('Mean : Fare Amount $')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g9rAQLZmcC7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 피쳐 엔지니어링\n",
        "- 위에서 한 과정 요약해서 함수로 만듦 "
      ],
      "metadata": {
        "id": "5ZQGavCJfd0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def skip_logic(index, skip_num):\n",
        "  if index % skip_num == 0:\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "train = pd.read_csv('./train.csv', skiprows = lambda x: skip_logic(x, 1000))\n",
        "print(train.shape)\n",
        "test = pd.read_csv('./test.csv')\n",
        "submission = pd.read_csv('./sample_submission.csv')"
      ],
      "metadata": {
        "id": "SnCCisSbdy7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위도, 경도의 최소 / 최댓값은 그냥 이걸로 확인하고 넘길게요~\n",
        "test.describe()"
      ],
      "metadata": {
        "id": "6PndwOLvfAX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(data):\n",
        "  print(\"old data shape : \", data.shape)\n",
        "\n",
        "  # 결측치 처리\n",
        "  data = data.drop(data[data.isnull().any(1)].index, axis = 0)\n",
        "\n",
        "  # 이상치 처리\n",
        "  if 'fare_amount' in data.columns: # 테스트 데이터에는 fare_amount 가 없다\n",
        "    data = data.drop(data[data['fare_amount'] < 0].index, axis = 0 ).reset_index(drop = True)\n",
        "    data = data.drop(data[data['fare_amount'] > 500].index, axis = 0).reset_index(drop = True)\n",
        "\n",
        "  # 지도의 범위를 넘어간다면 데이터 제거\n",
        "  boundary = {'min_lng' : -74.26342, 'min_lat' : 40.573143, 'max_lng' : -72.986532, 'max_lat' : 41.709555}\n",
        "\n",
        "  # ~는 Not을 의미함 : 조건을 모두 만족한다면 0, 하나라도 삐끗하면 1임\n",
        "\n",
        "  data.loc[~((data.pickup_longitude >= boundary['min_lng']) & (data.pickup_longitude <= boundary['max_lng']) &\n",
        "             (data.pickup_latitude >= boundary['min_lat']) & (data.pickup_latitude <= boundary['max_lat']) &\n",
        "             (data.dropoff_longitude >= boundary['min_lng']) & (data.dropoff_longitude <= boundary['max_lng']) &\n",
        "             (data.dropoff_latitude >= boundary['min_lat']) & (data.dropoff_latitude <= boundary['max_lat'])), 'is_beyond_NY'] = 1\n",
        "\n",
        "  data.loc[((data.pickup_longitude >= boundary['min_lng']) & (data.pickup_longitude <= boundary['max_lng']) &\n",
        "             (data.pickup_latitude >= boundary['min_lat']) & (data.pickup_latitude <= boundary['max_lat']) &\n",
        "             (data.dropoff_longitude >= boundary['min_lng']) & (data.dropoff_longitude <= boundary['max_lng']) &\n",
        "             (data.dropoff_latitude >= boundary['min_lat']) & (data.dropoff_latitude <= boundary['max_lat'])), 'is_beyond_NY'] = 0\n",
        "\n",
        "  print(data['is_beyond_NY'].value_counts())\n",
        "\n",
        "  data = data.drop(data[data['passenger_count'] == 1].index, axis = 0 ).reset_index(drop = True)\n",
        "  data.drop(['is_beyond_NY'], axis = 1 , inplace = True)\n",
        "  data = data.drop(data[data['passenger_count'] > 6].index, axis = 0 ).reset_index(drop = True)\n",
        "  data = data.drop(data[data['passenger_count'] == 0].index, axis = 0 ).reset_index(drop = True)\n",
        "  data['pickup_datetime'] = pd.to_datetime(data['pickup_datetime'], format = '%Y-%m-%d %H:%M:%S UTC')\n",
        "\n",
        "  # 날짜에서 변수 뽑아내기\n",
        "  data['year'] = data['pickup_datetime'].dt.year\n",
        "  data['month'] = data['pickup_datetime'].dt.month\n",
        "  data['date'] = data['pickup_datetime'].dt.day\n",
        "  data['day_of_week'] = data['pickup_datetime'].dt.dayofweek\n",
        "  data['hour'] = data['pickup_datetime'].dt.hour\n",
        "\n",
        "  # 변수 제거\n",
        "  data.drop(['key', 'pickup_datetime'], axis = 1, inplace = True)\n",
        "\n",
        "  print(\"new data shape : \", data.shape)\n",
        "\n",
        "  return data\n",
        "\n",
        "new_train = preprocessing(train)\n",
        "new_train"
      ],
      "metadata": {
        "id": "fGsLTcbFfaOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제점!\n",
        "- 이 지역에 대한 배경 도메인이 없는 경우 특징 추출을 어떻게 할 것인가?\n",
        "  - 이 경우, 위도와 경도에 대한 지식을 거리로 통합해버림\n",
        "  - 근데 위도와 경도를 거리로 어떻게 통합하느냐?\n",
        "    - 아크하버사인(Arcsin)이라는 공식이 있음. 파이썬엔 haversine이라는 라이브러리 구현됨 (코랩에 없기 때문에 인스톨해야함)"
      ],
      "metadata": {
        "id": "XJoUA-aUjVA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install haversine"
      ],
      "metadata": {
        "id": "32eDjIV0iS0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 : 서울 - 부산 간의 거리\n",
        "from haversine import haversine, Unit \n",
        "seoul = (37.532700, 127.024612)\n",
        "busan = (35.114839, 129.041494)\n",
        "\n",
        "haversine(seoul, busan)"
      ],
      "metadata": {
        "id": "gn3VgWpFjttN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 본 데이터에 적용 : Pandas 내부 변수를 list로 변환한 뒤에 반복문을 적용해 하나씩 계산함\n",
        "# ? : numpy로 하면 안되나?\n",
        "distances = []\n",
        "pick_lon = new_train['pickup_longitude'].tolist()\n",
        "pick_lat = new_train['pickup_latitude'].tolist()\n",
        "drop_lon = new_train['dropoff_longitude'].tolist()\n",
        "drop_lat = new_train['dropoff_latitude'].tolist()\n",
        "\n",
        "for row in range(len(new_train)):\n",
        "  dist = haversine((pick_lat[row], pick_lon[row]), (drop_lat[row], drop_lon[row]))\n",
        "  distances.append(dist)\n",
        "\n",
        "new_train['distance'] = distances\n",
        "print(new_train[['fare_amount', 'distance', 'passenger_count']])"
      ],
      "metadata": {
        "id": "nmtOm_YJj_Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 물론 이 값들은 직선 거리라서 실제 거리는 조금 더 길겠지만 데이터에서는 실제 주행거리를 제공하지 않기 때문에 이 정도가 한계임\n",
        "# 사용된 위도, 경도 값을 제거\n",
        "new_train.drop(['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'], axis = 1, inplace = True)\n",
        "new_train.info()"
      ],
      "metadata": {
        "id": "yHu3jJ7jknx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 추가로 진행되어야 하는 과정들이지만 여기선 생략됨:\n",
        "  - 수치형 데이터의 로그 변환, 표준화 / 정규화\n",
        "  - day_of_week은 문자열데이터로 취급되어야 함(Categories?)\n",
        "  - Label Encoding, One-Hot Encoding 등도 필요\n",
        "  - [중요 : 도메인]\n",
        "    - 택시가 가장 많이 활용되는 지역을 찾아서 피처 엔지니어링(캐글 노트북 에제 중에는 공항과 연계된 피쳐 엔지니어링이 있는 노트북을 찾을 수 있음)\n"
      ],
      "metadata": {
        "id": "1WzthLd9lO04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델링"
      ],
      "metadata": {
        "id": "etdszcxFlnBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 저자는 초보자에게 하이퍼파라미터 튜닝을 권하지 않음\n",
        "- 투입 대비 결과물의 향상이 그렇게 높지 않을 확률이 높음\n",
        "- 따라서 하이퍼파라미터 튜닝이 필요하다면, 캐글 그마 같은 사람들의 파라미터를 갖다 쓰는 것과 같이 효율적인 측면을 고려하는 게 더 중요할 수도 있음\n",
        "- 하이퍼파라미터에 대한 논문 등을 읽어서 이론적 배경을 쌓는 것도 매우 훌륭한 공부일 수 있다"
      ],
      "metadata": {
        "id": "uwOI2SFNmNqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 또한 하이퍼파라미터 튜닝을 맹신하면 생길 수 있는 문제점으로, 검증 세트에 대한 과적합이 있음\n",
        "- 캐글에서 모덷 평가는 미지의 데이터가 그 대상임(실제로 2021년 2월에 종료된 Competition의 제출일은 2.22이지만 실제 예측 구간에 해당하는 날짜는 8.23임\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sNs7JVucmkQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 하이퍼파라미터의 의미와 최적의 하이퍼파라미터 찾기"
      ],
      "metadata": {
        "id": "NsEl-cesm4wU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tree : Graphviz 패키지"
      ],
      "metadata": {
        "id": "dnaCpL2fm77u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "import graphviz\n",
        "\n",
        "iris = load_iris()\n",
        "X_features = iris.data\n",
        "y_target = iris.target\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X_features, y_target)\n",
        "dot_data = tree.export_graphviz(clf, out_file = None,\n",
        "                                feature_names = iris.feature_names,\n",
        "                                class_names = iris.target_names, filled = True,\n",
        "                                rounded = True, special_characters = True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "metadata": {
        "id": "wNe9jPxdlAUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clf 파라미터 출력\n",
        "print(clf)"
      ],
      "metadata": {
        "id": "P7tIeC0-nVVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 트리 모델에서 Max_depth만 수정한 뒤 다시 실행\n",
        "clf = tree.DecisionTreeClassifier(max_depth = 2)\n",
        "clf = clf.fit(X_features, y_target)\n",
        "dot_data = tree.export_graphviz(clf, out_file = None,\n",
        "                                feature_names = iris.feature_names,\n",
        "                                class_names = iris.target_names, filled = True,\n",
        "                                rounded = True, special_characters = True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "metadata": {
        "id": "-JdwH4mnnct0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 그리드 서치 vs 랜덤 서치\n",
        "- 랜덤 서치는 같은 비용으로 더 많은 탐색을 할 수 있다는 장점이 있다"
      ],
      "metadata": {
        "id": "ov7dJgRZtHuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import pandas as pd\n",
        "\n",
        "iris_data = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 42\n",
        "                                                    )\n",
        "\n",
        "# GridSearchCV\n",
        "tree = DecisionTreeClassifier()\n",
        "grid_serach_params = {'max_depth' : [1, 2],\n",
        "                      'max_features' : [1, 2]}\n",
        "grid_tree = GridSearchCV(tree, param_grid = grid_serach_params, cv = 5)\n",
        "grid_tree.fit(X_train, y_train)\n",
        "scores = pd.DataFrame(grid_tree.cv_results_)\n",
        "scores[['params', 'mean_test_score', 'rank_test_score']]\n"
      ],
      "metadata": {
        "id": "9seV1DNIr6ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "random_search_params = {'max_depth' : randint(1, 4),\n",
        "                        'max_features' : randint(1, 4)}\n",
        "\n",
        "random_tree = RandomizedSearchCV(tree, random_search_params, cv = 5)\n",
        "random_tree.fit(X_train, y_train)\n",
        "\n",
        "scores = pd.DataFrame(random_tree.cv_results_)\n",
        "scores[['params', 'mean_test_score', 'rank_test_score']]"
      ],
      "metadata": {
        "id": "vIsrp4Yjtz_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 본 데이터에 적용\n",
        "- XGBoost에는 Python API와 sklearn aPI가 같이 존재함. 그래서 같은 파라미터 이름도 다르게 쓰이는 경우가 종종 있음\n",
        "  - ex) 학습률 : eta vs learning rate\n",
        "    - 최소 손실(leaf 노드 추가로 나눌지 여부를 결정하는 값: 감마) - gamma vs Min_Split_Loss\n",
        "    - 샘플링 비율 : Sub_Sample, Subsample\n",
        "- 이는 LightGBM도 비슷함"
      ],
      "metadata": {
        "id": "tGsrcwTjvCOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 따라서 사이킷런을 적용하느냐 독자적인 모듈을 쓸 거냐를 정하고 시작해야 하며\n",
        "### 본문에서는 사이킷런을 적용함"
      ],
      "metadata": {
        "id": "KbsQJYI9va2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_train.info()"
      ],
      "metadata": {
        "id": "OBj68ggz3ONx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from math import sqrt \n",
        "import time\n",
        "import datetime\n",
        "\n",
        "y = new_train['fare_amount']\n",
        "new_train.drop(['fare_amount'], axis = 1, inplace = True)\n",
        "X = new_train\n",
        "X.shape, y.shape"
      ],
      "metadata": {
        "id": "f92k9IMxudoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 123)\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "id": "Wv2z0t1yvw04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost 파라미터 적용\n",
        "params = {\"max_depth\" : 5,\n",
        "          'learning_rate' : 0.5,\n",
        "          'objective' : 'reg:linear', # 회귀 : 'reg:linear' / 이진 분류 : 'binary:logisitic' / 'multi:softmax' (개별 분류값 바로 확인) / 'multi : softprob' (개별)\n",
        "          'eval_metric' : 'rmse',\n",
        "          'early_stopping_rounds' : 5\n",
        "          }\n",
        "xgb_model = xgb.XGBRegressor(**params)\n",
        "print(xgb_model)\n",
        "\n",
        "start = time.time()\n",
        "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
        "              verbose = True) # 검증 데이터의 학습 결과를 하나씩 출력해서 보여줌\n",
        "sec = time.time() - start\n",
        "\n",
        "times = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
        "times = times[0]\n",
        "print(times)"
      ],
      "metadata": {
        "id": "vyOLpNxAwuoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "id": "tIzKiYxt2Vj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.info()"
      ],
      "metadata": {
        "id": "V7GieWye2Zy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_test = preprocessing(test)\n",
        "\n",
        "distances = []\n",
        "pick_lon = new_test['pickup_longitude'].tolist()\n",
        "pick_lat = new_test['pickup_latitude'].tolist()\n",
        "drop_lon = new_test['dropoff_longitude'].tolist()\n",
        "drop_lat = new_test['dropoff_latitude'].tolist()\n",
        "\n",
        "for row in range(len(new_test)):\n",
        "  dist = haversine((pick_lat[row], pick_lon[row]), (drop_lat[row], drop_lon[row]))\n",
        "  distances.append(dist)\n",
        "\n",
        "new_test['distance'] = distances\n",
        "new_test.drop(['pickup_longitude', 'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'], axis = 1 , inplace = True)\n"
      ],
      "metadata": {
        "id": "uWSWhd2xxWnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_test.columns"
      ],
      "metadata": {
        "id": "lkdXm4OX0ez3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_xgb = xgb_model.predict(new_test)\n",
        "print(y_pred_xgb)"
      ],
      "metadata": {
        "id": "M_1RpU9hzYU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission['fare_amount'] = y_pred_xgb\n",
        "submission.to_csv('final_submission.csv', index = False)"
      ],
      "metadata": {
        "id": "9dOB0E4CzwTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 자꾸 뭐가 쳐내지기 떄문에 그냥 코드만 작성하고 이번 과정은 종료하겠음\n",
        "!kaggle competitions submit -c new-york-city-taxi-fare-prediction -f _final_submission.csv -m 'Message'"
      ],
      "metadata": {
        "id": "W6b3vYUi0TKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lightGBM\n",
        "\n",
        "params = {\"max_depth\" : 5,\n",
        "          'learning_rate' : 0.5,\n",
        "          'objective' : 'regression', # 회귀 : 'reg:linear' / 이진 분류 : 'binary:logisitic' / 'multi:softmax' (개별 분류값 바로 확인) / 'multi : softprob' (개별)\n",
        "          'eval_metric' : 'rmse',\n",
        "          'early_stopping_rounds' : 5\n",
        "          }\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "lgb_model = lgb.LGBMRegressor(**params)\n",
        "lgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], \n",
        "              verbose = True) # 검증 데이터의 학습 결과를 하나씩 출력해서 보여줌\n",
        "sec = time.time() - start\n",
        "\n",
        "times = str(datetime.timedelta(seconds=sec)).split(\".\")\n",
        "times = times[0]\n",
        "print(times)\n",
        "\n",
        "y_pred_lgb = lgb_model.predict(new_test)\n",
        "print(y_pred_xgb)\n",
        "\n",
        "submission['fare_amount'] = y_pred_xgb\n",
        "submission.to_csv('lightgbm_final_submission.csv', index = False)\n",
        "\n",
        "!kaggle competitions submit -c new-york-city-taxi-fare-prediction -f lightgbm_final_submission.csv - m 'Message'"
      ],
      "metadata": {
        "id": "j74fFqlS34ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CatBoost\n",
        "\n",
        "!pip install catboost\n",
        "\n",
        "from catboost import CatBoostRegressor\n",
        "params = {'depth' : 5,\n",
        "          'learning_rate' : 0.5,\n",
        "          'eval_metric' : 'RMSE',\n",
        "          'early_stopping_rounds' : 5}\n",
        "\n",
        "start = time.time()\n",
        "cat_model = CatBoostRegressor(**params)\n",
        "cat_model.fit(X_train, y_train, eval_set = (X_val, y_val), verbose = True)\n",
        "\n",
        "sec = time.time()-start\n",
        "times = str(datetime.timedelta(seconds = sec)).split(\".\")\n",
        "times = times[0]\n",
        "print(times)\n",
        "\n",
        "y_pred_cat = cat_model.predict(new_test)\n",
        "print(y_pred_cat)\n",
        "\n",
        "submission['fare_Amount'] = y_pred_cat\n",
        "submission.to_csv('catboost_final_submission.csv', index = False)\n",
        "\n",
        "!kaggle competitions submit -c new-york-city-taxi-fare-prediction -f catboost_final_submission.csv -m \"Message\""
      ],
      "metadata": {
        "id": "brLoliaM34u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2LapciFF34yq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3n6e3kn3342e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PmMqcVkt345e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NAzn3Sot348p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1EzAOG-B34_p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}